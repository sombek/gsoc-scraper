{"name":"Kornia","description":"Advancing Computer Vision & Spatial AI, Openly","gsoc_url":"https://summerofcode.withgoogle.com/programs/2025/organizations/kornia","ideas_url":"https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025","logo":"https://summerofcode.withgoogle.com/media/org/kornia/p4e366l478clqvvg-360.png","technologies":["cuda","rust","deep learning","data science","Spatial AI"],"topics":["machine learning","artificial intelligence","robotics","computer vision","3D Geometry"],"projects":[{"project_name":"Implement efficient Smol VLM","summary":"This project focuses on integrating lightweight Visual Language Models into Kornia using Rust, specifically the SmolVLM model from Hugging Face.","difficulty":"Medium"},{"project_name":"Apriltag and calibration detectors","summary":"Aimed at implementing detection algorithms for localization and calibration using April tags and other feature detectors to enhance machine vision capabilities in Kornia.","difficulty":"Hard"},{"project_name":"Pose Estimation algorithms","summary":"This project seeks to improve 3D registration and pose estimation functionalities in Kornia by optimizing algorithms such as ICP, PnP, and various transformation techniques.","difficulty":"Hard"},{"project_name":"Implement GPU image transforms","summary":"The goal is to upgrade native CPU image transformations to GPU implementations in Kornia, improving efficiency for various image processing tasks.","difficulty":"Hard"},{"project_name":"Depth Estimation on Android Using Rust","summary":"Develop an Android application in Rust for real-time depth estimation using ONNX Runtime, enhancing AI processing capabilities for mobile devices.","difficulty":"Hard"},{"project_name":"Implementation of VO Slam API","summary":"This project plans to build a Visual Odometry SLAM API in Rust for use with RGB-D and monocular systems, facilitating robotics and AR applications.","difficulty":"Hard"}],"jina_response":"Title: Google Summer of Code Ideas 2025\n\nURL Source: https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025\n\nMarkdown Content:\n![Image 1: Google Summer of Code](https://raw.githubusercontent.com/kornia/data/main/gsoc_2024_banner.png)\n\n⚠️ ⚠️ [\\[ **READ APPLICATION PROTOCOL**\\]](https://github.com/kornia/kornia-rs/wiki/Google-Sumer-of-Code-Application) ⚠️ ⚠️\n\nProjects Index\n--------------\n\n[](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#projects-index)\n\n1.  [Implement efficient SmolVLM](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#implement-efficient-smol-vlm)\n2.  [Apriltag and calibration detectors](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#apriltag-and-calibration-detectors)\n3.  [Pose Estimation algorithms](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#pose-estimation-algorithms)\n4.  [Implement GPU image transforms](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#implement-gpu-image-transforms)\n5.  [Depth Estimation on Android Using Rust](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#depth-estimation-on-android-using-rust)\n6.  [Implement modular VO Slam API](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#implementation-of-vo-slam-api)\n\n\\*\\* _projects ideas are ordered by soft priority_\n\nProjects\n--------\n\n[](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#projects)\n\n1.  ### Implement efficient Smol VLM\n    \n    [](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#implement-efficient-smol-vlm)\n    \n    *   _**Description:**_ The aim of this project is to bring State of the Art methods for lightweight Visual Language models into Kornia in Rust. Recently, Hugging Face released a family of small visual language models (SmolVLM) which can be a game changer for the industry to build applications in embedded devices using such AI models.\n        \n    *   _**Expected Outcomes:**_ The expectation is to implement an API in Rust to integrate the latest SmolVLM model. Evaluate which NN engine suits better for this task, either onnxruntime (via ORT-Pyke) or Candle. It’s expected also to evaluate a native Rust implementation of the model and its feasibility. Tests and benchmarks in both desktop and nvidia jetson are also mandatory as part of the final delivery.\n        \n    *   _**Resources:**_\n        \n        *   Rust Book: [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/)\n        *   ORT: [https://ort.pyke.io/](https://ort.pyke.io/)\n        *   Candle: [https://github.com/huggingface/candle](https://github.com/huggingface/candle)\n        *   SmolVLM: [https://huggingface.co/HuggingFaceTB/SmolLM-1.7B-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM-1.7B-Instruct)\n    *   _**Possible Mentors:**_ [Miquel Farre](https://github.com/mfarre)\n        \n    *   _**Difficulty:**_ Medium\n        \n    *   _**Duration:**_ 350 hours\n        \n2.  ### Apriltag and calibration detectors\n    \n    [](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#apriltag-and-calibration-detectors)\n    \n    *   _**Description:**_ This project aims to implement in Kornia Rust curated detection algorithms useful for localization and calibration purposes. It’s very common to use April tags for camera calibration applications; or corners detectors for more advanced machine vision applications. In the area of visual localization, common algorithms are FAST (because it is really fast), or ORB. With such methods kornia-rs could be used in many robotics applications together with existing foundational libraries such sophus-rs.\n        \n    *   _**Expected Outcomes:**_ Implement efficient CPU versions of the above detectors with proper testing and benchmarking against common libraries such OpenCV or VPI. It’s expected also as part of the delivery to work together with the author of sophus-rs to show an integration of a calibration system using e.g the april tag detector and/or using FAST features for a Visual SLAM implementation.\n        \n    *   _**Resources:**_\n        \n        *   Rust Book: [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/)\n        *   Nvidia VPI: [https://docs.nvidia.com/vpi/index.html](https://docs.nvidia.com/vpi/index.html)\n        *   Opencv-rs: [https://docs.rs/opencv/latest/opencv/](https://docs.rs/opencv/latest/opencv/)\n        *   Aprilgrid-rs: [https://github.com/powei-lin/aprilgrid-rs](https://github.com/powei-lin/aprilgrid-rs)\n        *   Sophus-rs: [https://github.com/sophus-vision/sophus-rs](https://github.com/sophus-vision/sophus-rs)\n    *   _**Possible Mentors:**_ Edgar Riba. Backup: Hauke or Steven\n        \n    *   _**Difficulty:**_ Hard\n        \n    *   _**Duration:**_ 350 hours\n        \n3.  ### Pose Estimation algorithms\n    \n    [](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#pose-estimation-algorithms)\n    \n    *   _**Description:**_ This project aims to enhance kornia-rs's capabilities in 3D registration and pose estimation by implementing and optimizing key algorithms, including:\n        \n        *   Improve existing Iterative Closest Point (ICP) for point cloud alignment by adding Point to Normal loss, or evaluate again KISS-ICP. Additionally, implement Truncated Signed Distance Function (TSDF).\n        *   Perspective-n-Point (PnP) and Efficient PnP (EPnP) for camera pose estimation\n        *   Affine and similarity transformations (e.g., cv2.AffineTransform3D) for rigid and non-rigid transformations\n        *   Potential optimizations for real-time performance and robustness\n    *   _**Expected Outcomes:**_\n        \n        *   A set of efficient, well-tested Rust implementations of the above algorithms\n        *   Integration with kornia-rs for seamless use in robotics, AR, and SLAM applications\n        *   Benchmarking and comparison with existing implementations for accuracy and performance\n        *   Comprehensive documentation and examples\n    *   _**Resources:**_\n        \n        *   Rust Book: [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/)\n        *   PNP : [https://medium.com/@rashik.shrestha/perspective-n-point-pnp-f2c7dd4ef1ed](https://medium.com/@rashik.shrestha/perspective-n-point-pnp-f2c7dd4ef1ed)\n        *   EPNP : [https://www.tugraz.at/fileadmin/user\\_upload/Institute/ICG/Images/team\\_lepetit/publications/lepetit\\_ijcv08.pdf](https://www.tugraz.at/fileadmin/user_upload/Institute/ICG/Images/team_lepetit/publications/lepetit_ijcv08.pdf)\n        *   ICP: [https://manipulation.csail.mit.edu/Fall2020/pset2/pset2\\_ICP.html](https://manipulation.csail.mit.edu/Fall2020/pset2/pset2_ICP.html)\n        *   KISS-ICP: [https://arxiv.org/abs/2209.15397](https://arxiv.org/abs/2209.15397)\n        *   TSDF: [https://www.open3d.org/docs/0.14.1/tutorial/t\\_reconstruction\\_system/integration.html](https://www.open3d.org/docs/0.14.1/tutorial/t_reconstruction_system/integration.html)\n    *   _**Possible Mentors:**_ [Dmytro Mishkin](https://github.com/ducha-aiki)\n        \n    *   _**Difficulty:**_ Hard\n        \n    *   _**Duration:**_ 350 hours\n        \n4.  ### Implement GPU image transforms\n    \n    [](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#implement-gpu-image-transforms)\n    \n    *   _**Description:**_ This project has the main objective to improve the existing image transformations in the kornia-imgproc crate which are currently implemented in native CPU to be upgraded to GPU. Ideally, propose a plan to upgrade the functionality in this crate into efficient GPU implementations via CubeCL or similar that can support WGP in native Rust. An example would be geometric sampling transformations like resize, or warp\\_affine/warp\\_perspective. Additionally, color transformations and Distance Transform would be very welcomed.\n        \n    *   _**Expected Outcomes:**_ Finished implementations of the functions with proper documentation, testing and benchmarking against existing libraries such OpenCV or Nvidia VPI. Examples and tutorials are expected as part of the end of the project delivery as testing in Nvidia Jetsons.\n        \n    *   _**Resources:**_\n        \n        *   Rust Book: [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/)\n        *   Kornia Imgproc Crate: [https://github.com/kornia/kornia-rs/tree/main/crates/kornia-imgproc](https://github.com/kornia/kornia-rs/tree/main/crates/kornia-imgproc)\n        *   CubeCL: [https://github.com/tracel-ai/cubecl](https://github.com/tracel-ai/cubecl)\n        *   Nvidia VPI: [https://docs.nvidia.com/vpi/index.html](https://docs.nvidia.com/vpi/index.html)\n        *   Opencv-rs: [https://docs.rs/opencv/latest/opencv/](https://docs.rs/opencv/latest/opencv/)\n    *   _**Possible Mentors:**_ [Edgar Riba](https://github.com/edgarriba)\n        \n    *   _**Difficulty:**_ Hard\n        \n    *   _**Duration:**_ 350 hours\n        \n5.  ### Depth Estimation on Android Using Rust\n    \n    [](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#depth-estimation-on-android-using-rust)\n    \n    *   _**Description:**_ This project aims to develop an Android application using Rust to perform real-time depth estimation with ONNX Runtime via [Rust bindings for ONNX Runtime](https://ort.pyke.io/). By leveraging Rust’s performance efficiency and memory safety, the application will enable on-device AI processing for applications in robotics, augmented reality (AR), SLAM, and 3D scene reconstruction.\n        \n    *   _**Expected Outcomes:**_\n        \n        *   A fully functional Rust-based Android application capable of real-time depth estimation.\n        *   Integration of ONNX Runtime via Pyke’s Rust bindings for optimized AI inference.\n        *   Utilization of Android’s official Rust build system for compatibility and performance.\n        *   A lightweight, user-friendly UI for depth visualization.\n        *   Performance benchmarking to compare execution efficiency.\n        *   Comprehensive documentation and a demo video showcasing real-world applications.\n    *   _**Resources:**_\n        \n        *   Android’s Official Build System for Rust Modules: [Overview](https://source.android.com/docs/setup/build/rust/building-rust-modules/overview)\n        *   ONNX Runtime with Rust Bindings: [ORT](https://ort.pyke.io/)\n        *   Depth Estimation Models: \\[Depth-Anything, MiDaS, etc.\\]\n    *   _**Possible Mentors:**_ [Christie Jacob](https://github.com/cjpurackal)\n        \n    *   _**Difficulty:**_ Hard\n        \n    *   _**Duration:**_ 350 hours\n        \n6.  ### Implementation of VO Slam API\n    \n    [](https://github.com/kornia/kornia-rs/wiki/Google-Summer-of-Code-Ideas-2025#implementation-of-vo-slam-api)\n    \n    *   _**Description:**_ This project aims to build a Visual Odometry (VO) SLAM API in Rust for the Kornia-rs ecosystem, focusing first on an RGB-D pipeline (e.g., iPhone LiDAR data + Prompt DepthAnything for high-resolution, accurate depth) and subsequently extending it to monocular-only VO. The implementation should be efficient, dependency-light, and well-suited for real-time or near–real-time robotics and AR/VR use cases.\n        \n    *   _**Expected Outcomes:**_ A VO SLAM crate in Rust that is straightforward to integrate with Kornia-rs, starting first with the simpler RGB-D visual odometry pipeline and making progress towards robust monocular visual odometry pipeline in rust.\n        \n    *   _**Resources:**_\n        \n        *   [RGB-D Odometry Open3D](https://www.open3d.org/docs/release/tutorial/pipelines/rgbd_odometry.html)\n        *   [Monocular Visual Odometry](https://www.mathworks.com/help/vision/ug/monocular-visual-odometry.html)\n        *   [Visual Odometry From Scratch](https://avisingh599.github.io/vision/visual-odometry-full/)\n        *   [Global Registration Open3D](https://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html)\n        *   [MadPose - Relative Pose Estimation through Affine Corrections of Monocular Depth Priors](https://github.com/MarkYu98/madpose)\n        *   [PromptDA - Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation](https://github.com/rerun-io/prompt-da)\n    *   _**Possible Mentors:**_ [Pablo Vela](https://github.com/pablovela5620)\n        \n    *   _**Difficulty:**_ Hard\n        \n    *   _**Duration:**_ 350 hours\n"}