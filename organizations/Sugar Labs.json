{"name":"Sugar Labs","description":"Learning software for children","gsoc_url":"https://summerofcode.withgoogle.com/programs/2025/organizations/sugar-labs","ideas_url":"https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md","logo":"https://summerofcode.withgoogle.com/media/org/sugar-labs/pgbt7fp6gr6lhihd-360.png","technologies":["python","gtk","typescript","javascipt","LLM"],"topics":["education","programming languages","games","desktop","generative AI"],"projects":[{"project_name":"Git backend for Turtle Blocks and Music Blocks","summary":"Introduce Git version control to Turtle Blocks and Music Blocks, enabling collaboration, history tracking, and project management features.","difficulty":"Hard"},{"project_name":"Color sensor for Music Blocks","summary":"Add functionality to detect colors from uploaded images and live video in Music Blocks, enhancing interactive projects for visually impaired users.","difficulty":"Medium"},{"project_name":"Interactive AI-powered Chatbot and Debugger for Music Blocks","summary":"Develop an AI chatbot and debugger for Music Blocks to assist users with project troubleshooting and feature exploration.","difficulty":"Hard"},{"project_name":"Improve synth and sample features in Music Blocks","summary":"Enhance sound capabilities in Music Blocks by updating the synth and sampling features for better audio quality and usability.","difficulty":"Hard"},{"project_name":"Generative AI Instrument Sample Generation for Music Blocks","summary":"Create a generative AI API to allow users to generate unique audio samples based on textual prompts in Music Blocks.","difficulty":"Hard"},{"project_name":"AI Code generation for lesson plans","summary":"Develop a system utilizing AI to generate project code snippets for lesson plans, improving educational outcomes in Music Blocks.","difficulty":"Hard"},{"project_name":"AI tools for reflection","summary":"Implement AI-driven tools for learners to reflect on their projects by generating thoughtful prompts during saving or journaling.","difficulty":"Hard"},{"project_name":"Music Blocks 4 Program Engine","summary":"Build the execution engine for Music Blocks 4 to interpret and execute programs, focusing on efficiency and accuracy.","difficulty":"High"},{"project_name":"Music Blocks 4 Masonry Module","summary":"Develop a visual programming module for Music Blocks that allows users to build programs interactively using graphical blocks.","difficulty":"Hard"},{"project_name":"Add an AI-assistant to the Write Activity","summary":"Integrate AI features into the Write Activity to assist with writing suggestions and grammar corrections.","difficulty":"High"},{"project_name":"Refactor the Infoslicer Activity","summary":"Transform the Infoslicer into a tool that generates plain-language summaries for educators, enhancing lesson planning.","difficulty":"High"},{"project_name":"GTK4 Exploration","summary":"Migrate Sugar from GTK3 to GTK4, ensuring modern compatibility and maintaining core functionalities of the platform.","difficulty":"High"},{"project_name":"JS internationalization","summary":"Update the JavaScript localization framework for Sugar activities to a more modern and flexible solution for language support.","difficulty":"Medium"},{"project_name":"Sugarizer Human Activity pack","summary":"Create new activities and finalize existing ones in Sugarizer's framework, enhancing user engagement across subjects.","difficulty":"Medium"},{"project_name":"Pippy Debugger","summary":"Build a debugging tool for the Pippy activity using AI to help learners identify and fix issues with their Python code.","difficulty":"Medium"},{"project_name":"Math Games","summary":"Design and develop several interactive math games to enhance educational engagement among learners.","difficulty":"Medium"}],"jina_response":"Title: GSoC/Ideas-2025.md at master · sugarlabs/GSoC\n\nURL Source: https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md\n\nMarkdown Content:\nProject Ideas\n-------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#project-ideas)\n\n*   [Git backend for Turtle Blocks and Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Git-backend-for-Turtle-Blocks-and-Music-Blocks)\n*   [Color sensor for Music Blocks for photos and real-time video](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Color-sensor-for-Music-Blocks-for-photos-and-real-time-video)\n*   [Interactive AI-powered Chatbot and Debugger for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Interactive-AI-powered-Chatbot-and-Debugger-for-Music-Blocks)\n*   [Improve synth and sample features in Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Improve-synth-and-sample-features-in-Music-Blocks)\n*   [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)\n*   [AI Code generation for lesson plans and model abstraction layer](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#AI-Code-generation-for-lesson-plans-and-model-abstraction-layer)\n*   [AI tools for reflection](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#AI-tools-for-reflection)\n*   [Music Blocks 4 Program Engine](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Music-Blocks-4-Program-Engine)\n*   [Music Blocks 4 Masonry Module](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Music-Blocks-4-Masonry-Module)\n*   [Add AI-assistant to the Write Activity](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Add-an-AI-assistant-to-the-Write-Activity)\n*   [Refactor the Infoslicer Activity to generate plain-language summaries](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Refactor-the-Infoslicer-Activity-to-generate-plain-language-summaries)\n*   [Refactor the chatbot in the Speak Activity to use gen-AI](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Refactor-the-chatbot-in-the-Speak-Activity-to-use-gen-AI)\n*   [GTK4 exploration](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#gtk4-exploration)\n*   [JS internationalization](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#js-internationalization)\n*   [Sugarizer Human Activity pack](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#sugarizer-human-activity-pack)\n*   [Pippy Debugger](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#pippy-debugger)\n*   [Math Games](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#math-games)\n\n* * *\n\nGit backend for Turtle Blocks and Music Blocks\n----------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#git-backend-for-turtle-blocks-and-music-blocks)\n\n**Prerequisites**\n\n*   Experience with Git\n*   Experience with JavaScript\n*   Experience with Music Blocks and Turtle Blocks\n\n**Description**\n\nPortfolio creation, reflection, and collaboration are important parts of the educational philosophy at Sugar Labs, and Git version control is a great way to explore all these things.\n\nAt Sugar Labs, we've created some initial designs\\]([https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing](https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing)) for a couple approaches to introducing Git version control to young learners. This proposal focuses on introducing Git version control through our existing web-based programs, namely Turtle Blocks and Music Blocks. Both these programs have a feature to publish projects to a server called the \"Planet\". Currently the Planet just stores projects that users have made, without any sort of version control features like _fork_, _history_, or _checkout_.\n\nThis project requires a contributor to work closely with Sugar Labs mentors to implement a system of Git version control features, running on a backend server, that are exposed to the user.\n\nReferences:\n\n*   [https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing](https://drive.google.com/file/d/15G0vtr-1JyzCorwmgjvXE-37vwZMLgJD/view?usp=sharing)\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**Hard**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)\n\n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\nColor sensor for Music Blocks for photos and real-time video\n------------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#color-sensor-for-music-blocks-for-photos-and-real-time-video)\n\n**Prerequisites**\n\n*   Experience with JavaScript\n*   Experience with Music Blocks\n\n**Description**\n\nMusic Blocks has a feature to detect the color of pixels generated from drawing within the program, but it cannot detect the color of pixels from images that are either uploaded or from a webcam. By adding a feature to detect color from both uploaded images and a live webcam stream, users would be able to implement _Lego music notation for the blind_ and similarly interactive programs.\n\nThe goal of the project is to develop extended functionality to our existing tools of turtle/mouse glyph movement and limited color detection to sense color from uploaded images, as well as the real-time feed from a webcam. Upon successful implementation, the turtle/mouse glyph will be able to detect the color of pixels underneath it, regardless of whether those pixels were drawn by the turtle/mouse itself, part of an uploaded image stamped to the canvas, or part of a live webcam video feed into Music Blocks. One test of success is to run our _Lego music notation for the blind_ project with a live feed. The result should be able to playback and record the abstract brick notation based on its contrasting colors.\n\nReferences:\n\n*   [https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c](https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c)\n*   [https://vimeo.com/983707992](https://vimeo.com/983707992)\n*   [https://vimeo.com/983697295](https://vimeo.com/983697295)\n\n**Project Length**\n\n**175** hours\n\n**Difficulty**\n\n**Medium**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/)  \n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nInteractive AI-powered Chatbot and Debugger for Music Blocks\n------------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#interactive-ai-powered-chatbot-and-debugger-for-music-blocks)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Music Blocks\n*   Experience with LLMs/Chatbots\n*   Experience with AWS\n*   Experience with FastAPI\n\n**Description**\n\nThe idea is to enhance Music Blocks with an AI-powered chatbot and project debugger. This feature aims to bridge the gap between users' creative ideas and their ability to troubleshoot or fully utilize the platform's features. The AI chatbot would provide real-time assistance by answering questions, explaining features, and offering creative suggestions, while the project debugger would help users quickly identify and resolve issues in their projects or block connections. This enhancement would make the platform more accessible for beginners while streamlining the debugging and experimentation process for advanced users.\n\nSpecifically, we aim to achieve the following:\n\n*   Train an open-source LLM to understand Music Blocks projects and develop the ability to debug them effectively.\n*   Implement robust Retrieval-Augmented Generation (RAG) for the LLM model to enhance contextual understanding.\n*   Integrate the AI chatbot and debugger into the Music Blocks platform.\n*   Develop FastAPI endpoints to deploy the model efficiently.\n*   Work on techniques to minimize hallucinations and improve accuracy.\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**Hard**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)\n\n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nImprove synth and sample features in Music Blocks\n-------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#improve-synth-and-sample-features-in-music-blocks)\n\n**Prerequisites**\n\n*   Experience with JavaScript\n*   Experience with Music Blocks\n*   Experience with Tone.JS\n\n**Description**\n\nUsers have two main methods within Music Blocks to play with sound: synths and samples. For our synth, we use tone.js. For samples, we use .wav binaries and transpose the sound to different pitches. While these features work \"well enough,\" there is still more that can been to make them useful. For this project, a contributor would work closely with their mentors to 1) update the sampler widget, 2) port a list of free/libre/open samples into Music Blocks, and 3) add to the _Set Instrument_ feature and _Sampler Widget_ the ability to assign multiple samples for the same instrument with criteria (e.g. high and low, short and long) for a more natural sound.\n\nUpdating the sampler widget will involve updating tone.js to its current version, debugging any issues that updates may cause, and making improvements to the UI/UX of the widget itself.\n\nPorting samples into Music Blocks will require following the directions specified in the Music Blocks documentation to convert a curated list of samples. After completing this, the user-facing menus showing the samples will need to be updated and organized based on instrument type. There is some room to get creative with the presentation of the instruments, perhaps adding icons for each instrument.\n\nThe final part of the project is perhaps the most challenging. It will require adding additional functionality so that a user can either upload or record multiple samples of an instrument or voice to be assigned to a custom instrument in Music Blocks. Doing this will make the overall tone of the instruments more persuasive. For example, if the Music Blocks project has short, staccato sounds, the playback can use the short sample created by a recorded instrument.\n\nReferences:\n\n*   [https://github.com/sugarlabs/musicblocks/tree/master/sounds/samples](https://github.com/sugarlabs/musicblocks/tree/master/sounds/samples)\n*   \"Processing for pitched (non-percussion) samples\" section of [https://wiki.sugarlabs.org/go/Music\\_Blocks/2025-02-09-meeting](https://wiki.sugarlabs.org/go/Music_Blocks/2025-02-09-meeting)\n*   A professionals guide to creating \"virtual instruments\": [https://www.nicolastiteux.com/en/blog/making-a-virtual-instrument-a-guide-to-sampling/](https://www.nicolastiteux.com/en/blog/making-a-virtual-instrument-a-guide-to-sampling/)\n*   Possible samples: [https://philharmonia.co.uk/resources/sound-samples/](https://philharmonia.co.uk/resources/sound-samples/)\n*   Possible samples: [https://github.com/sonic-pi-net/sonic-pi/tree/dev/etc/samples](https://github.com/sonic-pi-net/sonic-pi/tree/dev/etc/samples)\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**Hard**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/)  \n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nGenerative AI Instrument Sample Generation for Music Blocks\n-----------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#generative-ai-instrument-sample-generation-for-music-blocks)\n\n**Prerequisites**\n\n*   Experience with JavaScript and Python\n*   Experience with Music Blocks\n*   Experience with Tone.JS\n*   Experience with LLMs/neural-networks\n\n**Description**\n\nFor this project, a contributor would work closely with their mentors create an API to a gen-AI to generate samples based on a user prompt.\n\nIn order to give users (nearly) limitless options for samples, we are adding to the project's scope a gen-AI-enabled sample generator. A user should be able to prompt a sound font, such as \"something between a heavy metal guitar and a lion roar\" or \"something between a clarinet and a human singing 'ah'\" additionally, a user should be able to play an instrument or upload recorded audio of an instrument and prompt modifications for the gen-AI to make to the sound, such as \"make this recording of my acoustic cello sound like an electric cello with heavy distortion and get a result that they can use in their project's code. A contributor will need to extend our sample widget (which currently records audio) to accept a user prompt, create an API to call an LLM/neural-network backend, and test/tweak the gen-AI backend to create an appropriate sample for the user. The results of this part of the project need not be \"perfect\" by the end of the summer. A solid proof of concept will be sufficient.\n\nIn particular, our focus will be on achieving the following objectives:\n\n*   Extend the sample widget to support user prompts for AI-generated sound samples.\n*   Develop an LLM-based generative AI backend to produce high-quality, relevant sound samples.\n*   Build a high-performance API using FastAPI to streamline interactions between the widget and the LLM.\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**Hard**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)\n\n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nAI Code generation for lesson plans and model abstraction layer\n---------------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#ai-code-generation-for-lesson-plans-and-model-abstraction-layer)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Music Blocks\n*   Experience with LLMs/Chatbots\n*   Experience with Fine tuning methods and RAG.\n\n**Description**\n\nDevelop and train an open-source Large Language Model to generate Music Blocks project code, enabling the integration of code snippets into the lesson plan generator for better understanding of the projects. Additionally, by implementing a model abstraction layer, the AI system will remain flexible and model-agnostic, allowing seamless integration of different AI models while maintaining consistent code generation capabilities. This approach ensures long-term sustainability and adaptability as AI technology evolves while keeping the core functionality of Music Blocks accessible and extensible.\n\nSpecifically, we would be working toward accomplishing the following:\n\n*   Train open source LLM to generate code to create new Music Blocks projects.\n*   Implement model abstraction layer to make the AI system model agnostic and robust.\n*   Increase database size by including more lesson plans and projects' data to get better response related to the projects.\n*   Implement Approximate Nearest Neighbor (ANN) algorithms for faster retrieval.\n*   Develop FastAPI endpoints to deploy the model.\n*   Work on and implement techniques to minimize hallucination.\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**Hard**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)\n\n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nAI tools for reflection\n-----------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#ai-tools-for-reflection)\n\n**Prerequisites**\n\n*   Experience with Python/JavaScript\n*   Experience with LLMs/Chatbots\n\n**Description**\n\nWhile off-the-shelf Generative AI tools are great at helping a learner to create, they offer little in regard to reflecting upon those creations. But reflection is a critical (and too often overlooked) part of the Constructionist learning pedagogy. With some prompting -- something LLMs are quite good at -- we can engage the learner in a quality relfective practice. The dialog could occur when exiting any Sugar activity as part of the journaling process or whenever a Music Blocks or Turtle Blocks project is saved to the Planet. Rather than just being presented with an empty form, the learner will be prompted to talk about what they did, why they did it, what they learned and what they might do next.\n\nSpecifically, we would be working toward accomplishing the following:\n\n*   Research different approaches to reflective practice\n*   Train open source LLM to generate code to prompt the learn with a multitude of these approaches to reflection\n*   Develop FastApi endpoints to deploy the model.\n*   Deploy this model in either the Music Blocks Planet or the Sugar Journal or the Sugarizer Journal to be triggered whenever a project is paused or saved\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**Hard**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)\n\n**Assisting Mentors**  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nMusic Blocks 4 Masonry Module\n-----------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#music-blocks-4-masonry-module)\n\n**Prerequisites**\n\n*   Proficiency in **TypeScript**\n*   Proficiency in **JavaScript DOM API**\n*   Experience with **React Functional Components and Hooks**\n*   Familiarity with **Storybook** and **Vitest**\n*   Familiarity with **SVG paths and groups**\n\n**Description**\n\n_Music Blocks_ programs are designed to be built interactively by connecting program constructs, which are visually represented as snap-together, Lego-like graphical bricks. The goal is to develop a module for _Music Blocks_ (_v4_) that enables the creation of _Music Blocks_ programs.\n\nThe project will begin with the development of a framework for generating individual brick components that represent various program syntax constructs. This will be followed by the creation of utilities to represent any program structure through visual connections between the bricks. Next, a component will be built to display all available program bricks, organized into categories, sections, and groups. Finally, a workspace will be developed where users can drag-and-drop, as well as connect and disconnect the program bricks to create their programs.\n\nTo draw the bricks, we will use SVG paths, so a solid understanding of SVG path commands is crucial. The development will follow an Object-Oriented Programming approach in TypeScript, with the rendering and management of visual states handled using React Functional Components. A strong understanding of both TypeScript and React is expected.\n\nThis project began last year, and you will be expected to build upon the progress made and complete the module.\n\nThe overall objectives are as follows:\n\n*   Collaborate with project maintainers to create a design document outlining functional requirements, UI considerations, both high-level and low-level designs, and a technical specification.\n    \n*   Develop utilities to generate SVG paths for the bricks based on configurations.\n    \n*   Build utilities to represent and manipulate _Music Blocks_ programs in-memory.\n    \n*   Develop the four individual submodules outlined above.\n    \n*   Write Storybook stories to document and showcase UI components.\n    \n*   Implement unit tests for functions and classes using Vitest.\n    \n*   Focus on optimizing processing performance.\n    \n*   Export a minimal API for integration with other parts of the application.\n    \n\n**Project Length:** **350** hours\n\n**Difficulty:** **Hard** (★ ★ ★ ★ ★)\n\n**Tech Stack**\n\nTypeScript 5, React 18, Sass, Storybook, Vitest, Vite\n\n**Mentors**  \n[Anindya Kundu](https://github.com/meganindya/)\n\n**Assisting Mentors**  \n[Walter Bender](https://github.com/waltebender/)  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nMusic Blocks 4 Program Engine\n-----------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#music-blocks-4-program-engine)\n\n**Prerequisites**\n\n*   Proficiency in **TypeScript** and **Object-Oriented Programming**\n*   Experience with writing unit tests using **Jest**/**Vitest**\n*   Good understanding of the **JavaScript Event Loop**\n*   Understanding of **Abstract Syntax Trees** (**AST**)\n\n**Tech Stack**\n\nTypeScript 5, Vitest, Vite\n\n**Description**\n\n_Music Blocks_ is a programming platform, and at its core is the execution engine responsible for running _Music Blocks_ programs. This project will focus on building the execution engine and the necessary components to represent and execute _Music Blocks_ programs in-memory.\n\nThe project will begin by refining the Object-Oriented program syntax constructs. These constructs will encapsulate the logic for each syntax element and will serve as the foundation for developing a framework to represent Abstract Syntax Trees (ASTs) for _Music Blocks_ programs. Additional utilities will be built to manage instances of these syntax constructs, thus completing the static pieces.\n\nNext, several components will need to be developed to execute the program ASTs, forming the dynamic pieces of the project. Key components include:\n\n*   **Parser:** Responsible for parsing the nodes of the ASTs in inorder traversal.\n*   **State Manager:** Manages the program state at any given point during execution.\n*   **Interpreter:** Executes individual expressions and instructions.\n\nIt’s important to note that _Music Blocks_ programs combine both imperative and declarative constructs. Additionally, some instructions in the programs execute over a time duration, and the programs themselves are multi-threaded. These threads must run concurrently while ensuring proper synchronization.\n\nWe currently have a work-in-progress on [github.com/sugarlabs/musicblocks-v4-lib](https://github.com/sugarlabs/musicblocks-v4-lib), but some design decisions need to be revisited. This project will involve understanding and refining these design choices and completing the remaining components.\n\nThe overall objectives are as follows:\n\n*   Collaborate with project maintainers to define all expected functionalities and behaviors, and write a technical specification.\n    \n*   Collaborate with project maintainers to develop a concrete execution algorithm, addressing time-based instructions, concurrency, and synchronization.\n    \n*   Refine and complete the static components responsible for program representation.\n    \n*   Refine and complete the dynamic components responsible for program execution.\n    \n*   Write comprehensive unit tests for all components.\n    \n*   Focus on optimizing runtime performance.\n    \n\n**Project Length:** **350** hours\n\n**Difficulty:** **High** (★ ★ ★ ★ ☆)\n\n**Mentors**  \n[Anindya Kundu](https://github.com/meganindya/)\n\n**Assisting Mentors**  \n[Walter Bender](https://github.com/waltebender/)  \n[Devin Ulibarri](https://github.com/pikurasa/)\n\n* * *\n\nAdd an AI-assistant to the Write Activity\n-----------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#add-an-ai-assistant-to-the-write-activity)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Sugar activities\n*   Experience with LLMs/Chatbots\n\n**Description**\n\nSugar pioneered peer editing in its Write Activity. However, the Write Activity has never had any serious support for grammar correction (just spell check) and none of the more recent developments around AI-assisted writing. The goal of this project is to add AI-assistance to the writing process: both in the form of providing feedback as to what has been written and making suggestions as to what might be written.\n\nThe challenge will be both in terms of workflow integration and UX.\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**High**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Ibiam Chihurumnaya](https://github.com/chimosky/)\n\n**Assisting Mentors**\n\n* * *\n\nRefactor the Infoslicer Activity to generate plain-language summaries\n---------------------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#refactor-the-infoslicer-activity-to-generate-plain-language-summaries)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Sugar activities\n*   Experience with LLMs/Chatbots\n\n**Description**\n\nThe Infoslicer Activity is designed to help teachers extract content from the Wikipedia in order to create lesson plans. This is currently a manual, extractive process. It is well suited to generative AI. The goal would be to have a teacher type in a theme for a lesson and have the AI create a simple lesson plan, which the teacher can then edit.\n\nThe biggest challenge to summarization using generative AI is hallucinations. A work-around for this is to include a validation step that surfaces evidence (or lack of evidence) for each assertion in the lesson plan. This will introduce some workflow and UX challenges.\n\n**Project Length**\n\n**350** hours\n\n**Difficulty**\n\n**High**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Ibiam Chihurumnaya](https://github.com/chimosky/)\n\n**Assisting Mentors**\n\n* * *\n\nRefactor the chatbot in the Speak Activity to use gen-AI\n--------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#refactor-the-chatbot-in-the-speak-activity-to-use-gen-ai)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Sugar activities\n*   Experience with LLMs/Chatbots\n\n**Description**\n\nThe [Speak Activity](https://github.com/sugarlabs/speak) is one of most popular Sugar activities. It allows someone just beginning to familiarize themselves with reading to interact with synthetic speech. It has both chat and chatbot capabilities, so that learners can share what they type with others, often using invented spelling. It would be a nice improvement if there were a chatbot option to allow a learner to have a conversation with a more modern chatbot -- LLM-based. This would contextualize the learner's experience with writing -- a tool for both self expression and communication.\n\nThe project would entail both enabling the LLM chatbot and doing some tuning in order to accommodate invented spelling. Finally, it will be important to create the proper persona, in this case, an adult explaining to a young child.\n\n**Project Length**\n\n**175** hours\n\n**Difficulty**\n\n**Medium**\n\n**Coding Mentors**  \n[Ibiam Chihurumnaya](https://github.com/chimosky/)\n\n**Assisting Mentors**  \n[Walter Bender](https://github.com/walterbender/)\n\n* * *\n\nGTK4 Exploration\n----------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#gtk4-exploration)\n\n**Prerequisites**\n\n*   Experience with C\n*   Experience with Python\n*   Experience with GTK\n*   Good understanding of Sugar Core architecture\n\n**Description**\n\nSugar 0.120 runs on GTK3 and needs to be ported to GT4, we need to port Sugar and its core activities to support GTK4 before GTK3 gets to its EOL.\n\n**Project Task Checklist**\n\n*   Migrate minimal [sugar-toolkit-gtk3](https://github.com/sugarlabs/sugar-toolkit-gtk3) components to support Hello World activity, in particular the activity and graphics classes.\n*   Migrate [Hello World](https://github.com/sugarlabs/hello-world) activity.\n*   Document migration strategy based on extending any existing upstream GTK3 to GTK4 porting documentation.\n*   Migrate remaining toolkit components.\n*   Extend Hello World to use remaining toolkit components, and rename as a Toolkit Test activity,\n*   Migrate [Sugar](https://github.com/sugarlabs/sugar).\n*   Migrate the [Fructose](https://wiki.sugarlabs.org/go/Development_Team/Release/Modules) activity set, as time permits.\n\n**Steps to start**\n\n*   Plan migration.\n*   Setup a [live build](https://github.com/sugarlabs/sugar/blob/master/docs/development-environment.md#sugar-live-build) development environment.\n*   See the [GTK4 migrating](https://docs.gtk.org/gtk4/migrating-3to4.html#stop-using-direct-access-to-gdkevent-structs) doc.\n\n**Project length**  \n**350** hours\n\n**Difficulty:**  \n**High**\n\n**Coding Mentors**  \n[Ibiam Chihurumnaya](https://github.com/chimosky/)\n\n* * *\n\nJS internationalization\n-----------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#js-internationalization)\n\n**Prerequisites**\n\n*   Experience with JavaScript\n\n**Description**\n\nOur JavaScript activities are using a somewhat antiquated mechanism for internationalization, the webL10n.js library. It does not even support plurals or any language-specific formatting. i18next looks like a well-maintained and promising alternative.\n\nThis project involves: (a) researching the state of art of language localization for JavaScript, keeping in mind that we are currently maintaining PO files; (b) making a recommendation as to the framework; (c) proposing a path to implementation; and (d) implementing the solution in Music Blocks. (Other JS projects can follow along.)\n\n**Project Task Checklist**\n\n*   research\n*   recommendation\n*   plan\n*   coding\n\n**Project length**  \n**175** hours\n\n**Difficulty:**  \n**Medium**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/)\n\n* * *\n\nSugarizer Human Activity pack\n-----------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#sugarizer-human-activity-pack)\n\n**Prerequisites**\n\n*   Experience with JavaScript/HTML5 in VanillaJS or with Vue.js\n*   Experience with three.js 3D framework\n*   Knowledge of 3D tools, capacity to create/combine 3D assets\n\n**Description**\n\nThe objective of this project is to:\n\n*   Finalize the 3D Human Body activity\n*   Create a new activity named Stickman Animation\n\n[![Image 1](https://github.com/sugarlabs/GSoC/raw/master/assets/sugarizer_humanbody.png)](https://github.com/sugarlabs/GSoC/blob/master/assets/sugarizer_humanbody.png)\n\n**3D Human Body activity**\n\nThe human Body activity has been started on [https://github.com/llaske/sugarizer/tree/feature/humanbody](https://github.com/llaske/sugarizer/tree/feature/humanbody).\n\nTasks to do:\n\n*   Identify the missing assets for the body layer and the organs layer (only skeleton layer is here today)\n*   Integrate these layers in the activity and the way to change layer\n*   Implement the shared mode for doctor mode\n*   Review the UI for toolbar and popups\n*   Localize the activity\n*   Suggest other improvements\n\n[![Image 2](https://github.com/sugarlabs/GSoC/raw/master/assets/sugarizer_stickman.png)](https://github.com/sugarlabs/GSoC/blob/master/assets/sugarizer_stickman.png)\n\n**Stickman Animation activity**\n\nCreate a new activity to allow creation of animated sequence of a stickman.\n\nThe idea of the activity is a \"keyframe animation\" tool that lets you pose and program a stick figure to rotate, twist, turn, tumble, and dance. The new activity can be integrated into many school subject areas such as creative writing, art, drama, geometry and computer programming. Students can make figures that relate to a subject the class is studying, and share them with peers using collaboration feature. It helps children develop spatial and analytical thinking skills and to express ideas that they might not have words for yet.\n\nFeatures expected:\n\n*   Put the stickman figure in different poses by moving dots\n*   Create and order frames with the different poses created\n*   Play/Pause the whole frames\n*   Change speed\n*   Share and collaborate\n*   Export as a video\n*   Access to a list of existing fun templates\n*   Import a photo of an human body to create a stickman figure in the same pose\n\nInspirations:\n\n*   [https://activities.sugarlabs.org/en/sugar/addon/4044](https://activities.sugarlabs.org/en/sugar/addon/4044)\n*   [https://www.spatial.io/g/stick-animator](https://www.spatial.io/g/stick-animator)\n*   [https://flipanim.com/](https://flipanim.com/)\n*   [https://pivotanimator.net/](https://pivotanimator.net/)\n*   [https://drawastickman.com](https://drawastickman.com/)\n*   [https://stickfigure-recorder.web.app/](https://stickfigure-recorder.web.app/)\n\n**First steps to starts**\n\n*   Complete the [Sugarizer Vanilla Javascript activity development tutorial](https://github.com/llaske/sugarizer/blob/dev/docs/tutorial/VanillaJS/tutorial.md) or the [Sugarizer Vue.js activity development tutorial](https://github.com/llaske/sugarizer/blob/dev/docs/tutorial/VueJS/tutorial.md). Publish on Discord a video of the Pawn activity running.\n*   Start working of tasks listed for Human Body activity\n*   Create a mockup of the Stickman Animation activity\n\n**Project length**  \n**175** hours\n\n**Difficulty:** ★ ★ ☆ (medium)\n\n**Coding Mentors**  \n[Lionel Laské](https://github.com/llaske/)\n\n**Assisting Mentors**  \n[Samarth Bagga](https://github.com/SamarthBagga/)\n\nPippy Debugger\n--------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#pippy-debugger)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Sugar activities\n*   Experience with LLMs/Chatbots\n\n**Description**\n\nMany LLM programs for coding are almost exclusively marketed as \"helping you write code for you\". However, we believe that LLMs can also assist learners to _debug their code_. This project proposal is to create an LLM-powered debugger for Pippy, the Sugar Activity for creating code in Python.\n\nThe proposed Pippy Debugger integrates with the existing Pippy Activity. The LLM-powered debugger should be able to read a learner's code and offer suggestions for improvement when prompted. It should also help engage the learning in a conversation about how to discover where to look to find bugs and how to think about resolving them -- in other words, take the learning on a debugging journey as opposed to just spoon-feeding a solution. And since we work with youth, we need to make sure that the debugger's output is age-appropriate. The Pippy interface will also be updated to expose the new feature to a user.\n\n**Project Length**\n\n**175** hours\n\n**Difficulty**\n\n**Medium**\n\n**Coding Mentors**  \n[Walter Bender](https://github.com/walterbender/) [Ibiam Chihurumnaya](https://github.com/chimosky/) [Kshitij Shah](https://github.com/kshitijdshah99/)\n\n* * *\n\nMath Games\n----------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#math-games)\n\n**Prerequisites**\n\n*   Experience with Python\n*   Experience with Sugar activities\n*   Interest in math puzzles and games\n\n**Description**\n\nWhile Sugar has lots of activities, you can never have enough math games and puzzles.This project would be to develop 8 new maths activities.\n\nThese are some of the tentative Maths games of interest:\n\n*   [Four Color map game](https://www.transum.org/maths/activity/colouring/)\n    \n*   [Broken Calculator](https://toytheater.com/broken-calculator/)\n    \n*   [Soma cubes](https://www.britannica.com/topic/Soma-Cubes),\n    \n*   [Fifteen Puzzle](https://www.britannica.com/topic/Fifteen-Puzzle).\n    \n*   [Euclid's Game](https://www.cut-the-knot.org/blue/EuclidAlg.shtml)\n    \n*   [Odd Scoring](http://cut-the-knot.org/Curriculum/Games/OddScoring.shtml)\n    \n*   [Make An Identity](http://www.cut-the-knot.org/Curriculum/Algebra/Latin.shtml)\n    \n*   Number Detective - Number Detective is a fun math game that teaches pattern recognition and AI basics.  \n    User input a number sequence, and the AI predicts the next number.  \n    If the AI is wrong, the user corrects it, helping it learn over time!  \n    The game uses simple rule-based logic and machine learning for predictions.\n    \n*   Sorting Hat AI - Sorting Hat AI is an interactive game that teaches how AI classifies objects.  \n    User label animals, shapes, or numbers, and the AI learns to classify new ones.  \n    If the AI makes a mistake, kids correct it, improving its learning over time!  \n    The game uses **Decision Trees** or **k-Nearest Neighbors (k-NN)** for classification.\n    \n\nNote: These are some tentative ideas for math games. Further updates, additions, or modifications can be made through discussions with mentors to develop the best possible games.\n\n**Project Length**  \n**350** hours\n\n**Difficulty**  \n**Medium**\n\n**Coding Mentors**  \n[Ibiam Chihurumnaya](https://github.com/chimosky/)\n\n**Assisting Mentors**  \n[Walter Bender](https://github.com/walterbender/)\n\n* * *\n\nAdministrative notes\n--------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#administrative-notes)\n\nAbove are a list of ideas we've planned for GSoC 2025 projects. If you have any ideas which can be useful to us, but are not in the list, we'd love to hear from you. You need not be a potential student or a mentor to suggest ideas.\n\n*   [Criteria for Ideas](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#criteria-for-ideas)\n*   [Coding Mentors](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#coding-mentors)\n*   [Assisting Mentors](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#assisting-mentors)\n*   [Everyone Else](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#everyone-else)\n*   [Suggested Issues](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#suggested-issues)\n\nCriteria for Ideas\n------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#criteria-for-ideas)\n\n1.  Does it fill an empty pedagogy niche in the activity set for Sugar or Sugarizer,\n2.  Does it increase quality of our software products (Sugar, activities, Music Blocks, or Sugarizer),\n3.  Does it _not_ involve any project infrastructure, e.g. not another app store, web site, or developer landing page,\n4.  Do we have a developer _now_ who would be willing and able to do it if a student was not available, and who can _promise_ to do it if a student is not selected; these are shown as a _coding mentor_,\n\nCoding Mentors\n--------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#coding-mentors)\n\nFor each idea, we must have offers from one or more _coding mentors_ willing and able to assist students with coding questions.\n\nRequirements for a _coding mentor_ are a demonstrated coding ability in the form of contributions of code to Sugar Labs.\n\nMentors for a project will be assigned after proposals are received.\n\nAssisting Mentors For each idea, we may have offers from\n--------------------------------------------------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#assisting-mentors-for-each-idea-we-may-have-offers-from)\n\nmentors _who do not code_ willing to assist students in various other ways, such as gathering requirements, visual design, testing, and deployment; these are shown as an _assisting mentor_.\n\nThe only requirement for an _assisting mentor_ is _knowledge of the project_.\n\nMentors for a project will be assigned after proposals are received.\n\nEveryone Else\n-------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#everyone-else)\n\nEveryone else in Sugar Labs may also be involved with these projects, through mailing lists, Wiki, and GitHub.\n\nThe difference between a _mentor_ and _everyone else_, is that a _mentor_ is obliged to respond when a student has a question, even if the answer is \"I don't know.\" When a _mentor_ receives a question for which the best forum is _everyone else_, then they are to respectively redirect the student to ask _everyone else_. See [\"Be flexible\"](https://github.com/sugarlabs/sugar-docs/blob/master/src/CODE_OF_CONDUCT.md#be-flexible) and [\"When you are unsure, ask for help\"](https://github.com/sugarlabs/sugar-docs/blob/master/src/CODE_OF_CONDUCT.md#when-you-are-unsure-ask-for-help) in our Code of Conduct.\n\nSuggested Issues\n----------------\n\n[](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#suggested-issues)\n\nFor some ideas, there is a list of 'Suggested issues to work on'. These may help you to get familiar with the project. The more you work on these issues, the more experienced you will be for the project. However, this is not a strict list. You _should_ try and explore other issues as well.\n"}