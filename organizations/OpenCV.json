{"name":"OpenCV","description":"++ beneficial uses of computer vision in society","gsoc_url":"https://summerofcode.withgoogle.com/programs/2025/organizations/opencv","ideas_url":"https://github.com/opencv/opencv/wiki/GSoC_2025","logo":"https://summerofcode.withgoogle.com/media/org/opencv/fmh9fnybaz97kodm-360.png","technologies":["python","c++","deep learning","ai"],"topics":["robotics","computer vision","ai","deep learning"],"projects":[{"project_name":"OpenCV Google Summer of Code 2025","summary":"This is the project page for the Google Summer of Code 2025 involving the OpenCV library, providing an overview of accepted projects, important dates, and resources for contributors.","difficulty":"Medium-Difficult"},{"project_name":"Accepted Projects","summary":"The page includes an 'Accepted Projects' section which mentions contributions and the contributors for the GSoC 2025, along with a link to a spreadsheet of projects.","difficulty":"Medium"},{"project_name":"Important Dates","summary":"This section outlines key dates for GSoC 2025, from organization applications to coding phases and evaluations, helping contributors keep track of deadlines.","difficulty":"Easy"},{"project_name":"Resources","summary":"A collection of links and resources for GSoC participants that includes the GSoC home page, OpenCV project pages, forums, and community channels for better collaboration.","difficulty":"Easy"},{"project_name":"OpenCV Project Ideas List","summary":"An extensive list of project ideas available for contributors, detailing each project‚Äôs description, expected outcomes, skills required, and other relevant information.","difficulty":"Medium"},{"project_name":"Multi-camera Calibration Techniques","summary":"Several project ideas include advanced multi-camera calibration methods aimed at improving user-friendliness and accuracy, showcasing skills in C++ and Python.","difficulty":"Medium-Difficult"},{"project_name":"Quantized Models for OpenCV Model Zoo","summary":"This project focuses on enhancing OpenCV's capabilities by adding optimized 8-bit models for various machine learning tasks to achieve faster inference.","difficulty":"Medium"},{"project_name":"Dynamic CUDA Support in DNN","summary":"To enhance the DNN (Deep Neural Network) module in OpenCV by making CUDA backend plugins dynamic, providing flexibility without the need to recompile OpenCV.","difficulty":"Hard"},{"project_name":"RISC-V Optimizations","summary":"This involves adding performance enhancements for OpenCV on a RISC-V architecture, focusing on efficient implementations for critical functions like convolution.","difficulty":"Hard"},{"project_name":"Computational Photography Algorithms","summary":"An initiative to improve image quality through advanced computational photography techniques such as denoising, white balance adjustments, and super-resolution methods.","difficulty":"Hard"},{"project_name":"Improving OpenCV's Security","summary":"This idea aims to integrate fuzz testing and sandboxing techniques to enhance the security of OpenCV, particularly in its image codecs and video I/O aspects.","difficulty":"Hard"},{"project_name":"Integrate Fractal ArUco and JuMarker into OpenCV","summary":"Involves incorporating new types of customizable fiducial markers to improve OpenCV's capabilities in marker detection and utilize unique designs for identification.","difficulty":"Medium"}],"jina_response":"Title: GSoC_2025\n\nURL Source: https://github.com/opencv/opencv/wiki/GSoC_2025\n\nMarkdown Content:\nOpenCV Google Summer of Code 2025\n---------------------------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#opencv-google-summer-of-code-2025)\n\n[Jump to Ideas List](https://github.com/opencv/opencv/wiki/GSoC_2025#opencv-project-ideas-list)\n-----------------------------------------------------------------------------------------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#jump-to-ideas-list)\n\n_Example use of computer vision:_ ![Image 1: Vision Transformer](https://camo.githubusercontent.com/602246aa899791d0d3f5811f7314047acfebabf812e5cd5c318512c540a4776b/68747470733a2f2f6c6561726e6f70656e63762e636f6d2f77702d636f6e74656e742f75706c6f6164732f323032332f30322f696d6167652d392e706e67)\n\n_[Parent of this page](https://github.com/opencv/opencv/wiki/OpenCV_GSoC)_ ¬† _[Last year's idea page](https://github.com/opencv/opencv/wiki/GSoC_2024)_ ¬† [_IDEAS LIST_ below](https://github.com/opencv/opencv/wiki/GSoC_2025#opencv-project-ideas-list)\n\n* * *\n\nOpenCV Accepted Projects:\n-------------------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#opencv-accepted-projects)\n\n[Mentor only list](https://groups.google.com/g/opencv_mentors)\n\n*   üöß **TBD** Spreadheet of projects link\n\n| Contributor | Title | Mentors | Passed |\n| --- | --- | --- | --- |\n\n* * *\n\n### Important dates:\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#important-dates)\n\n| Date (2025) | Description | Comment |\n| --- | --- | --- |\n| Jan 27 | Organization Applications Open | üëç |\n| Feb 11 | Org Application Deadline | üëç |\n| Feb 27 | Accepted Orgs Announced | üíØ |\n| Mar 24 | Contributor Proposals Open | üèÉ |\n| Apr 08 | Contributor Proposal Deadline |  |\n| Apr 29 | Contributor Ranking Deadline |  |\n| May 06 | Slot Allocation Deadline |  |\n| May 08 | Accepted Projects Announced |  |\n| May 8-Jun 1 | Bonding |  |\n| Jun 2 | Coding Starts |  |\n| jul 14-18 | Midterm Evals |  |\n| Aug 25-Sep 1 | Code in, Contrib Evals |  |\n| Sep 1-8 | Mentor Evals |  |\n| Nov 10 | Extended Contrib Evals |  |\n| Nov 17 | Extended Mentor Evals |  |\n\n[GSoC Timeline](https://developers.google.com/open-source/gsoc/timeline) ¬† [UTC time](https://time.is/UTC) ¬† [UTC time converter](http://www.timebie.com/std/gmt.php)\n\nResources:\n----------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#resources)\n\n*   [GSoC Home Page](https://summerofcode.withgoogle.com/)\n*   [**TBD:** GSoC OpenCV Project Page](https://summerofcode.withgoogle.com/)\n*   [Project Discussion List](https://groups.google.com/forum/#!forum/opencv-gsoc-202x) ¬† [Mentor List](https://groups.google.com/g/opencv_mentors)\n*   [OpenCV Home Site](https://opencv.org/) ¬† [OpenCV Wiki](https://github.com/opencv/opencv/wiki) ¬† [OpenCV Forum Q&A](https://forum.opencv.org/) ¬† [Developer meeting notes](https://github.com/opencv/opencv/wiki/2025)\n*   [How to do a pull request/How to Contribute Code](https://github.com/opencv/opencv/wiki/How_to_contribute)\n*   Source Code: [GitHub/opencv](https://github.com/opencv/opencv) and [GitHub/opencv\\_contrib](https://github.com/opencv/opencv_contrib)\n*   IRC Channel: [#opencv Libera.chat](https://web.libera.chat/#opencv), ¬† Slack: [https://open-cv.slack.com](https://open-cv.slack.com/)\n*   [**TBD:** OpenCV GSoC Dashboard](https://summerofcode.withgoogle.com/organizations/opencv/projects)\n\nOpenCV Project Ideas List:\n--------------------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#opencv-project-ideas-list)\n\n[Project Discussion list](https://groups.google.com/g/opencv-gsoc-202x)\n\n### Index to Ideas Below\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#index-to-ideas-below)\n\n1.  [Multi-camera calibration part 3](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-multi-camera-calibration-part-3)\n2.  [Multi-camera calibration test](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-Multi-camera-calibration-test)\n3.  [Multi-camera calibration toolbox](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-Multi-camera-calibration-toolbox)\n4.  [Quantized models for OpenCV Model Zoo](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-quantized-models-for-opencv-model-zoo)\n5.  [RISC-V Optimizations](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-risc-v-optimizations)\n6.  [Dynamic CUDA support in DNN](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-dynamic-cuda-support-in-dnn)\n7.  [Synchronized multi-camera video recorder](https://github.com/opencv/opencv/wiki/GSoC_2025#IDEA-Synchronized-multi-camera-video-recorder)\n8.  [libcamera back-end for VideoCapture](https://github.com/opencv/opencv/wiki/GSoC_2025#IDEA-libcamera-back-end-for-VideoCapture)\n9.  [Better LLMs support in OpenCV (1)](https://github.com/opencv/opencv/wiki/GSoC_2025#IDEA-Better-LLMs-support-in-OpenCV-1)\n10.  [Better LLMs support in OpenCV (2)](https://github.com/opencv/opencv/wiki/GSoC_2025#IDEA-Better-LLMs-support-in-OpenCV-2)\n11.  [Computational photography algorithms for better image quality](https://github.com/opencv/opencv/wiki/GSoC_2025#IDEA-Computational-photography-algorithms-for-better-image-quality)\n12.  [Improve OpenCV security](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-improve-opencvs-security)\n13.  [Integrate Fractal ArUco into OpenCV](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-integrate-fractal-aruco-into-opencv)\n14.  [Integrate JuMarker ArUco into OpenCV](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-Integrate-JuMarker-ArUco-into-OpenCV)\n\n[Idea Template](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-template)\n\nAll work is in C++ unless otherwise noted.\n\n* * *\n\nIdeas:\n------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#ideas)\n\n1.  #### _IDEA:_ Multi-camera calibration part 3\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-multi-camera-calibration-part-3)\n    \n    *   _**Description:**_ During GSoC 2023 a new cool [multi-camera calibration](https://github.com/opencv/opencv/wiki/GSoC_2023#idea-multi-camera-calibration-part-2) algorithm was improved: [https://github.com/opencv/opencv/pull/24052](https://github.com/opencv/opencv/pull/24052). This year we would like to finish this work with more test cases, tune the accuracy and build higher-level user-friendly tool (based on the script from the tutorial) to perform multi-camera calibration. If this is completed before the internship is up, then we'll move on to leveraging the IMU or marker-free calibration.\n    *   _**Expected Outcomes:**_\n        *   A series of patches with more unit tests and bug fixes for the multi-camera calibration algorithm\n        *   New/improved documentation on how to calibrate cameras\n        *   A short YouTube video showing off how to use the calibration routines\n    *   _**Skills Required:**_ Mastery of C++ and Python, mathematical knowledge of camera calibration, ability to code up mathematical models\n    *   _**Difficulty:**_ Medium-Difficult\n    *   _**Possible Mentors:**_ Maksym Ivashechkin, Alexander Smorkalov\n    *   _**Duration:**_ 175 hours\n2.  #### _IDEA:_ Multi-camera calibration test\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-multi-camera-calibration-test)\n    \n    *   _**Description:**_ We are looking for a student to curate best of class calibration data, collect calibration data with various OpenCV Fiducials, and graphically produce calibration board and camera models data (script). Simultaneously, begin to write comprehensive test scripts of all the existing calibration functions. While doing this, if necessary, improve the calibration documentation. Derive from this expected accuracy of fiducial types for various camera types.\n    *   _**Expected Outcomes:**_\n        *   Curate camera calibration data from public datasets.\n        *   Collect calibration data for various fiducials and camera types.\n        *   Graphically create camera calibration data with ready to go scripts\n        *   Write test functions for the OpenCV Calibration pipeline\n        *   New/improved documentation on how to calibrate cameras as needed.\n        *   Statistical analysis of the performance (accuracy and variance) of OpenCV fiducials, algorithms and camera types.\n        *   A YouTube video showing describing and demonstrating the OpenCV Calibration testss.\n    *   _**Resources:**_ [OpenCV Fiducial Markers](https://docs.opencv.org/5.x/d5/dae/tutorial_aruco_detection.html), [OpenCV Calibration Functions](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html), [OpenCV Camera Calibration Tutorial 1](https://docs.opencv.org/5.x/dc/dbb/tutorial_py_calibration.html), [OpenCV Camera Calibration Tutorial 2](https://docs.opencv.org/5.x/d4/d94/tutorial_camera_calibration.html)\n    *   _**Skills Required:**_ Mastery of C++ and Python, mathematical knowledge of camera calibration, ability to code up mathematical models\n    *   _**Difficulty:**_ Medium\n    *   _**Possible Mentors:**_ Jean-Yves Bouguet, Alexander Smorkalov\n    *   _**Duration:**_ 175 hours\n3.  #### _IDEA:_ Multi-camera calibration toolbox\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-multi-camera-calibration-toolbox)\n    \n    *   _**Description:**_ Build a higher-level user-friendly tool (based on the script from the calibration tutorial) to perform multi-camera calibration. This should allow easy multi-camera calibration with at multiple [Charco patterns](https://docs.opencv.org/4.x/da/d13/tutorial_aruco_calibration.html) and possibly other calibration fiducial patterns. The results will use Monte-Carlo sampling to determine parameter stability, allow easy switching of camera models and output the camera calibration parameters and the fiducial patterns pose in space as well as the extrinsic locations of each camera relative to the others.\n    *   _**Expected Outcomes:**_\n        *   Tool with convenient API that will be more or less comparable and compatible with Kalibr tool ([https://github.com/ethz-asl/kalibr](https://github.com/ethz-asl/kalibr))\n        *   New/improved documentation on how to calibrate cameras\n        *   A Youtube video demonstrating how to use the box\n    *   _**Skills Required:**_ Python, mathematical knowledge of camera calibration, ability to code up mathematical models\n    *   _**Difficulty:**_ Medium-Difficult\n    *   _**Possible Mentors:**_ Jean-Yves Bouguet, Gary Bradski\n    *   _**Duration:**_ 175 hours\n4.  #### _IDEA:_ Quantized models for OpenCV Model Zoo\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-quantized-models-for-opencv-model-zoo)\n    \n    *   _**Description:**_ Many modern CPUs, GPUs and specialized NPUs include special instructions and hardware blocks for accelerated inference, especially for INT8 inference. The models don't just become ~4x smaller compared to FP32 original models, the inference speed increases significantly (by 2x-4x or more) as well. The number of quantized models steadily increases, however, beyond image classification there are not so many 8-bit computer vision models with proven high-quality results. We will be interested to add to our model zoo ([https://github.com/opencv/opencv\\_zoo](https://github.com/opencv/opencv_zoo)) 8-bit models for object detection, optical flow, pose estimation, text detection and recognition etc.\n    *   _**Expected Outcomes:**_\n        *   Series of patches to OpenCV Zoo and maybe to OpenCV DNN (when OpenCV DNN misses 8-bit flavors of certain operations) to add the corresponding models.\n        *   If quantization is performed by student during the project, we will request the corresponding scripts to perform the quantization\n        *   Benchmark results to prove the quality of the quantized models along with the corresponding scripts so that we can reproduce it.\n    *   _**Skills Required:**_ very good ML engineering skills, good Python programming skills, familiarity with model quantization algorithms and model quality assessment approaches\n    *   _**Possible Mentors:**_ Feng Yuantao, Zhong Wanli, Vadim Pisarevsky\n    *   _**Difficulty:**_ Medium\n    *   _**Duration:**_ 90 to 175 hours, depending on the particular model.\n5.  #### _IDEA:_ RISC-V Optimizations\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-risc-v-optimizations)\n    \n    *   _**Description:**_ RISC-V is one of main target platforms for OpenCV. During past several years we brought in some RISC-V optimizations based on RISC-V Vector extension by adding another backend to _OpenCV scalable universal intrinsics_. We refactored a lot of code in OpenCV to make the vectorized loops compatible with RISC-V backend and more or less efficient. Still, we see a lot of gaps and the performance of certain functions can be further improved. For some critical functions, like convolution in deep learning, it makes sense perhaps to implement custom loops using native RVV intrinsics instead of using OpenCV scalable universal intrinsics. This is what we invite you to do.\n    *   _**Expected Outcomes:**_\n        *   A series of patches for core, imgproc, video and dnn modules to bring improved loops that use OpenCV scalable universal intrinsics or native RVV intrinsics to improve the performance. In the first case the optimizations should not degrade performance on other major platforms like x86-64 or ARMv8 with NEON.\n    *   _**Resources:**_\n        *   [OpenCV Wide Universal Intrinsics Guide](https://docs.opencv.org/master/df/d91/group__core__hal__intrin.html)\n        *   [Implementation of wide universal intrinsics for various platforms, including RISC-V](https://github.com/opencv/opencv/tree/master/modules/core/include/opencv2/core/hal)\n    *   _**Skills Required:**_ mastery plus experience coding in C++; good skills of optimizing code using SIMD.\n    *   _**Possible Mentors:**_ Mingjie Xing, Maxim Shabunin\n    *   _**Difficulty:**_ Hard\n    *   _**Duration:**_ 350 hours\n6.  #### _IDEA:_ Dynamic CUDA support in DNN\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-dynamic-cuda-support-in-dnn)\n    \n    *   _**Description:**_ OpenCV DNN module includes several backends for efficient inference on various platforms. Some of the backends are heavy and bring in a lot of dependencies, so it makes sense to make the backends dynamic. Recently, we did it with OpenVINO backend: [https://github.com/opencv/opencv/pull/21745](https://github.com/opencv/opencv/pull/21745). The goal of this project is to make CUDA backend of OpenCV DNN dynamic as well. Once it's implemented, we can have a single set of OpenCV binaries and then add the necessary plugin (also in binary form) to accelerate inference on NVidia GPUs without recompiling OpenCV.\n    *   _**Expected Outcomes:**_\n        *   A series of patches for dnn and maybe core module to build OpenCV DNN CUDA plugin as a separate binary that could be used by OpenCV DNN. In this case OpenCV itself should not have any dependency of CUDA SDK or runtime - the plugin should encapsulate it. It is fine if the user-supplied tensors (cv::Mat) are automatically uploaded to GPU memory by the engine (cv::dnn::Net) before the inference and the output tensors are downloaded from GPU memory after the inference in such a case.\n    *   _**Resources:**_\n    *   _**Skills Required:**_ mastery plus experience coding in C++; good practical experience in CUDA. Acquaintance with deep learning is desirable but not necessary, since the project is mostly about software engineering, not about ML algorithms or their optimization.\n    *   _**Possible Mentors:**_ Alexander Smorkalov\n    *   _**Difficulty:**_ Hard\n    *   _**Duration:**_ 350 hours\n7.  #### _IDEA:_ Synchronized multi camera video recorder\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-synchronized-multi-camera-video-recorder)\n    \n    *   _**Description:**_ Multi-camera calibration and multi-view scenarios require synchronous recording with multiple cameras. Need to tune cv::VideoCapture or/and VideoWriter and implement sample for video recording with several cameras with timestamps\n    *   _**Expected Outcomes:**_\n        *   Sync video recording sample for several cameras: V4L2, RTSP(?)\n    *   _**Resources:**_ [Overview](https://medium.com/inatech/synchronize-multiple-cameras-to-capture-at-the-same-time-c285b520bd87)\n    *   _**Skills Required:**_ C++\n    *   _**Possible Mentors:**_ Alexander S.\n    *   _**Difficulty:**_ Easy-Medium\n    *   _**Duration:**_ 175\n8.  #### _IDEA:_ libcamera back end for VideoCapture\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-libcamera-back-end-for-videocapture)\n    \n    *   _**Description:**_ Discussion: [#21653](https://github.com/opencv/opencv/issues/21653)\n    *   _**Expected Outcomes:**_\n        *   MIPI camera support on Raspberry Pi\n    *   _**Resources:**_\n        *   _**Skills Required:**_ C++, Linux\n        *   _**Possible Mentors:**_ TBD\n        *   _**Difficulty:**_ Medium\n        *   _**Duration:**_ 175\n9.  #### _IDEA:_ Better LLMs support in OpenCV (1)\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-better-llms-support-in-opencv-1)\n    \n    *   _**Description:**_ **L**arge **L**anguage **M**odel**s**, or LLM, are AI models designed to understand, generate and manipulate human language. One of the barrier to better support LLMs is tokenizer support. A tokenizer can break down raw text into smaller pieces (tokens), which are easier for models to understand and process. This project aims to integrate tokenizer in dnn module.\n    *   _**Expected Outcomes:**_ A patch that integrates tokenizer in dnn module\n    *   _**Resources:**_\n        *   Let's Build the GPT Tokenzier [https://youtu.be/zduSFxRajkE?si=JF725Ipnzc4R5Nnc](https://youtu.be/zduSFxRajkE?si=JF725Ipnzc4R5Nnc)\n        *   OpenAI's tokenizer [https://github.com/openai/tiktoken](https://github.com/openai/tiktoken)\n        *   Hugging Face's AutoTokenizer [https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization\\_auto.py](https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py)\n    *   _**Skills Required:**_ C++, Python, LLMs/Transformers\n    *   _**Mentor:**_ [Yuantao Feng](https://github.com/fengyuentau)\n    *   _**Difficulty:**_ Hard\n    *   _**Duration:**_ 175\n10.  #### _IDEA:_ Better LLMs support in OpenCV (2)\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-better-llms-support-in-opencv-2)\n    \n    *   _**Description:**_ LLMs support in OpenCV is unclear. One of the most key feature in the current dnn engine is fixed memory allocation after model importing, which helps speeding up model inference for CNNs but then becomes the limit of running LLMs that has flexible inputs. This project aims to try LLMs as many as possible with OpenCV, fix dnn engine to support more LLMs, and write demos to show LLMs inference with OpenCV.\n    *   _**Expected Outcomes:**_\n        *   Several patches that fix dnn engine to support more LLMs.\n        *   Several patches that add demos to show LLMs inference with OpenCV.\n    *   _**Resources:**_\n        *   GPT2 inference with OpenCV [https://github.com/opencv/opencv/blob/5.x/samples/dnn/gpt2\\_inference.py](https://github.com/opencv/opencv/blob/5.x/samples/dnn/gpt2_inference.py)\n        *   LLMs that llama.cpp supports [https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#description](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#description)\n    *   _**Skills Required:**_ C++, Python, LLMs/Transformers\n    *   _**Mentor:**_ [Yuantao Feng](https://github.com/fengyuentau)\n    *   _**Difficulty:**_ Hard\n    *   _**Duration:**_ 175\n11.  #### _IDEA:_ Computational photography algorithms for better image quality\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-computational-photography-algorithms-for-better-image-quality)\n    \n    *   _**Description:**_ Improving image quality is important task, which is still not covered well in OpenCV. We already have \"non-local means\" (photo module) and BM3D (opencv\\_contrib) denoising algorithms, simple white balance algorithms (opencv\\_contrib), very simple exposure correction function (equalizeHist in imgproc: grayscale images only) and function for distortion correction (undistort function in imgproc), that's it. The following could be useful to have:\n        \n        *   more efficient/better-quality denoising algorithms\n        *   vignetting correction\n        *   chromatic aberration correction\n        *   smarter white balance algorithms\n        *   exposure correction for color images\n        *   multi-frame (image burst) denoising\n        *   superresolution for still images and video\n        *   deblurring\n        *   color enhancement, defogging\n        *   etc.\n        \n        Note that:\n        \n        1.  this idea is not about any special effects, 'beautification' etc. It's about improving pure technical image quality\n        2.  the idea is quite big, applicant(s) may and probably should suggest to implement a subset of the above items, they can also add something on top (as long as note (a) above is taken into account).\n    *   _**Expected Outcomes:**_\n        \n        *   Several patches to opencv\\_photo module and/or opencv\\_contrib repo that add the new functionality, tests, samples etc.\n    *   _**Resources:**_\n        \n        *   TBD\n    *   _**Skills Required:**_ C++, Python\n        \n    *   _**Mentor(s):**_ Gursimar Singh, Vadim Pisarevsky as adviser.\n        \n    *   _**Difficulty:**_ Hard\n        \n    *   _**Duration:**_ 175\n        \n12.  #### _IDEA:_ Improve OpenCV's security\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-improve-opencvs-security)\n    \n    *   _**Description:**_ OpenCV can be better integrated with [https://oss-fuzz.com/](https://oss-fuzz.com/) to get better fuzzing, mostly by moving the tests to the OpenCV repository and writing more tests (especially for imgcodecs and videoio). Additionally, sandboxing could be integrated into OpenCV to make sure invalid inputs are safely discarded by integrating sandbox2.\n    *   _**Expected Outcomes:**_\n        *   Several patches that improve the oss-fuz integration.\n        *   Several patches that add an optional build of OpenCV with sandbox2 integrated for some functions.\n    *   _**Resources:**_\n        *   sandbox2 documentation [https://developers.google.com/code-sandboxing/sandbox2](https://developers.google.com/code-sandboxing/sandbox2)\n        *   fuzztest documentation [https://github.com/google/fuzztest](https://github.com/google/fuzztest)\n        *   ongoing PR for fuzztest integration: [https://github.com/opencv/opencv/pull/24193](https://github.com/opencv/opencv/pull/24193)\n    *   _**Skills Required:**_ C++\n    *   _**Mentor:**_ [Vincent Rabaud](https://github.com/vrabaud)\n    *   _**Difficulty:**_ Hard\n    *   _**Duration:**_ 175\n13.  #### _IDEA:_ Integrate Fractal ArUco into OpenCV\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-integrate-fractal-aruco-into-opencv)\n    \n    *   _**Description:**_ Fractal markers are a new concept of marker, which is composed of several fiducial square markers of different size inside. Unlike traditional fiducial markers, the structure of this marker can be detected from a large number of distances, as well as solve problems of partial or total occlusion of the marker.\n    *   _**Expected Outcomes:**_\n        *   Integrate Fractal ArUco into OpenCV with a simple API, which should be similar to the ArUco API currently in OpenCV.\n        *   Detailed documents for Fractal ArUco API in OpenCV\n        *   A nice demo to show how to use the algorithm.\n    *   _**Resources:**_ [Frictal ArUco](https://www.uco.es/investiga/grupos/ava/portfolio/fractal-markers/)\n    *   _**Skills Required:**_ C++, Python.\n    *   _**Mentor:**_ [Rafael Mu√±oz Salinas](https://www.uco.es/investiga/grupos/ava/miembros/prof-dr-rafael-munoz-salinas-phd/), [Shiqi Yu](https://faculty.sustech.edu.cn/yusq/en/)\n    *   _**Difficulty:**_ Easy\n    *   _**Duration:**_ 175 hours\n14.  #### _IDEA:_ Integrate JuMarker ArUco into OpenCV\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-integrate-jumarker-aruco-into-opencv)\n    \n    *   _**Description:**_ Fiducial markers such as QR codes, ArUco, and AprilTag have become very popular tools for labeling and camera positioning. They are robust and easy to detect, even in devices with low computing power. However, their industrial appearance deters their use in scenarios where an attractive and visually appealing look is required. In these cases, it would be preferable to use customized markers showing, for instance, a company logo. This work proposes a novel method to design, detect, and track customizable fiducial markers. Our work allows creating markers templates imposing few restrictions on its design, e.g., a company logo or a picture can be used. The designer must indicate positions into the template where bits will encode a unique identifier for each marker. Then, our method will automatically create a dictionary of markers, all following the same design, but each with a unique identifier.\n    *   _**Expected Outcomes:**_\n        *   Integrate JuMarker ArUco into OpenCV with a simple API, which should be similar to the ArUco API currently in OpenCV.\n        *   Detailed documents for Fractal ArUco API in OpenCV\n        *   A nice demo to show how to create a JuMarker and to detect it.\n    *   _**Resources:**_ [JuMarker ArUco](https://sourceforge.net/projects/jumarker/)\n    *   _**Skills Required:**_ C++, Python.\n    *   _**Mentor:**_ [Rafael Mu√±oz Salinas](https://www.uco.es/investiga/grupos/ava/miembros/prof-dr-rafael-munoz-salinas-phd/), [Shiqi Yu](https://faculty.sustech.edu.cn/yusq/en/)\n    *   _**Difficulty:**_ Hard\n    *   _**Duration:**_ 350 hours\n\n* * *\n\n### _Idea Template:_\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#idea-template)\n\n```\n1. #### _IDEA:_ <Descriptive Title>\n   * ***Description:*** 3-7 sentences describing the task\n   * ***Expected Outcomes:***\n      * < Short bullet list describing what is to be accomplished >\n      * <i.e. create a new module called \"bla bla\">\n      * < Has method to accomplish X >\n      * <...>\n   * ***Resources:***\n         * [For example a paper citation](https://arxiv.org/pdf/1802.08091.pdf)\n         * [For example an existing feature request](https://github.com/opencv/opencv/issues/11013)\n         * [Possibly an existing related module](https://github.com/opencv/opencv_contrib/tree/master/modules/optflow) that includes some new optical flow algorithms.\n   * ***Skills Required:*** < for example mastery plus experience coding in C++, college course work in vision that covers optical flow, python. Best if you have also worked with deep neural networks. >\n   * ***Mentor:*** < your name goes here >\n   * ***Difficulty:*** <Easy, Medium, Hard>\n   * ***Duration:*** <175 <normal> 350 <extended>>\n```\n\n* * *\n\n*   **All Ideas Above**\n    -------------------\n    \n    [](https://github.com/opencv/opencv/wiki/GSoC_2025#all-ideas-above)\n    \n    1.  #### Have these Additional Expected Outcomes:\n        \n        [](https://github.com/opencv/opencv/wiki/GSoC_2025#have-these-additional-expected-outcomes)\n        \n        *   Use the [OpenCV How to Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute) and see [Line Descriptor](https://github.com/opencv/opencv_contrib/tree/master/modules/line_descriptor) as a high quality finished example.\n        *   Add unit tests [described here](https://github.com/opencv/opencv/wiki/QA_in_OpenCV), see also the [Line Descriptor example](https://github.com/opencv/opencv_contrib/tree/master/modules/line_descriptor/test)\n        *   Add a tutorial, and sample code\n            *   see the [Line Descriptor tutorial](https://github.com/opencv/opencv_contrib/tree/master/modules/line_descriptor/tutorials) and how they [look on the web](https://docs.opencv.org/4.x/df/dfa/tutorial_line_descriptor_main.html).\n            *   See the [Line Descriptor samples](https://github.com/opencv/opencv_contrib/tree/master/modules/line_descriptor/samples)\n        *   Make a short video showing off your algorithm and post it to Youtube. [Here's an Example](https://www.youtube.com/watch?v=O5P65CYqo_Q).\n\n* * *\n\n**Contributors**\n----------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#contributors)\n\n**How to Apply**\n----------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#how-to-apply)\n\nThe process at Google is described at [GSoC home page](https://summerofcode.withgoogle.com/)\n\n**How contributors will be evaluated once working:**\n----------------------------------------------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#how-contributors-will-be-evaluated-once-working)\n\n*   Contributors will be paid only if:\n    *   **Phase 1:**\n        *   You must generate a pull request\n            *   That builds\n            *   Has at least stubbed out _(place holder functions such as just displaying an image)_ functionality\n            *   With OpenCV appropriate Doxygen documentation ([example tutorial](https://www.youtube.com/watch?v=TtRn3HsOm1s&ab_channel=Abdullah))\n                *   Includes What the function or net is, what the function or net is used for\n            *   Has at least stubbed out unit test\n            *   Has a stubbed out example/tutorial of use that builds\n                *   See [the contribution guild](https://github.com/opencv/opencv/wiki/How_to_contribute)\n                *   and [the coding style guild](https://github.com/opencv/opencv/wiki/Coding_Style_Guide)\n                *   the [line\\_descriptor](https://github.com/opencv/opencv_contrib/tree/master/modules/line_descriptor) is a good example of contribution\n    *   **Phase 2:**\n        *   You must generate a pull request\n            *   That builds\n            *   Has all or most of the planned functionality (but still usable without those missing parts)\n            *   With OpenCV appropriate Doxygen documentation\n                *   Includes What the function or net is, what the function or net is used for\n            *   Has some unit tests\n            *   Has a tutorial/sample of how to use the function or net and why you'd want to use it.\n        *   Optionally, but highly desirable: create a (short! 30sec-1min) Movie (preferably on Youtube, but any movie) that demonstrates your project. We will use it to create the final video:\n            *   [The 2021 Movie](https://www.youtube.com/watch?v=6He1Ay7hfQc)\n            *   [The 2020 Movie](https://youtu.be/ROGa2tutPHQ)\n            *   [The 2015 Movie](https://www.youtube.com/watch?v=OUbUFn71S4s)\n            *   [The 2014 Movie](https://www.youtube.com/watch?v=3f76HCHJJRA)\n            *   [The 2013 Movie](https://www.youtube.com/watch?v=_TTtN4frMEA)\n    *   **Extended period:**\n        *   TBD\n\n* * *\n\nMentors:\n--------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#mentors)\n\n1.  Contact us, preferably in February or early March, on the opencv-gsoc googlegroups mailing list above and ask to be a mentor (or we will ask you in some known cases)\n2.  If we accept you, we will post a request from the Google Summer of Code OpenCV project site asking you to join.\n3.  You must accept the request and **you are a mentor!**\n\n*   You will also need to get on:\n    *   [Mentor only list](https://groups.google.com/g/opencv_mentors)\n    *   [opencv-gsoc-202X mailing list](https://groups.google.com/g/opencv-gsoc-202x)\n\n4.  You then:\n    *   Look through the ideas above, choose one you'd like to mentor or create your own and post it for discussion on the mentor list.\n    *   Go to the opencv-gsoc googlegroups mailing list above and look through the project proposals and discussions. Discuss the ideas you've chosen.\n        *   Find likely contributors, ask them to apply to your project(s)\n    *   You will get a list of contributors who have applied to your project. Go through them and select a contributor or rejecting them all if none suits and joining to co-mentor or to quit this year are acceptable outcomes.\n        *   Make sure your contributors officially apply through the [Google Summer of Code site](https://summerofcode.withgoogle.com/) prior to the deadline as indicate by the Contributor Application Period in the [time line](https://github.com/opencv/opencv/wiki/GSoC_2025#important-dates)\n5.  Then, when we get a slot allocation from Google, the administrators _\"spend\"_ the slots in order of priority influenced by whether there's a capable mentor or not for each topic.\n6.  Contributors must finally actually accept to do that project (some sign up for multiple organizations and then choose)\n7.  Get to work!\n\n**If** you are accepted as a mentor **and** you find a suitable contributor **and** we give you a slot **and** the contributor signs up for it, **then** you are an actual mentor! Otherwise you are **not a mentor** and have no other obligations.\n\n*   Thank you for trying.\n*   You may contact other mentors and co-mentor a project.\n\nYou get paid a modest stipend over the summer to mentor, typically $500 minus an org fee of 10%.\n\nSeveral mentors donate their salary, earning ever better positions in heaven when that comes.\n\n#### Potential Mentors List:\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#potential-mentors-list)\n\n```\nAnkit Sachan\nAnatoliy Talamanov\nCl√©ment Pinard\nDavis King\nDmitry Kurtaev\nDmitry Matveev\nEdgar Riba\nGholamreza Amayeh\nGrace Vesom\nJiri H√∂rner\nJo√£o Cartucho\nJustin Shenk\nMichael Tetelman\nNingxin Hu\nRafael Mu√±oz Salinas\nRostislav Vasilikhin\nSatya Mallick\nStefano Fabri\nSteven Puttemans\nSunita Nayak\nVikas Gupta\nVincent Rabaud\nVitaly Tuzov\nVladimir Tyan\nYida Wang\nJia Wu\nYuantao Feng\nZihao Mu\n```\n\nAdmins\n------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#admins)\n\n```\nGary Bradski\nVadim Pisarevsky\nShiqi Yu\n```\n\nGSoC Org Application Answers\n----------------------------\n\n[](https://github.com/opencv/opencv/wiki/GSoC_2025#gsoc-org-application-answers)\n\n[Answers from our OpenCV GSoC application](https://github.com/opencv/opencv/wiki/OpenCV_GSoC_Application)\n"}