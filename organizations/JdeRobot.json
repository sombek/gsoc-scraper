{"name":"JdeRobot","description":"Toolkit for developing Robotics applications","gsoc_url":"https://summerofcode.withgoogle.com/programs/2025/organizations/jderobot","ideas_url":"https://jderobot.github.io/activities/gsoc/2025#ideas-list","logo":"https://summerofcode.withgoogle.com/media/org/jderobot/xwu8zkcagffmlqdj-360.png","technologies":["python","ros","gazebo","opencv","tensorflow"],"topics":["education","artificial intelligence","robotics","computer vision","developer tools"],"projects":[{"project_name":"Robotics-Academy: Support for ROS2 topics","summary":"Enhancement of the Robotics-Academy framework to allow exercises to utilize ROS2 interfaces, which strengthens coding skills in robotics for students unfamiliar with ROS.","difficulty":"Medium"},{"project_name":"Robotics-Academy: CI & Testing","summary":"Implementation of automated testing and continuous integration processes to improve software maintainability and reliability for the Robotics-Academy framework.","difficulty":"Medium"},{"project_name":"Robotics-Academy: Improve Computer Vision Exercises","summary":"Updating and creating new Computer Vision exercises in Robotics-Academy to include real camera support and learning foundations of image processing with OpenCV.","difficulty":"Easy"},{"project_name":"Robotics-Academy: End-to-End Visual Control Exercise","summary":"Develop a deep learning exercise for visual control of autonomous vehicles within the Robotics-Academy, including a web interface for model upload and simulation.","difficulty":"Medium"},{"project_name":"VisualCircuit: Improve Functionality & Block Library","summary":"Enhancing the VisualCircuit tool by refining existing features, expanding the block library, and making it more robust for creating robot applications visually.","difficulty":"Medium"},{"project_name":"Robotics Academy: Open3DEngine Integration","summary":"Integrate Open3DEngine as an alternative simulator in the Robotics-Academy framework, creating exercises that utilize this new engine.","difficulty":"Medium"},{"project_name":"Robotics Academy: Gazebo Improvement","summary":"Improving existing Gazebo scenarios and models in Robotics-Academy to make exercises more visually appealing while maintaining performance.","difficulty":"Easy"},{"project_name":"Robotics Academy: Industrial Robotics Exercises","summary":"Updating and refining industrial robotics exercises using MoveIt2 and ROS2 for enhanced support and new manipulation applications in Robotics-Academy.","difficulty":"Medium"},{"project_name":"BT-Studio: Behavior Trees Programming Tool","summary":"Development of a library and sample applications for programming robots using Behavior Trees, enhancing the existing BT-Studio tool.","difficulty":"Medium"},{"project_name":"Extend DetectionMetrics: GUI & CI","summary":"Revamped toolkit for evaluating perception models, aiming to restore lost features, enhance usability, and implement a GUI and CI workflow.","difficulty":"Medium"}],"jina_response":"Title: GSoC 2025\n\nURL Source: https://jderobot.github.io/activities/gsoc/2025\n\nMarkdown Content:\nSkip links\nSkip to primary navigation\nSkip to content\nSkip to footer\nJdeRobot\nProgramming Robot Intelligence\nProjects\nActivities\nCommunity\nAbout\nPROJECTS\nRobotics Education\nAI driven Robotics\nRobot Programming Tools\nACTIVITIES\nGoogle Summer of Code\nInternships\nRobotics courses\nTech Talks\nCompetitions\nCOMMUNITY\nContributors\nGSoC 2025\nTOC GSoC-2025\nIdeas list\nProject #1: Robotics-Academy: support for solutions directly using ROS2 topics\nProject #2: Robotics-Academy: CI & Testing\nProject #3: Robotics-Academy: improve Computer Vision exercises, including with real cameras\nProject #4: Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning\nProject #5: VisualCircuit: Improving Functionality & Expanding the Block Library\nProject #6: Robotics Academy: using the Open3DEngine as robotics simulator\nProject #7: Robotics Academy: improvement of Gazebo scenarios and robot models\nProject #8: Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2\nProject #9: BT-Studio: a tool for programming robots with Behavior Trees\nProject #10: Extend DetectionMetrics: GUI, CI Workflow, and Object Detection\nApplication instructions for GSoC-2025\nRequirements\nProgramming tests\nSend us your information\nPrevious GSoC students\nHow to increase your chances of being selected in GSoC-2025\nRTFM\n\nRobotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS…). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS2-Humble (and Gazebo Harmonic).\n\nOur community mainly works on three development areas:\n\nEducation in Robotics. RoboticsAcademy is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars…. It is a collection of Python programmed exercises and challenges for engineering students.\n\nRobot Programming Tools. For instance, BT-Studio, for robot programming with Behavior Trees; VisualCircuit for robot programming with connected blocks, as in electronic circuits, in a visual way.\n\nMachine Learning in Robotics. For instance, the BehaviorMetrics tool for assessment of neural networks in end-to-end autonomous driving. Another example is DetectionMetrics tool for evaluation of visual detection neural networks and algorithms.\n\nIdeas list\n\nThis open source organization welcomes contributors in these topics:\n\nProject #1: Robotics-Academy: support for solutions directly using ROS2 topics\n\nBrief explanation: Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS 2 or OpenCV.\n\nNowadays, Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. All of them come ready to use in the RoboticsAcademy docker image (RADI). The only requirement for the students its to download the docker image, all the dependencies are installed inside the RADI.\n\nCurrently, exercises can be solved using Python without any knowledge of ROS 2 thank to our Hardware Abstraction Layer (HAL). However, some students asked for the possibility to use (and learn) ROS 2 interfaces (topics and services) while coding the solution. Project #2 will explore new ways of coding the exercise solution, where a few changes like ROS 2 spin control or editor autocompletions are required.\n\nSkills required/preferred: React, Python, ROS2.\nDifficulty rating: medium\nExpected results: New way of coding your solutions in RoboticsAcademy using ROS 2 topics\nExpected size: 90h\nMentors: Pedro Arias (pedro.ariasp AT upm.es) and Apoorv Garg (apoorvgarg.ms AT gmail.com)\nProject #2: Robotics-Academy: CI & Testing\n\nBrief explanation: Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision.\n\nProject #2 seeks to identify and address potential issues early on, fostering the maintainability and reliability of its software. This commitment to improving the quality of the software will be achieved through the implementation of automated testing and continuous integration (CI) processes. The project will also include the development of a testing strategy and the implementation of a CI pipeline.\n\nSkills required/preferred: Docker, GitHub actions, Python, JavaScript, pytest, Selenium\nDifficulty rating: medium\nExpected results: Tests on RAM, RI and RA\nExpected size: 350h\nMentors: Pedro Arias (pedro.ariasp AT upm.es), Pawan Wadhwani (pawanw17 AT gmail.com) and Miguel Fernandez (miguel.fernandez.cortizas AT upm.es)\nProject #3: Robotics-Academy: improve Computer Vision exercises, including with real cameras\n\nBrief explanation: As of now, Robotics-Academy includes two deprecated Computer Vision exercises: ColorFilter and OpticalFlow Teleoperator. These exercises allow users to learn de foundations of image processing using OpenCV library. A Work-In-Progress from the JdeRobot Computer Vision Working Group is the multiplatform support of real cameras in RoboticsAcademy exercises (it works on Linux, Windows and MacOS machines), using WebRTC.\n\nThe main objective of this project is to prepare several exercises in RoboticsAcademy about Computer Vision (including the update of the previous two) which can be performed with real camera from the browser.\n\nSkills required/preferred: ComputerVision, OpenCV, React, Python\nDifficulty rating: easy\nExpected results: new exercises on ComputerVision in Robotics-Academy, including with real cameras.\nExpected size: 90h\nMentors: David Pascual (d.pascualhe AT gmail.com) and David Pérez (david.perez.saura AT upm.es)\nProject #4: Robotics-Academy: new exercise on End-to-End Visual Control of an Autonomous Vehicle using DeepLearning\n\nBrief explanation: The goal of this project is to develop a new deep learning exercise focused on visual robotic control in the context of Robotics-Academy. We will create a web-based interface that allows users to upload a trained model, which will take camera input from a drone or car and output the linear speed and angular velocity of the vehicle. The controlled robot and its environment will be simulated using Gazebo. The objectives of this project include:\n\nUpdating the web interface to accept models trained with PyTorch/TensorFlow.\nBuilding new widgets to monitor exercise results.\nPreparing a simulated environment.\nCoding the core application that feeds input data to the trained model and returns the results.\nTraining a naive model to demonstrate how the exercise can be solved.\n\nThis new exercise may utilize the infrastructure developed for the “Human detection” Deep Learning exercise. The following videos showcase one of our current web-based exercises and a visual control task solved using deep learning:\n\nSkills required/preferred: Python, Deep Learning, Gazebo, React, ROS2\nDifficulty rating: medium\nExpected results: a web-based exercise for robotic visual control using deep learning\nExpected size: 350h\nMentors: David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)\nProject #5: VisualCircuit: Improving Functionality & Expanding the Block Library\n\nBrief explanation: VisualCircuit allows users to program robotic intelligence using a visual language similar to electronic circuits, simplifying the creation of code for robotics applications such as Deep Learning, ROS, and more.\n\nOver the past few years, we have focused on making VisualCircuit more robust by resolving Nested Blocks (multi-level blocks) with the Block Composition feature, developing a working prototype for dockerized execution of robotics applications directly from the browser, migrating the old POSIX IPC implementation to a cross-platform compatible Python Shared Memory implementation, and more.\n\nNow, for GSoC 2025, the goal of the project is to further refine VisualCircuit by improving Shared Memory, Block Composition, and other features, developing more real-world robotics applications utilizing the latest functionalities of VC, expanding the block library to cater to a larger audience, and enhancing automated testing. Additionally, we aim to address other issues such as implementing Undo and Redo functionality, adding more keyboard shortcuts for faster circuit creation, and making various other improvements. You can read further about the tool on the website.\n\nSkills required/preferred: ROS2, Gazebo, Python, TypeScript\nDifficulty rating: medium\nExpected results: Expanding Block library for VisualCircuit, improving automated testing using GitHub Actions and creating real world robotics applications developed with latest functionalities of VC and resolving other major issues.\nExpected size: 175h\nMentors: Toshan Luktuke (toshan1603 AT gmail.com), Pankaj Borade and Suhas Gopal.\nProject #6: Robotics Academy: using the Open3DEngine as robotics simulator\nBrief explanation: Open 3D Engine (O3DE) is an Apache 2.0-licensed multi-platform 3D engine that enables developers and content creators to build AAA games, cinema-quality 3D worlds, and high-fidelity simulations. It supports also simulation of most common robot sensors and actuators. The idea of this project is to integrate Open3DEngine into the RoboticsAcademy framework, with at least one exercise using it instead of Gazebo.\nSkills required/preferred: C++ programming, ROS\nDifficulty rating: Medium\nExpected results: A new robotics exercise in RoboticsAcademy using the Open3DEngine\nExpected size: 175h\nRepository Link - Open 3D Engine, RoboticsAcademy, RoboticsInfrastructure\nMentors: José M. Cañas (josemaria.plaza AT gmail.com) and Jan Hanca ( jan.hanca AT googlemail.com )\nProject #7: Robotics Academy: improvement of Gazebo scenarios and robot models\n\nBrief Explanation: Currently Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. The main goal of this project is to improve the current Gazebo scenarios and robot models for many the exercises making them more appealing and realistic without increasing too much the required computing power for rendering. For instance the world model of the FollowLine exercise will be enhanced in order to have a 3D race circuit and several models will be reviewed to be low poly (= faster to simulate).\n\nSkills required/preferred: experience with Gazebo, SDF, URDF, ROS2 and Python\nDifficulty rating: easy\nExpected results: New Gazebo scenarios\nExpected size: small (~90h)\nMentors: Pedro Arias (pedro.ariasp AT upm.es) and Shashwat Dalakoti (shash.dal623 AT gmail.com)\nProject #8: Robotics Academy: improvement of industrial robotics exercises with MoveIt2 and ROS2\n\nBrief explanation: A few years ago we developed some exercises on industrial robots using MoveIt1 and ROS1-Noetic. A Work-In-Progress from the JdeRobot Industrial Robotics Working Group is the support in RoboticsAcademy to MoveIt2 and ROS2. A proof of concept has already been developed and it opens the door to new applications with manipulators (pick-and-place, palletizing…). Developing an easy API for the programming of industrial robots, similar to other solutions such as RAPID from ABB is an open topic. The main goal of this project is to integrate, refine this support and develop a new exercise regarding manipulation.\n\nSkills required/preferred: Gazebo, URDF, ROS2, MoveIt2\nDifficulty rating: medium\nExpected results: updated and operating new exercise on industrial robot manipulation\nExpected size: medium (~175h)\nMentors: Diego Martín (diego.martin.martin AT gmail.com) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)\nProject #9: BT-Studio: a tool for programming robots with Behavior Trees\n\nBrief explanation: Behavior Trees is a recent paradigm for organizing robot deliberation. There are brilliant open source projects such as BehaviorTrees.CPP and PyTrees. Our BT-Studio has been created to provide a web based graphical editor of Behavior Trees. It also includes a conversor to Python language, the dockerized execution of the generated robotics application from the browser and supports subtrees (a feature created along a previous GSoC-2024 project).\n\nThe goal of this GSoC proposed project is to develop a Behavior Tree library, a collection of example robotics applications and further refine the tool.\n\nSkills required/preferred: Python, ROS, Gazebo\nDifficulty rating: medium\nExpected results: Behavior Trees library for BT-Studio and several example robotics applications developed with them.\nExpected size: 175h\nMentors: José M. Cañas (josemaria.plaza AT gmail.com) and Oscar Martínez (oscar.robotics AT tutanota.com)\nProject #10: Extend DetectionMetrics: GUI, CI Workflow, and Object Detection\n\nBrief explanation: DetectionMetrics is a toolkit for evaluating perception models across frameworks and datasets. Past GSoC projects (Vinay Sharma, Jeevan Kumar) contributed to its first stable release, published in Sensors (Paniego et al., 2022). Recently, we revamped the tool to improve usability and installation—check it out here! Currently, DetectionMetrics functions as both a Python library and CLI, focusing on the quantitative evaluation of image and LiDAR segmentation models, with plans to expand into object detection. It supports PyTorch and TensorFlow models, along with multiple public datasets. Its modular design allows easy integration of new models and datasets. While redesigning the core functionality, some useful features were lost. This project aims to bring them back and enhance DetectionMetrics by:\n\nRecovering object detection evaluation support, including metrics like mAP and IoU. This involves restoring compatibility with COCO-style and Pascal VOC-style datasets and implementing necessary pipeline adjustments.\nBuilding a GUI for visualizing dataset samples (images, point clouds) and evaluation results (IoU, confusion matrices, etc.). Ideally, it will also provide an interactive interface for launching batched evaluation jobs. Possible tools: Streamlit, Gradio.\nSetting up a Continuous Integration (CI) workflow to automate testing, documentation generation, and versioning using Sphinx, pytest, and GitHub Actions.\n\nSince this new version of DetectionMetrics is still in its early stages, your contributions will have a lasting impact on a tool already featured in a scientific journal!\n\nSkills required/preferred: Python, GitHub Actions, PyTorch, Deep Learning\nDifficulty rating: Medium\nExpected results: A brand-new GUI and CI workflow for DetectionMetrics\nExpected size: Long (~350h)\nMentors: David Pascual Hernández (d.pascualhe AT gmail.com), Sergio Paniego (sergiopaniegoblanco AT gmail.com), Santiago Montiel Marín (santiago.montiel AT uah.es)\nApplication instructions for GSoC-2025\n\nWe welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send a message to jderobot AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal.\n\nRequirements\nGit experience\nC++ and Python programming experience (depending on the project)\nProgramming tests\nProject\t#1\t#2\t#3\t#4\t#5\t#6\t#7\t#8\t#9\t#10\t#11\nAcademy (A)\tX\tX\tX\tX\tX\tX\tO\tX\tX\tX\tX\nPython (B)\tX\tX\tX\tX\tX\tX\tX\tX\tX\tX\tX\nROS2 (C)\tX\tX\tO\tX\tX\tX\tX\t-\t-\tX\t*\nReact (D)\tO\tO\tX\tO\tO\tX\t*\t-\t-\tO\tO\n\n\n\n\nWhere:\t \n*\tNot applicable\nX\tMandatory\nO\tOptative\n\nBefore accepting any proposal all candidates have to do these programming challenges:\n\n(A) RoboticsAcademy challenge\n(B) Python challenge\n(C) ROS2 challenge\n(D) React challenge\nSend us your information\n\nAFTER doing the programming tests, fill this web form with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this:\n\nContact details\nName and surname:\nCountry:\nEmail:\nPublic repository/ies:\nPersonal blog (optional):\nTwitter/Identica/LinkedIn/others:\nTimeline\nNow split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc.\nDo you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job?\nDo you have any known time conflicts during the official coding period?\nStudies\nWhat is your School and degree?\nWould your application contribute to your ongoing studies/degree? If so, how?\nProgramming background\nComputing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.\nRobot or Computer Vision programming experience:\nOther software programming:\nGSoC participation\nHave you participated to GSoC before?\nHow many times, which year, which project?\nHave you applied but were not selected? When?\nHave you submitted/will you submit another proposal for GSoC 2025 to a different org?\nPrevious GSoC students\nPawan Wadhwani (GSoC-2023) Robotics Academy: migration to ROS2 Humble\nMeiqi Zhao (GSoC 2023) Obstacle Avoidance for Autonomous Driving in CARLA Using Segmentation Deep Learning Models\nSiddheshsingh Tanwar (GSoC 2023) Dockerization of Visual Circuit\nPrakhar Bansal (GSoC 2023) RoboticsAcademy: Cross-Platform Desktop Application using ElectronJS\nApoorv Garg (GSoC-2022) Improvement of Web Templates of Robotics Academy exercises\nToshan Luktuke (GSoC-2022) Improvement of VisualCircuit web service\nNikhil Paliwal(GSoC-2022) Optimization of Deep Learning models for autonomous driving\nAkshay Narisetti(GSoC-2022) Robotics Academy: improvement of autonomous driving exercises\nPrakarsh Kaushik(GSoC-2022) Robotics Academy: consolidation of drone based exercises\nBhavesh Misra (GSoC-2022) Robotics Academy: improve Deep Learning based Human Detection exercise\nSuhas Gopal (GSoC-2021) Shifting VisualCircuit to a web server\nUtkarsh Mishra (GSoC-2021) Autonomous Driving drone with Gazebo using Deep Learning techniques\nSiddharth Saha (GSoC-2021) Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2\nShashwat Dalakoti (GSoC-2021) Robotics-Academy: exercise using Deep Learning for Visual Detection\nArkajyoti Basak (GSoC-2021) Robotics Academy: new drone based exercises\nChandan Kumar (GSoC-2021) Robotics Academy: Migrating industrial robot manipulation exercises to web server\nMuhammad Taha (GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.\nSakshay Mahna (GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.\nShreyas Gokhale (GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.\nYijia Wu (GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.\nDiego Charrez (GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.\nNikhil Khedekar (GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy\nShyngyskhan Abilkassov (GSoC-2019) Amazon warehouse exercise on JdeRobot Academy\nJeevan Kumar (GSoC-2019) Improving DetectionSuite DeepLearning tool\nBaidyanath Kundu (GSoC-2019) A parameterized automata Library for VisualStates tool\nSrinivasan Vijayraghavan (GSoC-2019) Running Python code on the web browser\nPankhuri Vanjani (GSoC-2019) Migration of JdeRobot tools to ROS 2\nPushkal Katara (GSoC-2018) VisualStates tool\nArsalan Akhter (GSoC-2018) Robotics-Academy\nHanqing Xie (GSoC-2018) Robotics-Academy\nSergio Paniego (GSoC-2018) PyOnArduino tool\nJianxiong Cai (GSoC-2018) Creating realistic 3D map from online SLAM result\nVinay Sharma (GSoC-2018) DeepLearning, DetectionSuite tool\nNigel Fernandez GSoC-2017\nOkan Asik GSoC-2017, VisualStates tool\nS.Mehdi Mohaimanian GSoC-2017\nRaúl Pérula GSoC-2017, Scratch2JdeRobot tool\nLihang Li: GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction\nAndrei Militaru GSoC-2015, interoperation of ROS and JdeRobot\nSatyaki Chakraborty GSoC-2015, Interconnection with Android Wear\nHow to increase your chances of being selected in GSoC-2025\n\nIf you put yourself in the shoes of the mentor that should select the student, you’ll immediately realize that there are some behaviors that are usually rewarded. Here’s some examples.\n\nBe proactive: Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a bad idea to just submit your idea only in the Google web site without discussing it, because it won’t be noticed.\n\nDemonstrate your skills: Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch submitting your PullRequest, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code.\n\nDemonstrate your intention to stay: Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won’t be maintained. And moreover, one scope of GSoC is to bring new developers to the community.\n\nRTFM\n\nRead the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already!\n\nFull documentation about GSoC on official website.\nFAQ from GSoC web site.\nIf you are new to JdeRobot, take the time to familiarize with the JdeRobot.\nTWITTER GITHUB YOUTUBE LINKEDIN FEED\n© 2025 Non-profit Association of Robotics and Artificial Intelligence JdeRobot. G88145909. Alcorcón. Madrid.\nPowered by Jekyll & Minimal Mistakes. Modified by Nacho Arranz & Vanessa Fernandez.\n"}