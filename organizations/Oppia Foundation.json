{"name":"Oppia Foundation","description":"Free platform for interactive, tutor-like lessons","gsoc_url":"https://summerofcode.withgoogle.com/programs/2025/organizations/oppia-foundation","ideas_url":"https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list","logo":"https://summerofcode.withgoogle.com/media/org/oppia-foundation/nqvgy9fm3aqshwtv-360.png","technologies":["python","google app engine","angular","typescript","Apache Beam"],"topics":["education","web","ai","nonprofit","social impact"],"projects":[{"project_name":"Flashbacks","summary":"This project introduces 'flashbacks' functionality in Oppia that redirects learners back to earlier concepts directly related to misconceptions without requiring them to re-answer all prior questions. It aims to enhance the learning experience by making navigations more intuitive while also improving the UI for submitted answers.","difficulty":"Moderate"},{"project_name":"Platform parameters dashboard","summary":"This project entails creating a developer-only UI that displays platform parameters and feature flags, allowing developers to check their statuses, manipulate values, and enforce overrides, thereby enhancing the manageability of new features under development.","difficulty":"Moderate"},{"project_name":"Acceptance tests","summary":"This project focuses on ensuring critical user journeys (CUJs) within Oppia's web application are covered by acceptance tests. It includes tightening existing testing functions, writing new tests, and organizing them to improve test coverage and facilitate audits of user journeys.","difficulty":"Easy / Moderate"},{"project_name":"Standardize and validate domain objects and storage models","summary":"The goal of this project is to validate Oppia's production data and ensure all models are consistent by implementing audits and setting up validation jobs, addressing any errors found to mitigate future issues for new data.","difficulty":"Moderate"},{"project_name":"Consolidate entity migration jobs","summary":"This project intends to standardize migration jobs across various model types within Oppia, simplifying the upgrade process and ensuring consistency in how data is migrated and managed by introducing a common class structure for these jobs.","difficulty":"Moderate"},{"project_name":"Lesson player redesign","summary":"This project aims to redesign the lesson player for Oppia to enhance user engagement and intuitive navigation, facilitating a better experience for learners accessing educational content.","difficulty":"Hard"},{"project_name":"AI-powered translation suggestions","summary":"This project seeks to integrate AI-generated translation suggestions into Oppia's Contributor Dashboard, improving translation efficiency and accuracy, while allowing easy manual edits by reviewers.","difficulty":"Hard"},{"project_name":"Clean up the structure for study guides and worked examples","summary":"This project focuses on improving the structure of study guides and examples in Oppia's backend, making it easier to translate and display content while enhancing user experience.","difficulty":"Moderate/Hard"}],"jina_response":"Title: Google Summer of Code 2025\n\nURL Source: https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025\n\nMarkdown Content:\n**Important**: _We are making some changes to how we run GSoC for 2025. Please read this page carefully, since some things have changed from previous years._\n\nTable of Contents\n-----------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#table-of-contents)\n\n*   [Getting started](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#getting-started)\n*   [FAQs](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#faqs)\n*   [Dates and Deadlines](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#dates-and-deadlines)\n*   [Types of work related to Oppia projects](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#types-of-work-related-to-oppia-projects)\n*   [GSoC proposal template](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#gsoc-proposal-template)\n    *   [Tips for writing a good project plan](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#tips-for-writing-a-good-project-plan)\n    *   [What should applicants expect from mentors in a proposal review?](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#what-should-applicants-expect-from-mentors-in-a-proposal-review)\n*   [Selection Criteria](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#selection-criteria)\n*   [Communication](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#communication)\n*   [Oppia's Project Ideas List](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list)\n\nOppia is planning to participate in [Google Summer of Code 2025](https://summerofcode.withgoogle.com/)! GSoC is a global program which offers post-secondary students, as well as newcomers to open source, an opportunity to discover and work with open source organizations. The contributions are supported by a stipend. Contributors work closely with one or more mentors to implement either a project idea by the organization, or a proposal of their own.\n\nIn order to receive updates about GSoC at Oppia, please subscribe to the [Oppia GSoC Announce](https://groups.google.com/g/oppia-gsoc-announce) mailing list, as well as the [Developer Announcements](https://github.com/oppia/oppia/discussions/categories/developer-announcements) category on GitHub Discussions.\n\nThis year, based on previous years' feedback, Oppia plans to follow a slightly extended GSoC timeline: projects will have 7 weeks for each milestone, with an additional \"holiday week\" between the milestones. Each milestone includes 5 weeks of coding time, 1 week for evaluations, and 1 week for fixes, as well as a product demo session after the 4th coding week. Please refer to the [Dates and Deadlines](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#dates-and-deadlines) section below for more details.\n\nAlso, please note that acceptance into GSoC isn't a prerequisite for becoming an Oppia contributor. The Oppia project is run by a global community dedicated to making meaningful social change, and we warmly welcome anyone who'd like to help out! You can get started by following the instructions here ([Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)).\n\nContributors\n------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#contributors)\n\nGSoC is an excellent opportunity for new contributors to get paid to work on an open source project. If you're interested in applying as a contributor, we strongly recommend reading this entire wiki page, including our [FAQ](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#faqs) which answers many of the common questions we receive.\n\nYou should also definitely read the following resources:\n\n*   [Google Summer of Code contributor guide](https://google.github.io/gsocguides/student/)\n*   [Google's list of resources](https://developers.google.com/open-source/gsoc/resources/)\n*   [Google's GSoC FAQ](https://developers.google.com/open-source/gsoc/faq)\n\nFurthermore, note that GSoC isn't just about code -- it's also about communication and interaction with the open source community! Hear what some of our previous contributors have to say:\n\n*   _I learnt a lot from this organisation -- tackling a huge codebase, writing clean and efficient code and communication._\n*   _I learn a lot of things in Oppia which I didn't learn in my school and college. It's not necessary that only a software engineer can contribute, anyone can contribute to Oppia with his/her skill._\n*   _I like the fact that the maintainers are so sincere in their work and are very responsive._\n*   _Oppia Foundation is really awesome and I get to interact with amazing people and learn a lot. The best part is that everything is organised really well and that makes it easy to solve my issues._\n*   _The Oppia Foundation excelled in fostering a supportive and inclusive environment for contributors. The responsiveness of the mentors and the community was remarkable, making it easy to seek guidance and get help whenever needed. The clear communication, structured processes, and well-documented codebase greatly helped my learning and development throughout GSoC._\n*   _I really enjoyed the process, and the feeling of owning a feature end-to-end is fantastic, even with the challenges. Over the past three months, I've learned a lot about feature testing, release testing, PM demos, and more._\n\nYou might also enjoy the \"weekly journals\" from some of our previous contributors: **[Rd4dev](https://medium.com/@rd4dev)** and **[@theMr17](https://medium.com/@Mr_17)**.\n\nGetting started\n---------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#getting-started)\n\nWelcome! If you're interested in applying to work with Oppia for GSoC, please follow these steps:\n\n1.  Sign up to the [oppia-gsoc-announce@](https://groups.google.com/forum/#!forum/oppia-gsoc-announce) mailing list and the [Developer Announcements](https://github.com/oppia/oppia/discussions/categories/developer-announcements) category on GitHub Discussions, so that you can receive important notifications about Oppia's participation in GSoC. Make sure to set your preferences correctly so that you actually get the emails!\n    \n2.  Get a better understanding of what Oppia is about:\n    \n    *   Read the [user documentation](http://oppia.github.io/#/) to become familiar with important concepts like explorations and interactions.\n    *   Play some lessons on [Oppia.org](https://www.oppia.org/learn/math), which hosts a live instance of Oppia.\n3.  To get started with development, read and follow the instructions in the contributors' guide carefully ([Oppia Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Oppia Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)). If you're interested in Oppia Web, you might also find [these tutorials](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#developing-your-skills) helpful.\n    \n4.  Do a few starter projects to become familiar with the contribution process. This will help us get an idea of what it's like to work with you. It will also help you get a better understanding of the codebase and our development process, which may help with writing a good project proposal. Once you've merged at least 2 pull requests, you will get an invitation to become a collaborator to the Oppia repository and be officially onboarded! **This step is a prerequisite to applying for GSoC.**\n    \n\nNote\n\nYou must be onboarded to the repository to which you will contribute during GSoC. For example, to work on an Oppia Web GSoC project, you need to be onboarded to the oppia/oppia repository, which means that your 2 pull requests need to be to oppia/oppia.\n\nTip\n\nQuality is more important than quantity, so try to contribute to high-impact issues where possible. Also, we want to see examples of your best work, so please make sure to read the [\"getting started\" guide](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia) and [PR instructions](https://github.com/oppia/oppia/wiki/Rules-for-making-PRs) carefully, follow the [tips for success](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#tips-for-success), manually test your code before submitting (to ensure it does what you want it to and doesn't break anything else), ensure that your code conforms to the [style rules](https://github.com/oppia/oppia/wiki/Coding-style-guide), and pay attention to small details. These are good skills to learn when developing software in general, and they will also help you build credibility as a responsible developer who can be trusted to be a good steward of the Oppia codebase.\n\n5.  Select one or more [GSoC project ideas](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list) that you're most interested in, and write your project proposal! You can get feedback from project mentors when you've completed a sufficient draft -- see the instructions in the [GSoC proposal template](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#gsoc-proposal-template) section for details.\n    \n    We require that all general discussion about GSoC projects take place in open channels. If you have questions about a project, you can ask in [GitHub Web Discussions](https://github.com/oppia/oppia/discussions/categories/gsoc-2025-q-a) or [GitHub Android Discussions](https://github.com/oppia/oppia-android/discussions/categories/general-gsoc-q-a). Note that individual projects have their own categories, so please use those if you have project-specific questions. Please also be specific when asking questions, since this makes it easier for us to help you.\n    \n\nTip\n\nDuring the application period, your first goal should be to figure out how to become an effective contributor. Start developing your project proposal only once you have experience getting some PRs merged. This will give you a much better idea of what you want to work on, and how much you can accomplish.\n\nGood luck!\n\nFAQs\n----\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#faqs)\n\n**Q: What technical skills do I need to work on Oppia?**\n\nA: Please see the individual project ideas to determine which skills are recommended for the project in question. Also, in general:\n\n*   For Oppia Web, Angular 2+, Python 3.9, Google App Engine and Apache Beam are useful and recommended, and experience with Docker and GitHub Actions is useful for developer workflow projects. Also, it is important to be able to write tests for the code you submit (using Karma, Webdriverio and unittest). You might also find this [page of learning resources](https://github.com/oppia/oppia/wiki/Learning-Resources) helpful, as well as other pages on our [wiki](https://github.com/oppia/oppia/wiki) that provide guidance on Apache Beam, testing frameworks, etc.\n    \n*   For Oppia Android, you will need to know how to program in Kotlin, and have experience with Android development. Knowledge of Bazel may also be helpful for some projects.\n    \n*   Note that, although GSoC is aimed at both students and beginner contributors to open source, \"beginner to open source\" is **not** the same as \"beginner to coding\" -- the projects do assume that you have some proficiency with coding. The fact that GSoC projects produce high-quality code that solves real problems for open-source projects does make GSoC challenging, but this is also part of what makes GSoC such a valuable experience for students.\n    \n\n**Q: How can I increase my chances of getting selected?**\n\nA: The most important thing is to ensure that you have the required skills for the project -- see the \"Required Skills\" section of the [proposal template](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#gsoc-proposal-template) for more details. Aside from that, writing a good project proposal with a solid solution approach, engaging with the community, helping other contributors, successfully contributing PRs for high-priority issues, and demonstrating that you can work independently can all help you. We've also compiled some notes below on the [selection criteria](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#selection-criteria) we'll be using this year.\n\n**Q: Can you be flexible around my other commitments in the summer?**\n\nA: Probably not. We have not had good experiences offering flexibility in previous years, so this year, Oppia will strictly adhere to the Oppia GSoC timeline. Please refer to the [Dates and Deadlines](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#dates-and-deadlines) section below, and avoid taking up major commitments alongside GSoC. Experience from previous years suggests that you will be unlikely to successfully balance both.\n\n**Q: I do not have any experience in skill XYZ. What should I do?**\n\nA: If you are missing a skill that is needed for a project, we recommend trying to learn it -- in software development, it is common to develop experience and expertise as you take up and complete projects successfully. Some ways to do this include working on issues that give you a chance to develop that skill, referring to our wiki documentation, and following tutorials from elsewhere on the Web. Please note that, in general, we are unlikely to accept applicants who lack the required skills for a project, since this tends to result in significant difficulties during the coding phase.\n\n**Q: How will you assess whether I have the required skills for a project?**\n\nWe will assess your application based on your proposal and the skills that you have demonstrated in your PRs and other interactions with the community. Please see the guidance in the \"Required Skills\" section of the [proposal template](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#gsoc-proposal-template), which explains how to demonstrate that you have the required skills for a project, and provides pointers on how to develop those skills.\n\n**Q: Is it okay if I only focus on the frontend or backend?**\n\nA: This probably depends on the project(s) you wish to apply for. However, note that most projects are full-stack and require ability in both the frontend and backend. We recommend becoming familiar with both of these, since this will open up more opportunities for you, as the projects we work on at Oppia often touch multiple layers of the stack.\n\n**Q: What is the minimum number of PRs that one should have?**\n\nA: You should have at least 2 merged PRs. Beyond that, remember that quality is more important than quantity, so consider taking some high-priority or [\"impact: high\"](https://github.com/oppia/oppia/issues?q=is%3Aopen+is%3Aissue+label%3A%22Impact%3A+High%22) issues if you're able to, since those fixes are more valuable. You can find a list of high-priority issues on the respective teams' project boards: [LaCE](https://github.com/orgs/oppia/projects/3/views/8), [Dev Workflow](https://github.com/orgs/oppia/projects/8/views/11), [Contributor Dashboard](https://github.com/orgs/oppia/projects/18/views/4), [Android CLaM](https://github.com/orgs/oppia/projects/4/views/3), [Android Dev Workflow](https://github.com/orgs/oppia/projects/10/views/1). Additionally, you'll also want to demonstrate that you have the required skills to successfully complete your chosen project; please see the guidance in the \"Required Skills\" section of the [proposal template](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#gsoc-proposal-template), which explains how to do this.\n\n**Q: Will I be penalized during selection if I ask for help while contributing?**\n\nA: Not at all! Asking for help when you need it is part of the learning process, and the Oppia open-source community is more than happy to help and onboard new members. Please just ensure that your questions are well-formed and that you (a) have read the relevant docs on the wiki, (b) provide the necessary information (such as a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs)) to help responders understand what you've figured out so far and where you are stuck.\n\n**Q: I only discovered Oppia recently. Does this mean that, during selection, my application would automatically be ranked lower than those by other applicants who have a longer tenure with Oppia?**\n\nA: Definitely not! Here are the [selection criteria](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#selection-criteria) we use when selecting contributors for GSoC. Note that tenure is explicitly not part of these criteria.\n\n**Q: How early should I start working on the proposal?**\n\nA: We recommend developing your project proposal and engaging with the community as early as possible, so that you have enough time to get feedback from mentors and improve the proposal before the submission deadline. Make sure to follow all instructions in the [proposal template](https://docs.google.com/document/d/1BIvB0Pt_KCAD17wFS1viOTfZiehBuEJOO1GeypezdkY/edit) (especially around sharing and access) to reduce delays in reviewing your proposal. That said, it's important to note that the proposal is only one part of the application process, and it is probably more important to figure out how to become an effective contributor by getting some PRs merged and demonstrating that you have the required skills for the project.\n\n**Q: Can I submit more than one proposal to Oppia?**\n\nA: Yes, you can. However, we strongly recommend picking one project and writing a solid proposal for it. Splitting attention across multiple projects might not be a great idea. (That said, GSoC is offering projects of multiple lengths, and if you're interested in doing either the 'full version' or the 'half version' of a project idea that can support both modes, you can submit **both** the 'full version' and the 'half version' as separate applications. Just make sure that you'd be happy with either outcome if you are selected!)\n\n**Q: Can I use content from the project ideas list or PRD in my proposal?**\n\nA: It is fine for proposals to draw from the GSoC idea in the wiki and any linked PRDs. However, please note that if you copy content directly from any source (even if it is an Oppia doc), **you must cite and link to the original source**. Also, remember from our [selection criteria](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#selection-criteria) that when we review proposals, one of the things we look for is evidence that the applicant understands the project and existing codebase well. Strong proposals will therefore contain details that are original (e.g. that are not copied from the PRD).\n\n**Q: I'm part of team X in Oppia. Can I submit a proposal for a project idea from a different team?**\n\nA: Yes, you can; there are no issues with that. There is a space in the proposal template to list teams at Oppia you've participated in, and we will get feedback from members of those teams about what their experience of collaborating with you has been like.\n\n**Q: What is the total number of contributors that will be accepted?**\n\nA: We generally request slots for as many projects as we think will succeed. However, the Google GSoC admins may impose limits based on how they decide to distribute contributor slots among the different open-source organizations.\n\n**Q: Which projects are most important for Oppia?**\n\nA: All the projects we've listed in the [Ideas List](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list) are important, and we'd be very happy to see good progress made on any of them! Projects are treated as equally important during selection; note that the relative importance of a project to Oppia is not part of the [selection criteria](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#selection-criteria). We strongly encourage you to pick a project that you'd enjoy doing over the summer!\n\n**Q: The [Google GSoC FAQ](https://developers.google.com/open-source/gsoc/faq#can_someone_already_participating_in_open_source_be_a_gsoc_contributor) mentions that the program is only for new contributors. I have already contributed to Oppia and I have write access. Can I still participate?**\n\nA: The GSoC program is open to students, as well as beginner contributors to open source. If you do not qualify as a student, see [this FAQ](https://developers.google.com/open-source/gsoc/faq#how_do_i_know_if_i_am_considered_a_beginner_in_open_source_development) on the GSoC website for whether you would be considered a beginner.\n\n**Q: I'd love to contribute to open source, but I'm not sure I have enough time during the summer to do a GSoC project. Can I still help out?**\n\nA: Yes, GSoC is probably not the best choice if you don't have enough time during the summer, since it requires focused commitment. However, you can still start contributing to Oppia by following the instructions in the contributors' guide ([Oppia Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Oppia Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)).\n\nDates and Deadlines\n-------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#dates-and-deadlines)\n\nNoteworthy dates for 2025 (see also the [Official GSoC Timeline](https://developers.google.com/open-source/gsoc/timeline)):\n\n*   **Jan 27 - Feb 11**: Mentoring organizations apply\n*   **Feb 27**: Mentoring organizations are announced\n*   **Mar 1**: [GSoC Q&A session with Oppia](https://calendar.app.google/5jPfYs3oaoy2o8zx8)\n*   **Mar 24 - Apr 8**: GSoC contributor application period\n*   **May 8**: Accepted GSoC contributors are announced\n*   **May 8 - June 1**: Community bonding (\"greenlight\") period\n*   **June 2 - Jul 18**: Milestone 1 work period for GSoC\n    *   **Jul 4**: Milestone 1 work due for internal evaluation\n    *   **Jul 5 - Jul 11**: Testing of the milestone 1 work product\n    *   **Jul 12 - Jul 18**: Buffer time for Milestone 1 revisions\n    *   **Jul 19 - Jul 25**: Official GSoC midpoint evaluation\n*   **Jul 26 - Sept 12**: Milestone 2 work period for GSoC\n    *   **Aug 27**: Milestone 2 work due for internal evaluation\n    *   **Aug 28 - Sept 3**: Testing of the milestone 2 work product\n    *   **Sept 4 - Sept 10**: Buffer time for Phase 2 revisions\n    *   **Sept 15 - Sept 22**: Official GSoC mentor evaluation due\n*   **Sep 23**: GSoC period at Oppia officially ends\n\n**Note!** For Oppia's participation in GSoC 2025, the coding period dates are strict, and we will not be offering extensions. Please ensure that you have sufficient time during the summer to work on your projects.\n\nTypes of work related to Oppia projects\n---------------------------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#types-of-work-related-to-oppia-projects)\n\nThe Oppia team is committed to making GSoC an enriching educational experience for contributors. In general, our goal for GSoC is for contributors to have a really meaningful experience, and to do something worthwhile over the summer that they can look back on with pride.\n\nIn order to ensure a well-rounded engineering experience, GSoC contributors will have the opportunity to do some or all of the following, depending on their project:\n\n*   Write design documents for technical projects\n*   Read and understand parts of the codebase related to their project\n*   Receive code reviews for all code they write for their project\n*   Develop user-focused, responsive and internationalized UIs.\n*   Write automated tests for their projects\n*   Meet regularly with other contributors on their Oppia development team (LaCE, Contributor Dashboard, Dev Workflow, Android)\n*   Meet 1:1 with their mentors regularly to get developmental feedback\n*   Give presentations and demos of their projects\n*   Get personalized feedback on their project from the product team or a technical lead\n*   Learn how to do code reviews\n\nWe've also asked our previous GSoC contributors what specific things they learned during their GSoC projects. Here are their collated answers:\n\n*   Technical ability and domain knowledge\n    *   Writing maintainable and readable code.\n    *   Building an entirely new feature in a scalable way.\n    *   Writing better automated tests.\n    *   More confidence working with Angular.\n    *   Making better design, UI and technical decisions.\n    *   Getting a better understanding of overall full-stack development.\n    *   Enhanced ability to debug and resolve technical issues.\n*   Technical leadership skills\n    *   How to manage my time well, and how to achieve deadlines.\n    *   Improved skills in managing and executing projects.\n    *   How to give, respond to and understand reviews.\n    *   How to effectively convey ideas.\n    *   How to write a good project proposal.\n    *   Becoming a better developer, not only in terms of technical skills, but also in thinking of actual application of the built product and the edge case scenarios that the user might face.\n*   Communication and personal development\n    *   How to seek help when needed and overcome challenges.\n    *   How to reach out to people, work with them, and help solve each other's problems.\n    *   How to get myself unblocked.\n    *   Putting forward my thoughts more systematically so that others can understand me well.\n    *   Feeling more confident while joining online meetings.\n\nContributors have also told us why they continue to stay engaged with the project after GSoC ends:\n\n*   Community\n    \n    *   It is really an awesome experience working with some amazing folks from all around the world at Oppia.\n    *   The organisation is active and has a strong community bond.\n    *   The kind of support the complete community provides is extraordinary.\n*   Giving back\n    \n    *   The main reason to stay connected is the purpose the community serves. Providing education to those who do not have access to it helps me give back to the society.\n    *   It makes me very happy that I'm part of an organization which provides free education and I think the education is the biggest blessing we can give to one to make them stand on their feet.\n    *   I would love to be part of this org by knowing that maybe not much but yes I'm trying to make an impact and my contribution in the educational field. I really want to do this because where I come from there is not much of education.\n*   Growth / learning:\n    \n    *   I like working in Oppia since it not only helps me improve my coding skills but also helps me grow as an individual.\n    *   Working with Oppia has really helped me grow as a developer and I would really like to stick around to gain even more experience of real world software development.\n    *   I feel my exponential growth while contributing in Oppia and got to learn many new things while getting help from mentors and other Oppia team members.\n    *   The kind of work that Oppia does is really inspiring and there are a lot of opportunities to improve your skills be it be technical skills or leadership skills and most of all the people at Oppia are really fun to work with :)\n\nGSoC Proposal Template\n----------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#gsoc-proposal-template)\n\nWhen submitting a proposal, please use the provided [GSoC 2025 proposal template](https://docs.google.com/document/d/1QbCIpoMLdlBOhfXGhTGMcjmmqp3rkaS5nW8P8FRXyqU/edit?tab=t.0). We will only consider proposals submitted using this template. Note that there is a length limit: the proposal's technical \"HOW\" section should not exceed 20 pages at \"Roboto 10\" font size.\n\n**Note:** There's **no** formal minimum length requirement for your proposal. The quality of what you write is much more important than the amount of text you write, and we encourage you to write **shorter** proposals that still convey the main aim of the project.\n\nImportant\n\nThe 2025 template differs from the 2024 template. Please make sure that you are using the 2025 one.\n\n**Some important notes:**\n\n1.  Your proposal must be **original** (see section 2.4 of the [Contributor Participation Agreement](https://summerofcode.withgoogle.com/terms/contributor)). During the selection process, proposals that are found to have passed off others' work as their own will automatically be disqualified. If you include any text in your proposal that is copied from the Internet or other sources (even if it is an Oppia doc), you **must** provide a link or reference back to the source. Note that you must attribute sources even if you paraphrase (i.e. re-write their content in your own words). In cases of doubt, we would encourage you to err on the side of citing your sources (since not doing so may be construed as plagiarism).\n    \n2.  When the necessary criteria for requesting a review are met, add [gsoc-2025-mentors@oppia.org](mailto:gsoc-2025-mentors@oppia.org) as an editor for your proposal doc. (This makes some workflows, like inviting PMs or fixing typos, etc., easier, but if you're concerned about changes to your doc, then you can [turn on notifications for edits](https://support.google.com/docs/answer/91588?hl=en&co=GENIE.Platform%3DDesktop).) After fixing the sharing settings, make a new post in the correct \"proposal reviews\" category in [GitHub Discussions](https://github.com/oppia/oppia/discussions) that is clearly titled with the name of the project that you are requesting a review for, and provide a link to the doc in your post.\n    \n    Please use only the above channel for proposal reviews: all proposal-related communication should happen through GitHub Discussions or directly through comments in the proposal doc. **Do not** send proposals directly to individual GSoC mentors.\n    \n    You can also request **at most one** \"tech lead review\" for **at most one** of your proposals during the pre-selection phase. To keep things fair, the tech lead will do only a single pass on your proposal and leave comments, but is not required to follow up on replies to those comments. Since you can only request a tech lead review once (per applicant), we recommend doing so after you have gotten feedback from mentors and completed a full draft of your proposal, but at least a week before the due date. Tech leads will process requests in the order they are received. To request a tech lead review, fill in [this Google Form](https://forms.gle/oGnj56rHNbNCWmBr6).\n    \n3.  Your final proposal should be self-contained. In particular, to be fair to all applicants, key components of the proposal should not be editable after the deadline. Don't assume that reviewers will follow external links.\n    \n\n### Tips for writing a good project plan\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#tips-for-writing-a-good-project-plan)\n\nHere's some advice about proposals and milestone timeline planning that we collated from previous contributors and mentors:\n\n*   **Choose a project you're interested in!** If you have a strong interest in your project, this might make it easier for you to pick up the necessary skills and tackle unforeseen difficulties that may arise during GSoC.\n*   **Familiarize yourself with the technologies for your project and the relevant part of the codebase.** Reviewers will want to see that you understand how to integrate your project with the current Oppia structure — don't design in a vacuum.\n*   **Define milestones with enough detail to get a proper ETA.** For example, don't just say \"write e2e tests\", otherwise you risk significantly underestimating the timeline.\n*   **Communicate and present your ideas clearly.** Your proposal should show that you have a good understanding of the codebase and the final goal of the project. For example, in a user-facing proposal, don't just make a list of files that need to be changed; you should also show detailed mocks and user flow diagrams that demonstrate a clear understanding of the requirements.\n*   **Limit proposal length.** A lengthy proposal is not necessarily better. In fact, adding large amounts of unnecessary detail can sometimes obscure the main points you are trying to get across.\n*   **Pick a project idea that is within your limits to tackle.** Make sure that what you're proposing is within your capabilities.\n\n### What should applicants expect from mentors in a proposal review?\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#what-should-applicants-expect-from-mentors-in-a-proposal-review)\n\n*   Please write your proposal on the assumption that you \"own\" your chosen project. From your perspective, the submitted proposal should be proofread and in as good a condition as possible before you ask for a review. Make sure that you have a sufficiently good understanding of the codebase/project so that you can find and fix flaws in the design; reviewers will give you feedback but not do this for you. Note that your proposal doesn't need to be flawless — we expect that you might make mistakes, and reviewers will be happy to guide you on how to improve. Instead, by \"as good a condition as possible\", we mean that your proposal should demonstrate:\n    *   Your ownership of the project\n    *   The research you have put into writing it\n    *   Your analytical skills\n    *   Your independence in making complex decisions\n*   Make sure to present solutions and ask for feedback, rather than just asking for solutions. The proposal template contains a \"key decisions\" section which you can use to present the various options you came up with, analyze their advantages & disadvantages using a comparison table, and explain your proposed choice and the reasoning behind it. Note that this doesn't mean that you must always have multiple ideas to solve a problem, but you should instead always explain how you reached a solution, and why is it the best one from the end-user's perspective. Think about how you might gather data to validate your conclusions (e.g. by finding support in the peer-reviewed literature, or by showing your ideas to potential users in the target audience and asking for feedback, etc.).\n*   Reviewers' suggestions are _suggestions_, not mandates. We do not expect you to always agree with your reviewers! This means that, as the proposal owner, you are always welcome to decide whether to accept/reject such suggestions. In either case, when accepting/rejecting a suggestion provided by a reviewer, try to explain your reasoning and the research that led to your decision.\n*   If you're confused about something, try to identify the point of confusion and ask have specific discussions about it, rather than simply agreeing to whatever is proposed. Don't rely on an \"appeal to authority\" (e.g. \"I am doing it this way because reviewer XXX said so\") — the rational analysis and thought that underlie the decision are what's important, so make sure that you understand and clearly communicate the reasons behind the decisions you make.\n*   Note that the process Oppia uses to select GSoC contributors typically includes multiple independent reviewers, most of whom will not have looked at the earlier versions of your submitted proposal. Your initial proposal reviewers may or may not be involved in the final selection process, and it is **not** a requirement that you need to implement all your reviewer's suggestions/requests in order to be selected. Instead, please consider your reviewer as a friendly advisor who is available to help you and provide guidance, rather than the main future evaluator of your proposal.\n\nSelection Criteria\n------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#selection-criteria)\n\nTo select contributors for GSoC, we will evaluate candidates based on a set of criteria designed to ensure we select individuals who not only possess the necessary skills but also demonstrate the ability to contribute effectively to the project. The criteria are as follows, listed in order of significance::\n\n*   **Primary Criterion: Required Skills for the Project** - This is the most critical factor in our selection process. A contributor must have the necessary skills for the project. Lack of these skills is a deal-breaker and can lead to immediate rejection of the proposal.\n    \n*   **Secondary Criteria** (of equal importance):\n    \n    *   **Quality of the Submitted Proposal** - This criterion helps us gauge the applicant's understanding of the project requirements. The proposal should align with project goals, and be clear, thorough, and feasible.\n    *   **Prior Experience Working with the Contributor** - We consider our previous interactions with the contributor, focusing on their reliability, communication skills, independence, initiative, responsiveness, and willingness to assist others. This assessment allows us to predict how well the contributor will integrate with the Oppia developer community and contribute to the success of the project.\n\nWe believe that strong performance in these dimensions is likely to correlate well with the contributor having an enjoyable, fulfilling and productive experience over the summer, and successfully completing the GSoC program.\n\nFor the proposal, we generally look for a clear indication that the contributor has a good, clear understanding of the project, and has broken it down sufficiently well, in a way that makes it very likely to succeed. Some indicators that could help with this include:\n\n*   Clear, unambiguous communication. (This is important; your proposal will be read by many mentors!)\n*   A clear analysis of (and good design decisions that build on top of) the original project idea, with a strong focus on creating a simple, intuitive experience for end users.\n*   A proposed solution approach which is sufficiently concrete and which demonstrates that the applicant has a good understanding of both the scope of the problem and the existing codebase.\n*   A description, if applicable, of how the applicant plans to mitigate risks that could potentially derail the project.\n*   A concrete, specific description of each milestone, together with a breakdown of the necessary work.\n\nCommunication\n-------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#communication)\n\nIf you have questions pertaining to \"how to get started with Oppia\" or any other queries regarding GSoC at Oppia, please ask them on **[GitHub Discussions](https://github.com/oppia/oppia/discussions)**. Please be specific when asking questions; this makes it easier for us to help you. Also, please make sure to read the relevant \"getting started\" wiki page ([Web](https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#setting-things-up), [Android](https://github.com/oppia/oppia-android/wiki/Contributing-to-Oppia-android)) first, since the answer to your question might already exist there!\n\nTo receive important announcements and updates about GSoC at Oppia, please subscribe to the **[Oppia GSoC Announce](https://groups.google.com/g/oppia-gsoc-announce)** mailing list, and the [Developer Announcements](https://github.com/oppia/oppia/discussions/categories/developer-announcements) category on GitHub Discussions.\n\nOppia's Project Ideas List\n--------------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#oppias-project-ideas-list)\n\n_**Note:** If you're coming to this section from an external link, please make sure to scroll up and read this entire wiki page carefully, not just this section. There's a lot of useful information on the rest of the page, including a FAQ and a section describing selection criteria. Thanks!_\n\nThe following is a list of Oppia's 2025 GSoC project ideas. You are welcome to choose among these ideas, or propose your own! However, if you're planning to propose something original, it's essential to engage with the Oppia community beforehand in order to get feedback and guidance to improve the proposal. We'd also recommend taking a look at [Oppia's mission](https://github.com/oppia/oppia/wiki/Oppia's-Mission) and seeing if there is a natural way to tie your idea to the Oppia project's goals, otherwise it might not be a good fit at this time.\n\nPlease note that the list of project ideas below is not set in stone: more projects may be added later, and some project descriptions may also change a bit, so check back regularly. In addition, the mentor assignments listed below are provisional, and may change depending on which proposals are eventually accepted. (If you want to see what changes have been made to this page since you last viewed it, you can use the [History tab](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025/_history).)\n\nIf you need clarification on any of these ideas, feel free to open a thread in GitHub Discussions following the process in [this guide](https://docs.google.com/document/d/1jt8_pKcrbsc0xHgUEa0Wh8i6imxYmZiB_2QjDmH7ODg/edit?tab=t.0).\n\n### Learner and Creator Experience (LaCE) team\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#learner-and-creator-experience-lace-team)\n\n1.1. [Clean up the structure for study guides and worked examples](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#11-clean-up-the-structure-for-study-guides-and-worked-examples)\n\n1.2. [Fix the most common server errors](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#12-fix-the-most-common-server-errors)\n\n1.3. [Lesson player redesign](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#13-lesson-player-redesign)\n\n### Contributor Dashboard team\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#contributor-dashboard-team)\n\n2.1. [Show AI-powered translation suggestions to translation submitters](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#21-show-ai-powered-translation-suggestions-to-translation-submitters)\n\n### Developer Workflow team\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#developer-workflow-team)\n\n3.1. [Acceptance tests](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#31-acceptance-tests)\n\n3.2. [Consolidate entity migration jobs](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#32-consolidate-entity-migration-jobs)\n\n3.3. [Standardize and validate domain objects and storage models](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#33-standardize-and-validate-domain-objects-and-storage-models)\n\n### Android team\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#android-team)\n\n4.1. [Flashbacks](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#41-flashbacks)\n\n4.2. [Platform parameters dashboard](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#42-platform-parameters-dashboard)\n\nLearner and Creator Experience (LaCE) team\n------------------------------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#learner-and-creator-experience-lace-team-1)\n\n### 1.1. Clean up the structure for study guides and worked examples\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#11-clean-up-the-structure-for-study-guides-and-worked-examples)\n\n**Project Description:**\n\nOppia topics include a list of skills to teach. These skills are grouped into subtopics (like ['Basic Concepts of Division'](https://www.oppia.org/learn/math/division/revision/basic-concepts)), each with its own study guide (or 'subtopic page' in the backend). Currently, subtopic pages are implemented as a single large rich-text field, which makes them hard to translate and limits how we can display them. We'd like to split this rich-text field into multiple heading/content parts. In the above example, the updated subtopic page would have two sections (\"What is division?\" and \"Parts of a division equation\"), and the subtopic page editor would have a list of sections, each with its own \"heading\" plain-text field and \"content\" rich-text field.\n\nAdditionally, both skill explanations and subtopic pages should be able to include worked examples. Previously, worked examples were implemented as an explicit subfield of the SkillContents object that is contained in the Skill model. We would like to implement worked examples as a general rich-text component instead, since this allows them to be used in contexts beyond skills as well.\n\nThe aim of this project is therefore to clean up the incorrect modelling described above and make the necessary updates to the viewing and editing flows for subtopic pages, worked examples, and their associated translations/voiceovers.\n\nLinks to PRD and mocks:\n\n*   Subtopic pages (study guides): [Figma mocks](https://www.figma.com/design/qIT6EvVeyLo2dDuQyR5xzC/Oppia-_-RTE?node-id=0-1&p=f&t=bfOaBMxVrGuWd7mF-0) and [design thread](https://github.com/oppia/design-team/issues/60)\n*   Worked examples: [Figma mocks](https://www.figma.com/design/1e1pq5PSoiULZqM4zvVNY0/Oppia-%23136-Incorporate-worked-examples-in-the-learning-experience?node-id=0-1&p=f&t=a47Jd68ycVXdkjdM-0), [design thread](https://github.com/oppia/design-team/issues/136), and [reference PRD](https://docs.google.com/document/d/1QrqTsR1Ew3WfQvj7D83mh0k9HjW6xQ-2dpJGkbe8XqY/edit#heading=h.s68z2sezulra). Note that some parts of the PRD are excluded -- see the \"not in scope\" section below.\n\n**Tracking issues**: [#18305](https://github.com/oppia/oppia/issues/18305), [#19851](https://github.com/oppia/oppia/issues/19851)\n\n**Not in scope:**\n\n*   Implementing new rich-text components other than \"Worked Example\".\n*   Implementing the \"Words to know!\" and \"Otter Tip!\" sections in the [revision card Figma mocks](https://www.figma.com/design/qIT6EvVeyLo2dDuQyR5xzC/Oppia-_-RTE?node-id=0-1&p=f&t=bfOaBMxVrGuWd7mF-0).\n*   Enabling the use of worked examples in hints and feedback. (We will do this later once we have tried out the functionality in subtopic pages and skill descriptions.)\n*   Implementing the more detailed validation described in the PRD (for limiting the number of worked examples to 2 if there are no images, or limiting them to 3 if there are images). For now, we will go with a general limit of 2.\n\n**Size:** Large (~350 hours)\n\n**Difficulty**: Moderate/Hard\n\n**Potential mentors:** @kevintab95\n\n**Product/technical clarifiers:** @seanlip (product), @kevintab95 (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Debug and fix CI failures/flakes.\n*   Write Python code with unit tests.\n*   Write TS + Angular code with unit tests.\n*   Write or modify e2e/acceptance tests.\n*   Write or modify Beam jobs, with tests.\n\n**Related issues:**\n\n*   [RTE-related issues](https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=Creators%3A+RTE+bugs)\n*   [Validation (backend + frontend)](https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=Data+validation)\n*   [Translation-related issues](https://github.com/orgs/oppia/projects/18/views/4)\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: In SubtopicPageContents, carry out migrations to do the following:\n    \n    *   Convert the existing `subtitled_html` field into the new structure (a `study_guide_sections` \"repeated JsonProperty\" field consisting of `{heading: str, content: str}` dicts).\n    *   Introduce a unique content ID for each translatable field, similar to explorations.\n    *   Move the written translations and voiceovers for subtopic pages in EntityTranslationsModel and EntityVoiceoversModel, instead of within the SubtopicPage object (similar to explorations).\n    \n    Update the subtopic page editor UI to accommodate the new structure, and the learner UI to match the Figma mocks. Then, deprecate the old `subtitled_html` field.\n    \n*   **Milestone 2**: Verify that the existing `worked_examples` fields are empty in production, then carry out a schema migration to safely deprecate the `worked_examples` field in the `skill_contents` part of the SkillModel, and remove it from the skill editor UI as well.\n    \n    Implement a new 'Worked Example' RTE component that appears only in the skill explanation and subtopic page RTEs, and validate that skill explanations cannot have more than 2 such components. Add acceptance tests for the learner and creator flows to verify that they align with [these mocks](https://www.figma.com/design/1e1pq5PSoiULZqM4zvVNY0/Oppia-%23136-Incorporate-worked-examples-in-the-learning-experience?node-id=0-1&p=f&t=a47Jd68ycVXdkjdM-0). Ensure that this component is translatable in the contributor dashboard, and update the [translation guide](https://docs.google.com/document/d/17jMFtfHVWtJYrzyGQUKdsRXgky7lWv76sGYLOxSbA5w/edit?tab=t.0#heading=h.5mvcuwerfyif) to include it.\n    \n\nOrg-admin/tech-lead commentary/adviceThis is an interesting and high-impact project that “has a little bit of everything”, and that should give you a good understanding of the overall Oppia stack. There is very little in the way of completely new functionality here; almost all the parts of the project have some existing precedent in the codebase.\n\nIf you tackle it, it is important to have a good understanding of the systems involved. Make sure you are familiar with Beam jobs, since these will be important.\n\nWhat we are looking for in proposals\n\n*   Almost all parts of this project have some precedent in the existing codebase, and it is important to maintain consistency with the existing implementations. Thus, in your proposal, when describing your technical approach, please also point to the existing parts of the codebase that already use a similar approach.\n    \n*   Explain how the current structure for exploration translations works, and describe, by analogy, the ideal structure for skill and subtopic card translations. For the subtopic pages, what changes exactly will you make with regards to written translations and content IDs?\n    \n*   Explain in detail the steps you would take to carry out the structural migrations for subtopic pages and skills. For the former, what will the updated editor UI look like?\n    \n*   Explain how you would make the new 'worked examples' component appear only in the concept card and revision card RTEs.\n    \n*   Explain how you would structure the acceptance tests for both parts of the project, and the behaviours you would test.\n    \n*   What is the full list of places in the codebase which list functionality for the different RTE components, and which will need to be updated with details for the worked example component? Explain the approach you took to find these.\n    \n\nTechnical hints / guidance\n\n*   This project combines many concepts that already exist in the Oppia codebase, and understanding (and following) existing precedent is important. You will need to have a good understanding of the following in order to tackle this project:\n    \n    *   The relationship between the different models (topics, skills, subtopics, etc.)\n    *   How to perform a (safe) schema migration (perhaps try doing a sample migration on your local machine). See [this wiki page](https://github.com/oppia/oppia/wiki/Writing-state-migrations) for details on how to write exploration state migrations; writing migrations for JSON properties in other entities follows a similar process.\n    *   How to create an RTE component (perhaps try creating a test component on your local machine). See [this wiki page](https://github.com/oppia/oppia/wiki/Rich-Text-Editor-%28RTE%29-Overview) for details on how to implement rich-text components.\n    *   How to control which RTE components appear in which RTEs, and validate that the RTE content is valid (i.e. doesn’t include any invalid components)\n    *   How translations work for existing entities, like explorations. (The original TDD for that project is here: [Infrastructure for separate storage of translations](https://docs.google.com/document/d/1ZZ6pVKpmynTlmf1_PV1I5TcccmEXPnmoFAVKXN-u2xM/edit), and you can examine the code related to the Contributor Dashboard for how the translation opportunities are generated and displayed.)\n*   Note that \"study guides\" were previously known as \"revision cards\".\n    \n*   For subtopic page contents, be careful to ensure that each element in the list has its own unique content ID. Do not just base the content ID on the item's index in the list – if you have 3 elements in the list and then remove the middle one, the last element’s content ID should not change. This is why we need a counter to keep track of the \"next content ID to assign\".\n    \n*   To migrate the existing subtitled\\_html content, you can transform it into a single-element list with one item whose heading is the revision card's title, and whose body is the existing RTE content. The content\\_id and translation/voiceover migrations for SubtopicPages should be quite easy, because no translations/voiceovers exist for them yet. However, you will still need to figure out the new structure and fix the \"plumbing\".\n    \n*   For \"ensure that this component is translatable in the contributor dashboard\", you can temporarily enable it in exploration RTEs (e.g. in the hints RTE), and then test out the translation workflow. It's important to ensure that the new 'worked example' RTE component has behavioural parity with other RTE components in all places which refer to RTE components, even if it's not being used in the relevant contexts yet – for example, you should update the character-counting logic for hint/solution validation to handle worked-example RTE components as well, in case we decide to make this component available to explorations in the future. Note that **@chris7716** is currently looking into a project that involves updating the translation structure for concept cards, topic descriptions, etc., and you might want to sync with him in order to ensure that your plan for introducing the necessary translation fields aligns with his work.\n    \n\nSuggested PM demo points\n\n*   Milestone 1:\n    \n    *   Editor UI for revision cards is complete\n    *   Learner UI is complete\n*   Milestone 2:\n    \n    *   A worked example RTE component can be created, and used within a broader context (such as a study guide section or a skill explanation).\n\n### 1.2. Fix the most common server errors\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#12-fix-the-most-common-server-errors)\n\n**Project Description:**\n\nWe currently see a number of unaddressed [server errors](https://github.com/oppia/oppia/labels/server%20errors) on hosted instances of Oppia. Many server errors relate to user-facing bugs, and are a good clue that something is problematic in the application. Furthermore, frequently occurring errors result in the server logs getting noisy, to the point that they are no longer treated as alerts because the volume of errors is too high.\n\nThe aim of this project is to address the 15 most common server errors, and improve/clarify the logging infrastructure to make server errors easier to debug in general. This would also make it easier to catch new issues during test deployments, and reduce the overall error rate of the app. \"Addressing a server error\" entails the following:\n\n*   Find a set of setup steps and actions that reliably reproduce the error on a local machine (see [this tutorial](https://github.com/oppia/oppia/wiki/Tutorial-Learn-to-Figure-Out-the-Reproduction-Steps-for-a-Server-Error)). If more insight is needed, it is also fine to add some logging and do another deployment to get more information.\n*   Identify the root cause of the error.\n*   Confirm the expected behaviour with the product/tech leads, if needed.\n*   Fix the error and add tests (which could be frontend, backend, or full-stack) to ensure that the error does not happen again. Some of the other steps listed in this [wiki page](https://github.com/oppia/oppia/wiki/Server-errors-and-solutions) might also be of interest. Note that some errors may be due to data issues, in which case a migration job or direct editing might be required, as well as stricter typing/validation to ensure that the issue doesn't reoccur.\n\n**Tracking issues**:\n\n*   [#21807](https://github.com/oppia/oppia/issues/21807), [#21841](https://github.com/oppia/oppia/issues/21841) and [#21872](https://github.com/oppia/oppia/issues/21872) are quality-of-life improvements to help make server errors easier to debug.\n*   See [this link](https://github.com/oppia/oppia/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22server%20errors%22%20label%3A%22Impact%3A%20High%22&page=1) for a list of the most common server errors.\n\nNote that the project will only cover a subset of the above, per the milestones described below. This will be the subject of a discussion between the contributor, mentor and org admins at the start of CBP.\n\n**Size:** Medium (~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @Nik-09\n\n**Product/technical clarifiers:** @kevintab95 (product), @Nik-09 (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Write Python code with unit tests.\n*   Write TS + Angular code with unit tests.\n*   Write or modify e2e/acceptance tests.\n*   Write or modify Beam jobs, with tests. (This is because you might need to write audit jobs for debugging certain errors.)\n*   Figure out repro steps based on info from server logs.\n\n**Related issues:**\n\nConsider taking up issues like [#21807](https://github.com/oppia/oppia/issues/21807), [#21841](https://github.com/oppia/oppia/issues/21841) and/or [#21872](https://github.com/oppia/oppia/issues/21872) to make errors easier to reproduce / debug.\n\nYou might also want to try some issues from this list to see whether this project is a good fit. In any issues you attempt, try to demonstrate your ability to (a) reproduce server errors deterministically, (b) write a debugging doc to narrow down the source of an error if you can’t pinpoint it in one go, (c) find the clear root cause of an error, and (d) prevent the error from happening in the future.\n\nIf you like, you can also suggest other improvements to the logging infrastructure that would make it easier to fix \"server error\" issues. (It is fine to file issues for these improvements and get assigned to them in the usual way. However, you should have tried to tackle at least one server error with a debugging doc, and the improvements you suggest should help address the problems you ran into while trying to figure out what caused the error.)\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: Fix the 7 most common server errors, and improve the logging for server errors as needed.\n    \n*   **Milestone 2**: Fix the 8 next-most common server errors.\n    \n\nOrg-admin/tech-lead commentary/adviceThis project requires very good debugging skills. You will be exposed to a mix of server errors, some of which are very easy to solve, and others which will require a lot more investigation. Along the way, look for improvements to the infrastructure that would make the debugging process easier (ideally to the point that server errors can be tackled as easily as regular issues).\n\nLaying out your work in a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs) is a very important skill for this project, since you will sometimes need to get help and it is important to provide responders with the context needed to do so.\n\nWhat we are looking for in proposalsFor the proposal, we recommend that you focus on identifying around 15 issues tagged as “server errors”, correctly outline their root cause, and propose a fix. These should include most of the ones from the list in the project description, as well as additional ones of your choice. You may also link to reproduction instructions (with video proof) and public debugging docs that you have already added to the corresponding issue threads.\n\nAlso, please note that, for this project, the proposal itself is a bit less important. The ability to solve some actual [server errors](https://github.com/oppia/oppia/labels/server%20errors) is better evidence that the project will be a good fit. If you need to clarify the expected behaviour for an issue, feel free to start discussions in individual issue threads and in the project proposal.\n\nTechnical hints / guidanceAll applicants for this project should read [this tutorial](https://github.com/oppia/oppia/wiki/Tutorial-Learn-to-Figure-Out-the-Reproduction-Steps-for-a-Server-Error) on how to fix server errors. Note that, for this project, reading and understanding what the code is doing is very important, and so is writing debugging docs to explain what you know. The code fix is often simple, but the analysis to figure out which fix to make can be harder.\n\nWhen attempting to fix a server error, first find a set of deterministic reproduction steps and add that to the issue. You will need to do this before you can be assigned that issue to fix. (Doing this investigation might result in linking the server error to a different existing issue that is already filed on GitHub, so general experience with bug-fixing is good to have as well.)\n\nNote that **@kevintab95** and **@lkbhitesh07** have access to the server logs. Please correspond with Kevin Thomas and the server admins team if you want to run debugging jobs on the server.\n\nSuggested PM demo points\n\n*   Milestone 1: Demonstrate fixes for any server errors with a user-facing behaviour component.\n    \n*   Milestone 2: Demonstrate fixes for server errors with a user-facing behaviour component.\n    \n\n### 1.3. Lesson player redesign\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#13-lesson-player-redesign)\n\n**Project Description:**\n\nThe aim of this project is to redesign Oppia's existing lesson player according to [these mocks](https://www.figma.com/file/YWe7SqfUVjxlJLKTUn0UZa/Project-2?type=design&node-id=7076-365949&mode=design&t=v3mhfxAkI0l9V53z-0). The goals of the redesign are to make the lesson player intuitive to navigate, easy to add features to in the future, and more engaging for younger audiences. The new lesson player should work well on mobile, desktop and tablet devices, as well as in RTL and LTR languages. (Note that some parts of the mocks are out of scope -- see the \"Not in scope\" section below.)\n\nThe new functionality should be developed behind the /lesson URL (which should, for now, redirect to the same backend handlers as /explore), and be gated behind a feature flag. Once the lesson player is ready to launch, all /explore URLs should be redirected to /lesson instead, and the new lesson player should be used for all lessons.\n\nRelevant links: [Mini-PRD](https://docs.google.com/document/u/1/d/1922aE9_TEFTbHyA3jrXy9cTxo2JgvjfEvKHlxqxG-Rw/edit) and [mocks](https://www.figma.com/file/YWe7SqfUVjxlJLKTUn0UZa/Project-2?type=design&node-id=7076-365949&mode=design&t=v3mhfxAkI0l9V53z-0)\n\n**Tracking issues**: [#19217](https://github.com/oppia/oppia/issues/19217)\n\n**Not in scope:**\n\n*   Implementing the speed adjuster in the voiceover toolbar\n*   Implementing the \"Get Help\" control in the sidebar and the tutorials within it\n\n**Size:** Large (~350 hours)\n\n**Difficulty**: Hard\n\n**Potential mentors:** @amyyeung17\n\n**Product/technical clarifiers:** @seanlip (product), @amyyeung17 (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Debug and fix CI failures/flakes.\n*   Write Python code with unit tests.\n*   Write TS + Angular code with unit tests.\n*   Write or modify e2e/acceptance tests.\n\n**Related issues:**\n\nAny non-backlog issues in the \"Lesson Player CUJs\" section of the [LaCE project board](https://github.com/orgs/oppia/projects/3/views/8?sliceBy%5Bvalue%5D=Lesson+player%3A+CUJ+bugs) (try to choose ones that relate specifically to the exploration player interface). Also, see the guidance in the last part of the \"What we're looking for in proposals\" section below.\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: Move all non-UI-specific logic in the exploration player page to services, so that they can be used in both the existing and new exploration players. Then, build the following parts of the new exploration player page at the /lesson URL:\n    \n    *   The overall layout (sub-navbar, main player area, sidebar, footer, audio bar). Only the back-and-forth navigation and \"Continue\" buttons in the footer need to work at this stage; the rest can be implemented in Milestone 2.\n    *   The main \"conversation flow\" UI (including all interactions).\n    *   The \"correct answer\" pop-up and confetti.\n    \n    By the end of this milestone, it should be possible to play any Oppia exploration via the `/lesson/{{exploration_id}}` URL (if the feature flag is turned on), submit and view wrong answers, and navigate back-and-forth through the lesson. Also, the exploration editor preview tab, practice questions page and diagnostic test pages (which use components of the lesson player) should show the new UI if the flag is turned on, and the old UI if it is not. Finally, if the flag is turned on, the /explore URL should redirect to the corresponding `/lesson` page.\n    \n*   **Milestone 2**: Transfer the remaining UI components to the new layout, updating or adding new acceptance tests as needed to verify their behaviour:\n    \n    *   Hints, solutions and concept cards\n    *   The voiceover audio player\n    *   The share, feedback, report and \"exit lesson\" buttons\n    *   The progress-saving and checkpoints flow\n    *   The end-of-lesson next steps (rate lesson, go to new lesson, practice, etc.)\n    \n    Flip the launch flag, and, once the new player is serving in production, remove the code for the old lesson player.\n    \n\nOrg-admin/tech-lead commentary/adviceNote that, although this project primarily involves UI changes, it also requires quite a strong understanding of Angular and \"layered architecture\", so it might be harder than you think.\n\nThe most important part is the very first part, which involves refactoring the existing UI (in a way that doesn't make any changes to functionality) so that the “services” code is properly separated from \"UI\" code. To do this properly, you will need to have a strong understanding of how the different pieces of the UI connect together in the new implementation, and be able to write out that specification.\n\nAfter the service code is properly isolated, the rest of the implementation should be fairly straightforward. However, there are a number of subparts and constraints to keep track of, so it will be important to plan the work in an organized way.\n\nWhat we are looking for in proposalsFor the proposal, we would like to see answers to the following questions:\n\n*   Give a detailed explanation of how you would identify and split out the “service” parts of conversation-skin.component.ts.\n*   Give a broad, high-level overview of how you would implement the UI, paying attention to how you would do this in a maintainable way. In particular:\n    *   What is the final structure of the three subfolders in core/templates/pages/exploration-player-page?\n    *   For each component in the new exploration player, specify its API fully, including the types and descriptions of each of the component’s inputs.\n    *   For each component, is there a reusable component implemented elsewhere in the app that you can reuse? If so, describe which one, and how you would refactor it (if needed) to support the new \"exploration player page\" use case.\n*   Specify the naming convention system you would use for the CSS. (It needs to be consistent and predictable.)\n*   How will you use feature flags to ensure that the old lesson player page (at /explore) remains intact while the new player functionality is being developed, and that the exploration editor preview tab, practice questions page and diagnostic test pages “behave correctly”? (In your proposal, please also specify what you believe the correct behaviour to be.)\n*   How will you connect the code for each of the interactions to the new exploration player? If you are making custom versions of each interaction for the new learner view, how will you ensure that the old code is used when the feature flag is turned off, and the new code is used when the feature flag is turned on?\n*   How will you handle \"supplemental interactions\" (see the \"Technical hints\" section below)?\n*   For each component you create, how will you ensure that it is accessible? What is the full list of CUJs that you will write acceptance tests for? (This should be covered in the \"Testing Plan\" section of your proposal.)\n\nWhile developing your proposal, you might find parts of the mocks that you would like clarification on. Please ask these questions in [GitHub Discussions](https://github.com/oppia/oppia/discussions) or leave comments directly on the [Figma mock](https://www.figma.com/design/YWe7SqfUVjxlJLKTUn0UZa/Project-2?node-id=7641-377168&t=UsCnBHgweFqwGCwR-0). If your technical plan relies on the answers to these questions, link to them (where appropriate) in the proposal you submit.\n\nIn addition to the proposal, the following is optional, but would significantly enhance your application if it is done well:\n\n*   Create 1-2 PRs that focus on a specific lesson player sub-component. For this sub-component, move the shared logic between the old and new implementations to the services/ folder, and implement the “new lesson player” version of that sub-component with Karma unit tests. Demonstrate that, with your PR, the old versions of the lesson player still work correctly (including in the exploration editor preview page, the practice questions page, and the diagnostic test page, where applicable).\n\nTechnical hints / guidance\n\n*   Note that parts of the lesson player functionality are reused in the exploration editor preview tab, practice sessions, and diagnostic test. Care should be taken to ensure that the new functionality is properly gated and does not break these other interfaces. Your acceptance tests should cover these cases as well.\n    \n*   Here is some guidance on how to [launch new features](https://github.com/oppia/oppia/wiki/Launching-new-features#how-do-you-as-a-developer-use-feature-flags), which also goes into detail on how to use feature flags.\n    \n*   The most important part of this project to get right (and also the hardest) is the first part of Milestone 1. If this is done properly then the rest of the project will be a lot more straightforward. To do this, make sure that you have a clear understanding, in your new implementation, of the list of services, list of components, and which components use which services (and how they do so) – this should all be specified clearly in your proposal. Then you can look at the existing services/components (for the old implementation) and figure out what modifications are needed to bring them in line with your proposal, and establish the right boundaries between UI and \"domain logic\" code. Here is a suggested technical approach for this part of the project:\n    \n    *   Within `core/templates/pages/exploration-player-page`, move all non-UI-specific logic from component.ts files to service.ts files in the \\`services/\\`\\` folder, so that such logic can be reused in both the existing and new exploration player layouts. Organize that folder to have just 3 subdirectories: a current-player-components folder with the Angular components for the existing experience, a new-player-components folder with the Angular components for the new experience, and a services folder for the services that both experiences have in common. Add a README to the root of the exploration-player-page folder explaining the layout.\n    *   At the end of this process:\n        *   There should be no duplication of code logic throughout any of the files in `/exploration-player-page` – each piece of functionality should be specified in exactly one location, with no copy-pasting.\n        *   The only dependencies between files in the three root subfolders should be from current-player-components to services, and from new-player-components to services. No other inter-subfolder dependencies are allowed.\n        *   No further adjustments should be needed to files in `current-player-components/` for the rest of this project.\n    *   After the code is organized, it is important to be really careful when modifying services, as doing so would impact both the new and old functionality.\n*   When developing the new UI components:\n    \n    *   Keep CSS scoped to each of the new UI components. There is a lot of “global CSS” in the old exploration player, but we do not want to repeat that pattern.\n    *   More generally, the old lesson player may not conform to best practices. You do not need to repeat those mistakes in the new implementation! If you are not sure whether an existing practice in the old lesson player UI code should be followed in the new UI implementation, feel free to ask about that on [GitHub Discussions](https://github.com/oppia/oppia/discussions/categories/q-a-other), and we can give you advice.\n    *   Where relevant, it is fine to copy UI code from the old components (if that matches the \"new lesson player experience\"), since we will be deleting the entire folder of old components at the end of the project.\n    *   Ensure that the new UI works for both mobile/desktop and also for RTL/LTR languages as you go. Don't wait until the end of the project/milestone to handle this.\n*   Note that the new exploration player will also need to handle \"supplemental\" interactions (like image click, music notes, etc.), where the interaction is a \"canvas\" that the learner enters answers in, and that doesn’t reset when Oppia gives feedback. Mocks do not exist for this case, but you can use the approach taken in the existing lesson player (e.g., for desktop view, show the \"canvas\" on the right of the screen and the conversation on the left side).\n    \n\nSuggested PM demo points\n\n*   Milestone 1:\n    \n    *   The overall structural layout for the exploration player is in place on both desktop and mobile.\n    *   A simple Oppia exploration (with just Continue, Multiple Choice and NumericInput) is playable in the new lesson UI.\n    *   An Oppia exploration with all interactions is playable in the new lesson UI.\n*   Milestone 2:\n    \n    *   All the controls in both sub-navbars and the sidebar are fully functional.\n    *   All the controls in the footer are fully functional.\n\nContributor Dashboard team\n--------------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#contributor-dashboard-team-1)\n\n### 2.1. Show AI-powered translation suggestions to translation submitters\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#21-show-ai-powered-translation-suggestions-to-translation-submitters)\n\n**Project Description:**\n\nThis project involves showing auto-generated suggestions in the Contributor Dashboard translation submission modal, so that translation submitters can edit and submit those translations, rather than needing to generate completely new ones from scratch each time. These suggestions would arise from autogenerated translations from an AI-powered translation service.\n\nThe project involves implementing a system for updating `EntityTranslationsModel` to associate each (content\\_id, language) pair with both a \"manual\" and \"auto\" translation (similar to `VoiceoverType` in feconf.py for voiceovers). The manual translation should only be populated once a translation is approved by a human reviewer (possibly after edits); this translation is shown to the learner when playing lessons. On the other hand, automatic translations will only be shown as suggestions to translation submitters via the contributor dashboard. To understand the effectiveness of the AI suggestions, the contributor admin dashboard will also display information about how many times the AI suggestions were used as-is, without any edits.\n\nThere should also be a button on the Admin page that can bulk-generate auto-translations via a Beam job. This job should be run to populate the initial auto-translations once the pipeline is ready. Subsequently, any additions/edits to a curated entity (lesson, topic, skill, etc.) should trigger an auto-translation of the added/edited content, and publishing a curated entity should trigger an auto-translation of all strings in the entity. In other words, the auto-translations should always be up-to-date with the English strings in the current version of the entity.\n\nLink to PRD: [Language Management and Lesson Auto-Translation PRD](https://docs.google.com/document/d/1TeGQQNLNJWkTgvGQ1xmV6snz8zXnJ23TvuDKtK5_Tok/edit?usp=sharing) (a bit out of date)\n\n**Tracking issues**: [#16164](https://github.com/oppia/oppia/issues/16164) (part), [#19681](https://github.com/oppia/oppia/issues/19681)\n\n**Not in scope:**\n\n*   Configuring the list of prioritized languages for translation\n*   Auto-generation of voiceovers (in any language)\n*   Enabling translations for concept cards, review cards, or practice questions\n*   Showing auto-generated translations in the learner view (see [https://github.com/oppia/oppia/issues/16164](https://github.com/oppia/oppia/issues/16164) for more information).\n\n**Size:** Large (~350 hours)\n\n**Difficulty**: Hard\n\n**Potential mentors:** @chris7716\n\n**Product/technical clarifiers:** @seanlip (product), @chris7716 (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Debug and fix CI failures/flakes.\n*   Write Python code with unit tests.\n*   Write TS + Angular code with unit tests.\n*   Write or modify e2e/acceptance tests.\n*   Write or modify Beam jobs, with tests.\n\n**Related issues:**\n\nIssues related to translation submitters are good ones to tackle: [https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=Translation+submitters](https://github.com/orgs/oppia/projects/18/views/4?sliceBy%5Bvalue%5D=Translation+submitters)\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: The computer-aided translation (CAT) backend is completed, and can process any rich-text field properly (including components like images, skill links, etc.), including validating that the autotranslated string has the same number and type of rich-text components as the original string. Storage models are updated to store these autogenerated translations, and the relevant statistics models and regeneration jobs are also updated to include the number of times a translation suggestion exactly matches the auto-translation. The wiki pages are also updated to explain how to add new languages and translation providers to the system.\n    \n    At the end of the milestone, admins should be able to configure the CAT service provider for each language, and run a job to generate auto-translations for any untranslated texts for curated lessons. (They can select 'all entities', 'all entities of a specific type', or a specific entity; and they can select 'all prioritized languages' or a particular language.)\n    \n*   **Milestone 2**: When a curated entity (lesson, topic, skill, etc.) is edited, this should trigger an auto-translation of the added/edited content. When a curated entity is published, this should trigger a full auto-translation of all strings that don't have auto-translations yet. These auto-generated translations are then shown to contributors in the contributor dashboard UI, together with an annotation explaining their origin.\n    \n\nOrg-admin/tech-lead commentary/adviceThis is a difficult project that involves building and completing a pipeline that can greatly reduce the effort needed to internationalize lessons. The main things to be prepared for are Beam jobs and working with an external translation service.\n\nWhen planning your milestones, try and do the Beam testing as early as possible so that you have enough time to debug any issues that arise. For the translation service, it is essential to have a quick way to test it, because you will likely need to fine-tune how you send the strings to the service. Getting that set up can involve some registration/activation steps, so it's worth getting familiar with the pipeline to ensure that you will have a good development environment to iterate in.\n\nWhat we are looking for in proposalsPlease explain the following clearly in your proposal:\n\n*   Details of all the Beam jobs you plan to write for this project.\n*   What is your plan for translating each of the rich-text component types, and how will you handle this when sending the string to the third-party system for translation? How will you validate that the correct number and type of rich-text fields are preserved between the original and the translated content?\n*   How will you structure the system so that different service providers can be specified for different languages, with each service provider having a ‘services.py’ file in core/platform/translate? (For this project, it is fine to include the implementation for only one provider, but the framework should be extensible and there should be clear instructions in the wiki for contributors on how to add a new provider.)\n*   What are the different tasks that need to be completed for this project, and in what order should they be done?\n*   What transformations need to be done to the content before it is sent to the cloud translation service, and what transformations need to be done to the received translation before it is saved in the datastore (so that it can be presented directly to translation submitters, without further edits)?\n*   What is your plan for setting up a quick-debugging loop that helps you fine-tune what you send to the cloud translation service? (It would be a good idea to try and get a proof-of-concept set up on your machine that shows you are able to do effective testing with a cloud translation service while developing locally.)\n*   What is the updated schema for the storage models, and (if necessary) how will you handle the migration of the existing models to the new structure?\n*   What updates you will make to the Contributor Admin dashboard files, and what modifications you will make to the Beam backfill statistics-regeneration jobs, to add a new statistic for submitted translations which match the AI ones.\n\nTechnical hints / guidance\n\n*   Much of the computer-aided translation (CAT) backend work has already been done (see [this doc](https://docs.google.com/document/d/1kJd-yLTzB9a2c3Nq7v9pzKfHwKHKGpkWfQ8B0YGf50U/edit#heading=h.jp6no890gjkv) for details). You might like to look at previous unfinished PRs: #12604 / #14418. However, please bear in mind that the translations system has evolved significantly since those PRs were created.\n    \n*   You will need to gate the new functionality behind a `SHOW_TRANSLATION_SUGGESTIONS_IN_CD` [feature flag](https://github.com/oppia/oppia/wiki/Launching-new-features) that gates the integration of translation suggestions to the contributor dashboard. We will only turn on this feature flag once the feature testing process has been completed.\n    \n*   This [design issue](https://github.com/oppia/design-team/issues/128) tracks the progress of the mocks for showing translation suggestions on the contributor dashboard, and you can follow it for updates. That said, for your proposal, please focus more on the technical aspects than the mocks – in general, anything that contributor dashboard submitters can reasonably understand and make use of is fine.\n    \n*   The technical approach we are taking involves pre-generating the auto-translations, to reduce latency at the time of translating. There should therefore be no need to generate auto-translations “in the moment” while a volunteer is submitting a translation via the contributor dashboard. If, for some reason, a stored auto-translation is not available for a piece of content, it is fine to just not show that part of the submission modal. (Don’t error noisily in a way that blocks the experience for the translation submitter.)\n    \n*   The list of languages for which to auto-generate translations can be derived from the information stored in VoiceoverAutogenerationPolicyModel, which contains language codes as keys. This list is currently shown on the /voiceover-admin page.\n    \n*   If you need to migrate JSON properties, following the approach used for migrating the states in the Exploration domain object might help (i.e. introduce a schema version field and use that to perform the migration safely).\n    \n*   To enable the (new version of the) Contributor Admin dashboard, go to /release-coordinator and turn the `cd_admin_dashboard_new_ui` flag on.\n    \n*   Here is a suggested technical sketch for the statistics model changes:\n    \n    *   Add a new `exactly_matches_ai_suggestion` boolean field, which defaults to False, to the GeneralSuggestionModel. This is used to increment new `submitted_ai_translations_exact_match_count` fields in `TranslationContributionStatsModel` and `TranslationSubmitterTotalContributionStatsModel` when a contributor’s translation suggestion is exactly the same as the auto-AI suggestion stored in `EntityTranslationsModel`.\n    *   Display the new count from `TranslationSubmitterTotalContributionStatsModel` in the relevant table of the Contributor Admin dashboard. (You don't need to display the corresponding count from `TranslationContributionStatsModel` in the contributor's \"Contribution Stats\" dashboard -- the reason we're storing it there is to make it easy to backfill the `TranslationSubmitterTotalContributionStatsModel` from it if needed, similar to how its other attributes are backfilled.)\n    *   Update any Beam backfill jobs that regenerate these statistics, as needed. (Note that `TranslationContributionStatsModel` would need to be backfilled based on the suggestions and entity translations.)\n\nSuggested PM demo points\n\n*   Milestone 1:\n    \n    *   Translation autogeneration works properly for rich-text content with different components (skill links, images, etc.).\n    *   A Beam job allows generation of all autotranslations.\n*   Milestone 2:\n    \n    *   Autogenerated translation suggestions are shown in the contributor dashboard UI.\n\nDeveloper Workflow Team\n-----------------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#developer-workflow-team-1)\n\n### 3.1. Acceptance tests\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#31-acceptance-tests)\n\n**Project Description:**\n\nIn order to streamline releases, we are planning to ensure that all critical user journeys (CUJs) on the Oppia web application are covered by acceptance tests. This is important because it will provide assurance that, on the merge of every PR, these critical user journeys still function correctly, which means that no major breakages will result if the develop branch gets deployed to production. Additionally, having a complete set of acceptance tests that are organized by CUJ makes it easier to audit whether or not a particular CUJ has been included, and it also helps developers add tests for new CUJs while still keeping the tests well-organized.\n\nThis project includes:\n\n*   Writing acceptance tests for the as-yet-uncovered CUJs in a way that keeps the tests organized and maintainable. This might also include small updates to the acceptance test framework, e.g. extracting utility functions to enable code reuse or providing relevant functionality for a group of tests.\n*   Tightening all page utility functions to have pre/post checks (in the form of \"wait\" statements) and proper error messaging, so that it is easier to debug flakes. The pre-check wait ensures that the conditions are good for performing the action, and the post-check wait ensures that the action has fully completed.\n*   Deleting e2e tests whose functionality has been fully replaced by the acceptance tests.\n\nRelevant documents:\n\n*   Current CUJ tracker: [Critical User Journeys v2](https://docs.google.com/document/d/1s3MG2MVh_7m7B0wIlZb7sAcoyUdY0zq7a1JEFtwYBjI/edit?tab=t.0#heading=h.gs2e2lh85so7)\n*   Spreadsheet that details most of the tests that need to be written: [Web QA Test Matrix (arranged by user type)](https://docs.google.com/spreadsheets/d/1O8EHiSAGrG0yoNUBz9E4DIwKNS8Rfsv_ffC4k1WK5jc/edit#gid=1807800085)\n\n**Tracking issues**: [#21646](https://github.com/oppia/oppia/issues/21646)\n\n**Not in scope:**\n\n*   Configuring the list of prioritized languages for translation\n*   Auto-generation of voiceovers (in any language)\n*   Enabling translations for concept cards, review cards, or practice questions\n*   Showing auto-generated translations in the learner view (see [https://github.com/oppia/oppia/issues/16164](https://github.com/oppia/oppia/issues/16164) for more information).\n\n**Size:** Large (~350 hours)\n\n**Difficulty**: Easy / Moderate\n\n**Potential mentors:** @imchristie\n\n**Product/technical clarifiers:** @seanlip (product), @imchristie (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Debug and fix CI failures/flakes.\n*   Write TS + Angular code with unit tests.\n*   Write or modify e2e/acceptance tests.\n\n**Related issues:**\n\nAcceptance test infrastructure: [https://github.com/orgs/oppia/projects/8/views/11?sliceBy%5Bvalue%5D=Acceptance+Tests](https://github.com/orgs/oppia/projects/8/views/11?sliceBy%5Bvalue%5D=Acceptance+Tests)\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: Tighten all existing page utility functions in `core/tests/puppeteer-acceptance-tests` to have appropriate pre/post checks. Complete all acceptance tests for exploration creators, logged-out users, and logged-in users (as specified in [#21646](https://github.com/oppia/oppia/issues/21646)), and ensure that they run on all PRs by adding them to the \"acceptance test\" GitHub workflow. Remove any existing webdriverio tests whose functionality is fully covered by the new acceptance tests.\n    \n*   **Milestone 2**: Complete all other remaining acceptance tests (as specified in [#21646](https://github.com/oppia/oppia/issues/21646)), and ensure that they run on all PRs by adding them to the \"acceptance test\" GitHub workflow. Remove any existing webdriverio tests whose functionality is fully covered by the new acceptance tests. If any webdriverio tests remain after this step, translate them into CUJs and work with the QA team to make them part of the CUJ document, then implement the corresponding acceptance tests. Finally, remove the old webdriverio and e2e test framework completely.\n    \n\nOrg-admin/tech-lead commentary/adviceThis is a relatively straightforward project, since a lot of the infrastructure has been written and there are lots of examples that you can follow. The most important thing is to set up a good development cycle so that you can debug issues with tests quickly.\n\nIt is important that you are able to get the tests running on your machine, so that you can pause them when needed and investigate to see what is going wrong.\n\nWhat we are looking for in proposalsFor this particular GSoC project, the proposal is less important and we are more interested in your previous PRs. In particular, each of the following can significantly enhance your application:\n\n*   Tackling at least one PR that solves a part of #21646.\n*   Showing at least one debugging doc that correctly diagnoses the root cause of an e2e/acceptance flake.\n*   Making at least one PR that resolves at least one E2E/acceptance flakiness issue (many of these are collected here).\n\nSome things you could address in your proposal:\n\n*   How will you break down this project into individual sub-milestones? Provide a clear timeline for this.\n*   How will you set up your debugging cycle so that you can easily figure out what is going wrong with a test, or fix a flake in it? Explain this for both (a) local development, and (b) getting a test to pass in the CI environment.\n*   Do an audit of which page-level functions are missing pre- or post-checks. List these in your proposal. You might also consider making a PR to fix them for at least one of those files, to demonstrate that you know how to add the checks correctly and to get feedback from reviewers.\n*   For each existing webdriverio test file, specify the set of CUJs which need to be covered by acceptance tests in order for it to be removed. (If you identify gaps in the spreadsheet CUJs during this audit, feel free to suggest additions/updates to those.)\n*   Suggest any improvements that you would make to how the tests are currently organized. How would you make it easy for the QA team to verify whether a particular CUJ is covered by acceptance tests? Also, how would you make it easy for developers to figure out which CUJ they need to update (or if they need to add a completely new one)?\n*   Suggest any missing CUJs that you would add. You can cross-reference the testing spreadsheet with the [CUJ document](https://docs.google.com/document/d/1s3MG2MVh_7m7B0wIlZb7sAcoyUdY0zq7a1JEFtwYBjI/edit) that is currently used for release testing, or identify those journeys yourself through direct experimentation with the test server or your local dev setup. Focus only on critical user journeys -- you do not need to go into detail for all the edge cases. When suggesting missing CUJs, include test specs for the corresponding user journeys (there is a format for this in the GSoC proposal template).\n\nTechnical hints / guidance\n\n*   Start by writing tests for just one CUJ to make sure you can do it properly. If you are able to do that well, then there is a good chance that you will be successful with this project.\n*   For this project, user journeys are detailed in a shared sheet, divided into distinct tabs. During the implementation phase, applicants should tackle each user journey in a structured way, leveraging lessons and code from earlier phases to inform later work. This will help streamline implementation and ensure efficient reuse of developed solutions.\n*   You might want to join the [Release Testing team](https://groups.google.com/g/oppia-release-testers) to help out with testing releases and becoming familiar with the application. The QA team, who coordinates the release testing team, can also advise on CUJs and provide detail on them if any are unclear. Feel free to reach out to them if you have questions.\n*   The acceptance tests ultimately need to pass in the CI environment, which is different from the local environment. How will you set up your debugging workflow so that you can test things on CI quickly? (One approach might be to temporarily comment out the other tests/workflows so that, when you make a push, only the acceptance test you are interested in runs. You might want to try this out for yourself and elaborate on what you did in your proposal.)\n*   The QA team owns the [CUJ document](https://docs.google.com/document/d/1s3MG2MVh_7m7B0wIlZb7sAcoyUdY0zq7a1JEFtwYBjI/edit). If you need to clarify CUJs, feel free to work directly with them on this.\n\nSuggested PM demo points\n\n*   Milestone 1: Acceptance tests for the exploration creator user journeys have been written.\n    \n*   Milestone 2: Acceptance tests for the contributor dashboard user journeys have been written.\n    \n\n### 3.2. Consolidate entity migration jobs\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#32-consolidate-entity-migration-jobs)\n\n**Project Description:**\n\nThe Oppia codebase includes several different versioned entities which store learning material: explorations, skills, stories, subtopic pages, questions, topics, and collections. The infrastructure to maintain each of these versioned entities has been developed separately, and is a bit patchy (for example, migrations of old snapshots have not been implemented for some of the entities). This is making it difficult to remove some of the old version upgrade functions in the codebase which are no longer needed.\n\nThe aim of this project is to standardize these migration jobs so that there is a single, standard way to migrate and upgrade versioned models. This will (a) ensure that all the versioned models can be easily updated on a periodic basis, (b) let us delete the code for upgrading from old versions once all the entities of that version have been upgraded, and (c) simplify the remaining version upgrade code.\n\n**Tracking issues**: [#22023](https://github.com/oppia/oppia/issues/22023)\n\n**Size:** Medium (~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @U8NWXD\n\n**Product/technical clarifiers:** @seanlip (product), @U8NWXD (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Write Python code with unit tests.\n*   Write or modify Beam jobs, with tests.\n\nAdditionally, strong technical design skills and a good sense of code architecture are helpful.\n\n**Related issues:**\n\n*   [#16556](https://github.com/oppia/oppia/issues/16556) is a good issue to look into, since it will help you become familiar with the migration job infrastructure.\n*   [Issues related to Beam jobs](https://github.com/oppia/oppia/labels/Beam%20jobs) are also good ones to look at.\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: Create a BaseVersionedDomainObject which specifies object member mappings to storage model properties in a declarative way, and also specifies the \"schema version field\" corresponding to each JsonProperty-related field. Add tests to ensure that all JsonProperties are accounted for. Then, replace all existing domain objects for versioned models with subclasses of BaseVersionedDomainObject. Additionally, ensure that all functions that convert storage models to domain objects also migrate domain objects to the latest schema version.\n    \n*   **Milestone 2**: Create BaseMigrateVersionedModelJob and BaseMigrateVersionedModelSnapshotsJob classes with the core logic for upgrading models and snapshots to the latest schema versions, respectively. Use these to build both job and audit job subclasses for all versioned models (explorations, skills, stories, subtopic pages, questions, topics, collections) with proper logging and error reporting (e.g. if a migration fails, the model that could not be migrated should be logged for debugging). Test these jobs on production data to ensure that they work correctly, and fix any issues that arise. Finally, run all the jobs in all our production environments, so that all the models and snapshots on the server are upgraded to the latest schema versions, then remove the old jobs and the old conversion functions for all 7 versioned models, as well as the methods they call (similar to what was done in [https://github.com/oppia/oppia/pull/12256/files](https://github.com/oppia/oppia/pull/12256/files)).\n    \n\nOrg-admin/tech-lead commentary/adviceThis project requires a very good understanding of how our migration pipeline works, and a solid grasp of technical architecture so that you can make good design decisions for how the base classes and their subclasses are structured. However, once that is well-understood, it should not be too difficult to implement. You will probably find deleting all the old code at the end quite satisfying!\n\nWhat we are looking for in proposalsIn addition to your implementation approach, please also:\n\n*   Analyze the jobs for the existing entities to understand and catalogue their differences. Then, for each of those differences, make a proposal for how you plan to standardize it, and explain the implementation of each of the resulting base job and audit job classes for migrating entities and entity snapshots.\n*   Describe what error reporting or logging you would add to the Beam job to make it easy for you or server admins to detect/debug issues when it is run.\n*   Describe how you would name the new jobs. Try to use a standard naming convention that is easily extended to versioned models that are introduced in the future.\n*   For each entity type, list the functions/constants that you plan to delete (in addition to the conversion methods) after you have confirmed that all models are using the latest schema versions. Describe how you determined that this is the complete list of orphaned functions/constants.\n*   Provide a full example of how you would set up the BaseVersionedDomainObject with declarative definitions for at least one of the existing versioned models. Clarify what goes into the base domain object and what goes into the subclasses.\n*   List the validation checks that the versioned domain object classes must satisfy, and describe how your backend tests will automatically pick up all the versioned domain object classes in the codebase when new ones are added.\n\nTechnical hints / guidance\n\n*   There are existing jobs and audit jobs in the codebase for migrating models and snapshots (e.g. MigrateExplorationJob, ExpSnapshotsMigrationAuditJob, etc.). All these should be deleted at the end of the project. This old wiki page with instructions for writing schema migrations might also provide some useful background: [https://github.com/oppia/oppia/wiki/Writing-state-migrations](https://github.com/oppia/oppia/wiki/Writing-state-migrations)\n    \n*   The bulk of the logic for all the new jobs should be in the two base classes, BaseMigrateVersionedModelJob and BaseMigrateVersionedModelSnapshotsJob. In general, if some functionality is common to all versioned models, it should be included in the base class, otherwise it should be defined in the relevant subclass(es). Ideally, the subclasses would just point to the relevant storage models / domain object classes and not include any custom logic – see `SNAPSHOT_METADATA_CLASS` in `ExplorationModel` for an example of this. The corresponding audit jobs for these two jobs should be trivial subclasses of the main jobs with `DATASTORE_UPDATES_ALLOWED = False`. (Look at the usage of `DATASTORE_UPDATES_ALLOWED` in the codebase for more information.)\n    \n*   Part of this project includes standardizing the infrastructure for migrating JSON properties. Here is a more detailed technical sketch for how this could be done:\n    \n    *   Create a BaseVersionedDomainObject whose subclasses declaratively specify a mapping from any versioned field to its corresponding schema version field. (These fields correspond to `JsonProperty` in the datastore's storage model.) Un-versioned fields of type `Dict` or \\`List\\[Dict\\]\\`\\` should be explicitly declared as un-versioned. Subclasses must also reference constants in feconf.py that specify the minimum and maximum version of each field.\n        \n    *   Write backend tests that:\n        \n        *   Identify all subclasses of BaseVersionedDomainObject in the codebase and verify that every `Dict` or \\`List\\[Dict\\]\\`\\` field contained in the object is either included in the mapping mentioned above or included in a list of un-versioned fields. This ensures that all versioned domain objects have the necessary infrastructure for performing schema upgrades for their respective JsonProperties.\n        *   Ensure that the relevant migration functions for each upgradable field are present in the corresponding domain object class with the function signatures (including type hints). Specifically, each conversion function should accept one parameter of the same type as the versioned field and should return one value of the same type. The migration functions can be named using a standard scheme, e.g. `_convert_{{field_name}}_v{{x}}_dict_to_v{{x+1}}_dict`, and the backend test can check for that. This test should also use the minimum and maximum schema versions to check that upgrade functions from the minimum up to the maximum version are present.\n    *   Add a `migrate_to_latest_schema_versions` function to BaseVersionedDomainObject to handle schema upgrades in a generalized way across all domain objects.\n        \n    *   Ensure that all the different getter functions in the \\_services/fetchers.py files that convert storage models to domain objects also use `migrate_to_latest_schema_versions` to translate that object’s fields to use the latest schema versions.\n        \n    *   Replace all domain objects corresponding to VersionedModels with the new BaseVersionedDomainObject.\n        \n*   Here's a schematic depiction of a possible end state for versioned domain models:\n    \n    ```\n    class BaseVersionedDomainObject:\n      - Class Variables:\n         - schema_versioned_attributes = {}\n      - Methods:\n        - def migrate_to_latest_schema_versions():\n          - Use the versioned_attributes map to find versioned fields. Then call update functions on each of those until the entire domain object is fully upgraded.\n    \n    class Exploration(BaseVersionedDomainObject:\n      - Class Variables:\n        -  schema_versioned_attributes: {\n            \"states_dict\": {\n              \"version_field\": \"states_schema_version\",\n              \"version_min\": feconf.MIN_STATE_SCHEMA_VERSION (e.g. 5),\n              \"version_max\": feconf.CURRENT_STATE_SCHEMA_VERSION (e.g. 10)\n            }\n          }\n      - Methods:\n        - def _convert_states_v5_dict_to_v6_dict\n        - ...\n        - def _convert_states_v9_dict_to_v10_dict\n    ```\nSuggested PM demo points\n\n*   Milestone 1: At least one domain object is using BaseVersionedDomainObject, and all the get/save functionality works correctly.\n    \n*   Milestone 2: All jobs run correctly on the backup server.\n    \n\n### 3.3. Standardize and validate domain objects and storage models\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#33-standardize-and-validate-domain-objects-and-storage-models)\n\n**Project Description:**\n\nOppia's production data is organized using [NDB storage models](https://github.com/oppia/oppia/wiki/Storage-models#storage-model-concepts), which in simple terms can be thought of as objects having different properties. For instance, data related to a user can be stored in a UserSettingsModel with properties like username, user ID, etc.\n\nDifferent inter-model relationships exist as well, corresponding to relationships between prod data. For instance, a story includes a list of explorations. So, a StoryModel might include the IDs of all the ExplorationModels it is composed of.\n\nFor proper functioning of the Oppia application, it is important to ensure that all the models are internally consistent and that the relationships between models are valid. The aim of this project is therefore to ensure that all production data is valid by:\n\n*   Ensuring that domain objects exist for all prod models, and that they have full `validate()` functions.\n    \n*   Implementing Beam jobs that audit production data and flag any errors. These jobs should validate the model properties as well as inter-model relationships. After these jobs are run, any errors should be investigated, and checks should be implemented to ensure that such problems don’t reoccur in the future with new data.\n    \n\n**Tracking issues**:\n\n*   [#21970](https://github.com/oppia/oppia/issues/21970)\n*   [#21905](https://github.com/oppia/oppia/issues/21905)\n*   [#21869](https://github.com/oppia/oppia/issues/21869)\n\n**Not in scope:** Migrating existing datastore data to address the validation issues found in the first milestone.\n\n**Size:** Large (~350 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @ankita240796\n\n**Product/technical clarifiers:** @seanlip (product), @ankita240796 (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Write Python code with unit tests.\n*   Write or modify Beam jobs, with tests.\n\n**Related issues:**\n\n*   [https://github.com/oppia/oppia/issues/21970](https://github.com/oppia/oppia/issues/21970)\n*   [https://github.com/oppia/oppia/issues/21905](https://github.com/oppia/oppia/issues/21905)\n*   [https://github.com/oppia/oppia/issues/21869](https://github.com/oppia/oppia/issues/21869)\n*   The first checkbox item from any of the following:\n    *   [https://github.com/oppia/oppia/issues/14968](https://github.com/oppia/oppia/issues/14968)\n    *   [https://github.com/oppia/oppia/issues/14967](https://github.com/oppia/oppia/issues/14967)\n    *   [https://github.com/oppia/oppia/issues/14969](https://github.com/oppia/oppia/issues/14969)\n    *   [https://github.com/oppia/oppia/issues/14971](https://github.com/oppia/oppia/issues/14971)\n    *   [https://github.com/oppia/oppia/issues/14972](https://github.com/oppia/oppia/issues/14972)\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: Domain objects exist for all storage models, and include validate() methods that fully validate the domain object's internal consistency and correctness. The usage of storage models in the domain layer is restricted to the interfaces for getting and saving datastore models, and they are not passed further around the codebase. 50% of the validation jobs for the storage models are implemented and run successfully. For each validation error found, an issue is filed with clear action steps for (a) stopping the error from happening for new data, and (b) migrating old data to fix the error.\n    \n*   **Milestone 2**: All remaining validation jobs for the storage models are implemented and run successfully, and issues are filed for all validation errors as described in Milestone 1. All root causes of the validation issues found in Milestones 1 and 2 are identified and fixed, so that the error no longer happens for new data. (This corresponds to part (a) of each issue in Milestone 1.)\n    \n\nOrg-admin/tech-lead commentary/adviceThis project is relatively straightforward if you can identify the validation checks correctly and are able to analyze the codebase to figure out why incorrect data is being written. The [design brief](https://docs.google.com/document/d/1u45oC6igsaTvQl4oNd8VvDiZe3JqeY3m_5n4QZ6d4rA/edit?usp=sharing) provided in the technical hints should help provide a lot of the necessary structure. Note that the validation requirements for the different models can vary greatly in terms of difficulty.\n\nWhat we are looking for in proposalsFor your proposal, please include the following:\n\n*   A complete list of all storage models, with “validity” clearly defined for (a) the corresponding domain objects, (b) the models themselves (including inter-model relationships).\n    \n*   How you would structure the sub-milestones to enable you to run jobs efficiently on the server in batches.\n    \n*   A worked example of how you would do each part of the project (domain-object creation, only using storage models in get/put, writing a validation job, filing the GitHub issue, fixing the root cause). You can link to sample PRs if you like. For the purposes of this illustration, we suggest that you pick one or two \"average\" or \"hard\" examples – try not to pick a trivial model.\n    \n*   Any complicated cases you identify for any of the above steps, and an explanation of how you would tackle them. (For example, customization arg validation for interactions.)\n    \n*   An explanation of how you would ensure/verify that storage models are not used beyond the get and save functions in the `*_services.py` file. (For example, you might come up with a standard pattern for get/save that you can implement universally to make that verification easy to do, or you might analyze import statements that involve to the storage layer, or you might add a backend test to ensure that ndb.Model instances are not passed beyond specific functions.)\n    \n\nWe also recommend taking up at least one checkbox item from each of the following, in order to confirm that this project is a good fit for you:\n\n*   [https://github.com/oppia/oppia/issues/21970](https://github.com/oppia/oppia/issues/21970)\n*   [https://github.com/oppia/oppia/issues/21869](https://github.com/oppia/oppia/issues/21869)\n*   The first checkbox from any of the following (to demonstrate ability to “identify the root cause of an error and stop it from happening”):\n    *   [https://github.com/oppia/oppia/issues/14968](https://github.com/oppia/oppia/issues/14968)\n    *   [https://github.com/oppia/oppia/issues/14967](https://github.com/oppia/oppia/issues/14967)\n    *   [https://github.com/oppia/oppia/issues/14969](https://github.com/oppia/oppia/issues/14969)\n    *   [https://github.com/oppia/oppia/issues/14971](https://github.com/oppia/oppia/issues/14971)\n    *   [https://github.com/oppia/oppia/issues/14972](https://github.com/oppia/oppia/issues/14972)\n\nTechnical hints / guidance\n\n*   Please go through the following guides in the Oppia wiki:\n    \n    *   [Storage models](https://github.com/oppia/oppia/wiki/Storage-models#storage-model-concepts)\n    *   [Testing jobs and other features on production](https://github.com/oppia/oppia/wiki/Testing-jobs-and-other-features-on-production)\n    *   [Debugging datastore locally](https://github.com/oppia/oppia/wiki/Debugging-datastore-locally)\n    *   [Apache Beam Jobs](https://github.com/oppia/oppia/wiki/Apache-Beam-Jobs) · oppia/oppia Wiki · GitHub\n        *   Note that, in general, any Beam jobs you write should be **idempotent**, i.e., running them twice should result in the same outcome as running them once. This allows us to just rerun them if a job fails for some reason (e.g. due to an internal Beam error).\n*   See [this design brief](https://docs.google.com/document/d/1u45oC6igsaTvQl4oNd8VvDiZe3JqeY3m_5n4QZ6d4rA/edit?usp=sharing) for a design approach that you can follow for the validation jobs.\n    \n*   To understand how validation jobs work, you might like to take a look at the existing [audit and validation jobs](https://github.com/oppia/oppia/tree/develop/core/jobs/batch_jobs). Some examples:\n    \n    *   [https://github.com/oppia/oppia/blob/develop/core/jobs/batch\\_jobs/user\\_validation\\_jobs.py](https://github.com/oppia/oppia/blob/develop/core/jobs/batch_jobs/user_validation_jobs.py)\n    *   [https://github.com/oppia/oppia/blob/develop/core/jobs/batch\\_jobs/blog\\_validation\\_jobs.py](https://github.com/oppia/oppia/blob/develop/core/jobs/batch_jobs/blog_validation_jobs.py)\n\nSuggested PM demo points\n\n*   Milestone 1: Validation jobs for at least 5 prod models are written & run, and errors arising from those jobs have been filed as issues on GitHub.\n    \n*   Milestone 2: A full list of errors is compiled with clear action items.\n    \n\nAndroid team\n------------\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#android-team-1)\n\n### 4.1. Flashbacks\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#41-flashbacks)\n\n**Project Description:**\n\nWhen learners make a mistake on a concept they have previously demonstrated in an earlier part of a lesson, it often makes sense to redirect them back to an earlier card to try and reinforce earlier concepts that the learner may have not fully understood. However, with the current implementation, learners subsequently need to re-answer all the cards between the earlier state and the state they had reached, which is frustrating.\n\nThis project aims to provide a new feature called ‘flashbacks’ which helps to bring the benefits of earlier redirection (i.e. reviewing an earlier concept that directly ties to the misconception) without the frustrating part of having to redo the old questions before returning back to the question that originally caused the learner to become stuck.\n\nAdditionally, this project also includes improving the general look-and-feel of submitted answers for both multiple choice and item selection interactions as these both currently rely on HTML generation rather than having a cleaner, natively rendered experience. This will also allow them to be displayed properly in the “flashback” experience.\n\nRelevant links: Mocks ([https://github.com/oppia/design-team/issues/50](https://github.com/oppia/design-team/issues/50)) and [PRD](https://docs.google.com/document/d/1NpWgRN6BgvlutWXTYkz997ft36nRMYCbxSO7RYy2iV8/edit?tab=t.0) (incomplete). Specific notes on mocks:\n\n*   The mocks don't include explicit changes for multiple choice and item selection.\n*   The mocks don't quite represent the correct ‘inline’ experience that needs to be introduced for the ‘Learn Again’ button (which should be part of the answer & response section of the incorrect answer that is prompting for a revisit).\n*   Only the mocks with the orange toolbars are actually correct and need to be implemented (except for the otter, and the return button should be part of the flow rather than overlaid).\n\n**Tracking issues**: _To be updated._\n\n**Size:** Medium (~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @adhiamboperes\n\n**Product/technical clarifiers:** @seanlip (product), @BenHenning (technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.\n*   Write new Kotlin code with unit tests.\n*   Change Android UIs, write tests for them, and manually verify that they work.\n\n**Related issues:**\n\nKey issue: [#5572](https://github.com/oppia/oppia-android/issues/5572). This tracks introducing a short-term solution of the broader problem this GSoC project aims to solve.\n\n_(Note: Additional issues will be added soon.)_\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: The new flashback dialog is implemented and hooked up to the existing soft redirection button. (The in-line flow does not need to work at this stage.)\n    \n*   **Milestone 2**: The flashback dialog is hooked up with the learner flow to have an in-line view (i.e. the 'Learn Again' button is attached to the incorrect answer that led to the flashback), and relevant UI tests are added. Also, the new designs for multiple choice and item selection interactions are implemented.\n    \n\nOrg-admin/tech-lead commentary/adviceThis project involves a lot of very gritty coding work in the most critical code pathways in the app: the core learner flow. These are not simple areas of the app as Oppia's core lesson flow is fundamentally complex, but fortunately there are dozens of past projects and changes that have changed these coding areas (which may act as good references) and the codepath has generally excellent test coverage (which means we can be confident when we make changes to these areas).\n\nMaking changes to the core lesson flow may be a combination of feeling like a lot of progress is being made (when adding some of the fairly substantial boilerplate involved in adding views to the lesson flow), and other times where it can take a while just to add a few lines of code (due to the surrounding area being particularly complex, such as for the actor-based [ExplorationProgressController](https://github.com/oppia/oppia-android/blob/4f58be9d399c70e1d1cd241495280ae913afbf07/domain/src/main/java/org/oppia/android/domain/exploration/ExplorationProgressController.kt#L106)). It may be very difficult to fully grok the full dependency and data flow for explorations, but it's usually straightforward to jump in and start making changes that in turn show up in the lesson viewer frontend.\n\nWhat we are looking for in proposals\n\n*   An explanation for how the new functionality will be gated behind a [feature flag](https://github.com/oppia/oppia-android/wiki/Platform-Parameters-&-Feature-Flags) to ensure that changes don't get shipped to end users before the feature is completed.\n*   A list of test names that will be added (we generally add automated tests for every code change).\n*   Multiple diagrams, particularly:\n    *   A dependency diagram showing how different components (i.e. classes) of the implementation call into each other.\n    *   A flow diagram to show how user interactions flow into different state changes in code.\n\nTechnical hints / guidance_This will be added soon._\n\nSuggested PM demo points\n\n*   Milestone 1: Trigger a “user is soft redirected” state to demonstrate the flashback dialog.\n    \n*   Milestone 2: Demonstrate the \"user is soft-redirected\" flashback with the in-line \"Learn Again\" button along with the new item selection and multiple choice interaction views (for submitted answers).\n    \n\n### 4.2. Platform parameters dashboard\n\n[](https://github.com/oppia/oppia/wiki/Google-Summer-of-Code-2025#42-platform-parameters-dashboard)\n\n**Project Description:**\n\nFeature flags are a special type of configurable [platform parameter](https://github.com/oppia/oppia-android/wiki/Platform-Parameters-&-Feature-Flags#introduction) which allows the team to stage features behind remotely configurable flags until they're ready to be launched. This allows features to be developed across multiple releases without users seeing part of the feature (or app stability issues when the feature is enabled), ensuring the team can release high-quality features without hurting the overall quality and performance of the app. Broadly, platform parameters allow the team to configure the overall app (which can be useful both for feature flags, as described above, and safety 'knobs' such as controlling rate limits to remote APIs to help reduce the chance of server outages).\n\nThis project entails introducing a developer-only UI (as part of the developer options section of the app) which displays all platform parameters and feature flags in the app, their current enabled/disabled status (for feature flags) or values (for platform parameters), and their sync status (i.e. whether they're being synced from the server or using a local developer default). It also allows an explicit manual override to force the feature on or off, or to override the platform parameter's value.\n\n**Tracking issues**: [#5345](https://github.com/oppia/oppia-android/issues/5345) (note that this issue presently includes testing work that may well be completed by [#5565](https://github.com/oppia/oppia-android/pull/5565)).\n\n**Size:** Medium (~175 hours)\n\n**Difficulty**: Moderate\n\n**Potential mentors:** @Rd4dev\n\n**Product/technical clarifiers:** @BenHenning (product + technical)\n\n**Required knowledge/skills:**\n\n*   Figure out the root cause of an issue and communicate it well using a [debugging doc](https://github.com/oppia/oppia/wiki/Debugging-Docs).\n*   Build the app and install it on a local device or emulator. Then verify that you can (a) build a non-test library target locally, (b) run a unit test locally, and (c) play through the app locally.\n*   Write new Kotlin code with unit tests.\n*   Change Android UIs, write tests for them, and manually verify that they work.\n\n**Related issues:**\n\n_(Note: Specific issues will be added soon.)_\n\n**Suggested Milestones:**\n\n*   **Milestone 1**: Key deliverables:\n    \n    *   Display a list of platform parameters and feature flags from a Developer Options menu, along with their current values and sync statuses.\n    *   Set up initial tests to demonstrate that the UI displays correctly.\n*   **Milestone 2**: Key deliverables:\n    \n    *   Support for overwriting platform parameters and feature flags, including force-restarting the app upon navigating away from the menu (so that the changes can take effect).\n    *   Updated UI tests for the new functionality.\n\nOrg-admin/tech-lead commentary/adviceThis project involves introducing a new, isolated user interface that only affects developers (and possibly testers or user study facilitators in the future) which means it doesn't require the same level of gating as regular learner-facing features. It's often nice to work on brand new UIs, as well, since everything is starting in a fresh, clean state rather than building on existing complexity and tests.\n\nThe domain side of platform parameters isn't trivial to understand, but it's straightforward to explain and analyze the dataflow. This is expected to be a straightforward project that balances domain and frontend work (with a majority of the work being UI-related).\n\nWhat we are looking for in proposals\n\n*   A strong understanding of:\n    *   Feature flags and platform parameters, including their complete lifecycle for both production and tests.\n    *   Dagger dependency gating and how dependencies can differ based on the flavor of the app being built, and whether it's a test environment.\n*   A list of test names that will be added (we generally add automated tests for every code change).\n*   Multiple diagrams, particularly:\n    *   A dependency diagram showing how different components (i.e. classes) of the implementation call into each other.\n    *   A flow diagram to show how user interactions flow into different state changes in code.\n\nTechnical hints / guidance_This will be added soon._\n\nSuggested PM demo points\n\n*   Milestone 1: The new UI correctly shows all platform parameters and feature flags, and their correct value and sync statuses.\n    \n*   Milestone 2: The new screen fully supports overriding various platform parameters and feature flag values.\n"}